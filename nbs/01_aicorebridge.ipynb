{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AICore-Bridge\n",
    "\n",
    "> Bridge between Stactics AICore framework and Wodan/Conan processor modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp aicorebridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import typing\n",
    "import logging\n",
    "import inspect\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fastcore.basics import patch_to, patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "syslog = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AICoreModule(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __init__(self:AICoreModule, \n",
    "             save_dir:str, # path where the module can keep files \n",
    "             processor:typing.Callable, # data processing function\n",
    "             *args, **kwargs):\n",
    "    \n",
    "    self.save_dir  = save_dir\n",
    "    self._init_processor(processor)\n",
    "\n",
    "    self.init_args = args\n",
    "    self.init_kwargs = kwargs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _init_processor(\n",
    "        self:AICoreModule, \n",
    "        processor:typing.Callable):\n",
    "    \"\"\"Initializes processor related variables on self\"\"\"\n",
    "    \n",
    "    self.processor = processor\n",
    "    self.processor_signature = inspect.signature(self.processor)\n",
    "    self.processor_params = dict(self.processor_signature.parameters)\n",
    "    self.return_param = self.processor_params.pop('return', None)\n",
    "    self.data_param, *self.call_params = list(self.processor_params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def infer(self:AICoreModule, data:dict, *_, **kwargs):\n",
    "    try:\n",
    "\n",
    "        msg=[\n",
    "            f\"{self.processor.__name__}({self.processor_signature})\",\n",
    "            f\"init_args: {self.init_args}, init_kwargs: {self.init_kwargs}\",\n",
    "        ]\n",
    "\n",
    "        lastSeen = kwargs.pop('lastSeen', False)\n",
    "        recordformat = kwargs.pop('format', \"records\").lower()\n",
    "        reversed = kwargs.pop('reversed', False)\n",
    "        timezone = kwargs.get('timezone', 'UTC')\n",
    "        msg.append(f\"lastSeen: {lastSeen}, recordformat: {recordformat}, timezone: {timezone}\")\n",
    "\n",
    "        calldata = self.get_call_data(\n",
    "            data, \n",
    "            recordformat=recordformat,\n",
    "            timezone=timezone,\n",
    "            reversed=reversed)\n",
    "        \n",
    "        msg.append(f\"calldata shape: {calldata.shape}\")\n",
    "\n",
    "        callargs = self.get_callargs(**kwargs)\n",
    "\n",
    "        for arg, val in callargs.items():\n",
    "            msg.append(f\"{arg}: {val}\")\n",
    "            \n",
    "        result = self.processor(calldata, **callargs)\n",
    "        msg.append(f\"result shape: {result.shape}\")\n",
    "\n",
    "        return {\n",
    "            'msg':msg,\n",
    "            'data': self.rewrite_data(\n",
    "                result if not lastSeen else result[-1:],\n",
    "                recordformat=recordformat,\n",
    "                timezone=timezone,\n",
    "                reversed=reversed)\n",
    "        }\n",
    "    except Exception as err:\n",
    "        return {\n",
    "            'msg': f\"Unexpected {err=}, {type(err)=}\",\n",
    "            'data': []\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_callargs(self:AICoreModule, **kwargs):\n",
    "    \"Get arguments for the processor call\"\n",
    "\n",
    "    metadata = kwargs.pop('metadata', {}) # TODO: historic metadata\n",
    "\n",
    "    return {\n",
    "        K:self.processor_signature.parameters[K].annotation(kwargs.get(K,metadata.get(K, self.init_kwargs.get(K, self.processor_signature.parameters[K].default))))\n",
    "        for K in self.call_params\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_call_data(\n",
    "        self:AICoreModule, \n",
    "        data:dict, \n",
    "        recordformat='records', \n",
    "        timezone='UTC', \n",
    "        reversed=False):\n",
    "    \n",
    "    \"Convert data to the processor signature\"\n",
    "\n",
    "    orient = recordformat.lower()\n",
    "    assert orient in ['records', 'table']\n",
    "    #assert False, \"started work on format\"\n",
    "    \n",
    "    if orient == 'records':\n",
    "        df = pd.DataFrame.from_records(data)\n",
    "        time_column = [C for C in df.columns if C.lower() in ['datetimemeasure', 'time']][0]\n",
    "\n",
    "    elif orient == 'table':\n",
    "        time_column = data['schema']['primaryKey'][0]\n",
    "        df = pd.DataFrame.from_dict(data['data']).set_index(data['schema']['primaryKey'])\n",
    "        df.index.name = 'time'\n",
    "\n",
    "    df.columns = [C.lower() for C in df.columns]\n",
    "    time_column = [C for C in df.columns if C in ['datetimemeasure', 'time']][0]\n",
    "    df[time_column] = pd.to_datetime(df[time_column],utc=True,format='ISO8601')\n",
    "    df.set_index(time_column, inplace=True)\n",
    "    #df.index = pd.DatetimeIndex(df.index).round('ms')\n",
    "    \n",
    "    df.index.name = 'time'\n",
    "\n",
    "    if reversed:\n",
    "        df = df[::-1]\n",
    "\n",
    "    if not df.index.tz:\n",
    "        df.index = df.index.tz_localize('UTC').tz_convert(timezone)\n",
    "    elif str(df.index.tz) != timezone:\n",
    "        df.index = df.index.tz_convert(timezone)\n",
    "\n",
    "    if self.processor_params[self.data_param].annotation == pd.DataFrame:\n",
    "        return df\n",
    "    elif len(df.columns) > 1:\n",
    "        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)\n",
    "        return df.to_records(index=True)\n",
    "    else:\n",
    "        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)\n",
    "        return df.reset_index().to_numpy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def rewrite_data(\n",
    "        self:AICoreModule, \n",
    "        data:typing.Union[pd.DataFrame, pd.Series, dict], \n",
    "        recordformat:str='split', \n",
    "        timezone:str='UTC', \n",
    "        reversed:bool=False):\n",
    "    \n",
    "    \"Rewrite data to dictionary matching the requested recordformat\"\n",
    "\n",
    "    orient = recordformat.lower()\n",
    "\n",
    "    if orient == 'split-index':\n",
    "        orient = 'split'\n",
    "\n",
    "    normalized_data = self.convert_to_dataframe(data, timezone=timezone)\n",
    "    normalized_data.index = normalized_data.index.map(lambda x: x.isoformat())\n",
    "    \n",
    "    if reversed:\n",
    "        normalized_data = normalized_data[::-1]\n",
    "\n",
    "    if orient == 'records':\n",
    "        records = normalized_data.reset_index().to_dict(orient='records')\n",
    "    else:\n",
    "        records =  normalized_data.to_dict(orient=orient)\n",
    "    \n",
    "\n",
    "    if normalized_data.isna().any(axis=None):\n",
    "        return [ {k:v for k,v in m.items() if pd.notnull(v)} for m in records]\n",
    "    else:\n",
    "        return records\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def convert_to_dataframe(\n",
    "        self:AICoreModule, \n",
    "        adata:typing.Union[pd.DataFrame, pd.Series, dict, np.ndarray, np.recarray], \n",
    "        timezone='UTC', \n",
    "        columnnames=None):\n",
    "    \"\"\"Convert various data formats to standardized timeseries DataFrame\"\"\"\n",
    "\n",
    "    if isinstance(adata, pd.DataFrame):\n",
    "        df = adata\n",
    "    elif isinstance(adata, pd.Series):\n",
    "        df = pd.DataFrame(adata)\n",
    "\n",
    "    elif isinstance(adata, dict):\n",
    "        # dict/mapping of individual timeseries\n",
    "        df = pd.DataFrame({\n",
    "            C:pd.Series(data=A[:,1], index=pd.DatetimeIndex(A[:,0]*1e9)) if isinstance(A, np.ndarray) else A\n",
    "            for C,A in adata.items()\n",
    "        })\n",
    "\n",
    "    elif adata.dtype.names is not None:\n",
    "        # structured or recarray\n",
    "        df = pd.DataFrame(\n",
    "            data=adata.view(dtype=np.float64).reshape(adata.shape[0],len(adata.dtype))[:,range(1,len(adata.dtype))],\n",
    "            index=pd.DatetimeIndex(adata.view(dtype=np.float64).reshape(adata.shape[0],len(adata.dtype))[:,0] * 1e9),\n",
    "            columns=adata.dtype.names[1:]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if adata.shape[0] > 0:\n",
    "            if adata.shape[1]>2:\n",
    "                columns=[f\"value_{str(i+1)}\" for i in range(adata.shape[1]-1)] if not columnnames else [f\"{str(i)}\" for i in columnnames[1:]]\n",
    "            else:\n",
    "                columns=['value']\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                data=adata[:, 1:],\n",
    "                index=pd.DatetimeIndex(adata[:,0]*1e9),\n",
    "                columns=columns\n",
    "            )\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    df.index.name = 'time'\n",
    "    if not df.index.tz:\n",
    "        df.index = df.index.tz_localize('UTC').tz_convert(timezone)\n",
    "    elif str(df.index.tz) != timezone:\n",
    "        df.index = df.index.tz_convert(timezone)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtimezone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumnnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Convert various data formats to standardized timeseries DataFrame\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_15928/1154341381.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = AICoreModule(\"\",print)\n",
    "? cm.convert_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       " \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtitles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbyteorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maligned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Construct an ndarray that allows field access using attributes.\n",
       "\n",
       "Arrays may have a data-types containing fields, analogous\n",
       "to columns in a spread sheet.  An example is ``[(x, int), (y, float)]``,\n",
       "where each entry in the array is a pair of ``(int, float)``.  Normally,\n",
       "these attributes are accessed using dictionary lookups such as ``arr['x']``\n",
       "and ``arr['y']``.  Record arrays allow the fields to be accessed as members\n",
       "of the array, using ``arr.x`` and ``arr.y``.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "shape : tuple\n",
       "    Shape of output array.\n",
       "dtype : data-type, optional\n",
       "    The desired data-type.  By default, the data-type is determined\n",
       "    from `formats`, `names`, `titles`, `aligned` and `byteorder`.\n",
       "formats : list of data-types, optional\n",
       "    A list containing the data-types for the different columns, e.g.\n",
       "    ``['i4', 'f8', 'i4']``.  `formats` does *not* support the new\n",
       "    convention of using types directly, i.e. ``(int, float, int)``.\n",
       "    Note that `formats` must be a list, not a tuple.\n",
       "    Given that `formats` is somewhat limited, we recommend specifying\n",
       "    `dtype` instead.\n",
       "names : tuple of str, optional\n",
       "    The name of each column, e.g. ``('x', 'y', 'z')``.\n",
       "buf : buffer, optional\n",
       "    By default, a new array is created of the given shape and data-type.\n",
       "    If `buf` is specified and is an object exposing the buffer interface,\n",
       "    the array will use the memory from the existing buffer.  In this case,\n",
       "    the `offset` and `strides` keywords are available.\n",
       "\n",
       "Other Parameters\n",
       "----------------\n",
       "titles : tuple of str, optional\n",
       "    Aliases for column names.  For example, if `names` were\n",
       "    ``('x', 'y', 'z')`` and `titles` is\n",
       "    ``('x_coordinate', 'y_coordinate', 'z_coordinate')``, then\n",
       "    ``arr['x']`` is equivalent to both ``arr.x`` and ``arr.x_coordinate``.\n",
       "byteorder : {'<', '>', '='}, optional\n",
       "    Byte-order for all fields.\n",
       "aligned : bool, optional\n",
       "    Align the fields in memory as the C-compiler would.\n",
       "strides : tuple of ints, optional\n",
       "    Buffer (`buf`) is interpreted according to these strides (strides\n",
       "    define how many bytes each array element, row, column, etc.\n",
       "    occupy in memory).\n",
       "offset : int, optional\n",
       "    Start reading buffer (`buf`) from this offset onwards.\n",
       "order : {'C', 'F'}, optional\n",
       "    Row-major (C-style) or column-major (Fortran-style) order.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "rec : recarray\n",
       "    Empty array of the given shape and type.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "core.records.fromrecords : Construct a record array from data.\n",
       "record : fundamental data-type for `recarray`.\n",
       "format_parser : determine a data-type from formats, names, titles.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This constructor can be compared to ``empty``: it creates a new record\n",
       "array but does not fill it with data.  To create a record array from data,\n",
       "use one of the following methods:\n",
       "\n",
       "1. Create a standard ndarray and convert it to a record array,\n",
       "   using ``arr.view(np.recarray)``\n",
       "2. Use the `buf` keyword.\n",
       "3. Use `np.rec.fromrecords`.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Create an array with two fields, ``x`` and ``y``:\n",
       "\n",
       ">>> x = np.array([(1.0, 2), (3.0, 4)], dtype=[('x', '<f8'), ('y', '<i8')])\n",
       ">>> x\n",
       "array([(1., 2), (3., 4)], dtype=[('x', '<f8'), ('y', '<i8')])\n",
       "\n",
       ">>> x['x']\n",
       "array([1., 3.])\n",
       "\n",
       "View the array as a record array:\n",
       "\n",
       ">>> x = x.view(np.recarray)\n",
       "\n",
       ">>> x.x\n",
       "array([1., 3.])\n",
       "\n",
       ">>> x.y\n",
       "array([2, 4])\n",
       "\n",
       "Create a new, empty record array:\n",
       "\n",
       ">>> np.recarray((2,),\n",
       "... dtype=[('x', int), ('y', float), ('z', int)]) #doctest: +SKIP\n",
       "rec.array([(-1073741821, 1.2249118382103472e-301, 24547520),\n",
       "       (3471280, 1.2134086255804012e-316, 0)],\n",
       "      dtype=[('x', '<i4'), ('y', '<f8'), ('z', '<i4')])\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.11/site-packages/numpy/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? np.recarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
