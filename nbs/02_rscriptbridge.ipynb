{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RScript-Bridge\n",
    "\n",
    "> Bridge between Stactics AICore framework and RScript prediction scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some things to set up first\n",
    "\n",
    "Notebooks use nbdev thingses and `addroot` makes importing from\n",
    "the repo-directory more convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import addroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import json, os\n",
    "import subprocess\n",
    "import hashlib\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AICore uses an `assets` dir from which we can read files, like scripts\n",
    "and a `save` dir were modules can write and read files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assets_dir = os.path.join(os.path.abspath(os.getcwd()), 'assets', 'rscript')\n",
    "save_dir = os.path.join(os.path.abspath(os.getcwd()), 'saves', 'rscript')\n",
    "\n",
    "def get_asset_path(script_name): \n",
    "    return os.path.join(assets_dir, script_name)\n",
    "def get_save_path(datafile_name): \n",
    "    return os.path.join(save_dir, datafile_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def display_table(feature_dict):\n",
    "    display(Markdown(tabulate(\n",
    "      [[v for v in row.values()] for row in feature_dict],\n",
    "      headers=[k for k in feature_dict[0].keys()],\n",
    "        tablefmt='github'\n",
    "    )))\n",
    "data_file_flow = {}\n",
    "\n",
    "def display_flow_table(flow_table):\n",
    "    columns = set([C for S in data_file_flow for C in data_file_flow[S]])\n",
    "    print(columns)\n",
    "    display_table(\n",
    "        [\n",
    "            dict(file=fn, **{c:rd.get(c,' ') for c in columns}) \n",
    "            for fn, rd in flow_table.items()\n",
    "        ]    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running R code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts written in R can be run from a Python program using `subprocess` and `Rscript`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Rscript`\n",
    "\n",
    "A script can be run from the commandline with\n",
    "\n",
    "    Rscript ascript.R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `subproces`\n",
    "\n",
    "[Python's `subprocess`module](https://docs.python.org/3.11/library/subprocess.html#) has the tools to execute external programs like `Rscript`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1] \"hello world\"\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subprocess.run(['Rscript',get_asset_path('hello.R')], capture_output=True).stdout.decode('UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sapflow prediction scripts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Data_preparation.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringer\n",
    "* zoo\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Data/Meta_data.csv`\n",
    "* `Data/Sapflux_Tilia_train.csv`\n",
    "* `Data/Weather_Tilia_train.csv`\n",
    "* `Data/Weather_Tilia_pred.csv`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Modelling_data.RData`\n",
    "* `Prediction_data.RData`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Data_preparation.R'] = {\n",
    "      \"in\": [\n",
    "         \"Data/Meta_data.csv\",\n",
    "         \"Data/Sapflux_Tilia_train.csv\",\n",
    "         \"Data/Weather_Tilia_train.csv\",\n",
    "         \"Data/Weather_Tilia_pred.csv\"\n",
    "      ],\n",
    "      \"out\": [\n",
    "         \"Modelling_data.RData\",\n",
    "         \"Prediction_data.RData\"\n",
    "      ],\n",
    "    'libs':['lubridate', 'stringr', 'zoo']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Prediction_part1.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringr\n",
    "* mgcv\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Modelling_data.RData`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Fitted_models.RData`\n",
    "* `Weights.RData`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Prediction_part1.R'] = {\n",
    "      \"in\": [\n",
    "         \"Modelling_data.RData\"\n",
    "      ],\n",
    "      \"out\": [\n",
    "         \"Fitted_models.RData\",\n",
    "         \"Weights.RData\"\n",
    "      ],\n",
    "    'libs':['lubridate', 'stringr', 'mgcv']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Prediction_part2.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringr\n",
    "* mgcv\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Fitted_models.RData`\n",
    "* `Weights.RData`\n",
    "* `Modelling_data.RData`\n",
    "* `Prediction_data.RData`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Predicted_sapflux.RData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Prediction_part2.R'] = {\n",
    "    \"in\":[\n",
    "        'Fitted_models.RData',\n",
    "        'Weights.RData',\n",
    "        'Modelling_data.RData',\n",
    "        'Prediction_data.RData'\n",
    "    ],\n",
    "    \"out\":[\n",
    "        'Predicted_sapflux.RData'\n",
    "    ],\n",
    "    'libs':['lubridate', 'stringr', 'mgcv']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Prediction_part3.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringr\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Predicted_sapflux.RData`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Predicted_water_usage.RData`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Prediction_part3.R'] = {\n",
    "    'in':['Predicted_sapflux.RData'],\n",
    "    'out':['Predicted_water_usage.RData'],\n",
    "    'libs':['lubridate', 'stringr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| data-file / script          | Data_preparation.R   | Prediction_part1.R   | Prediction_part2.R   | Prediction_part3.R   |\n",
       "|-----------------------------|----------------------|----------------------|----------------------|----------------------|\n",
       "| Meta_data.csv               | in                   | --                   | --                   | --                   |\n",
       "| Sapflux_Tilia_train.csv     | in                   | --                   | --                   | --                   |\n",
       "| Weather_Tilia_train.csv     | in                   | --                   | --                   | --                   |\n",
       "| Weather_Tilia_pred.csv      | in                   | --                   | --                   | --                   |\n",
       "| Modelling_data.RData        | out                  | in                   | in                   | --                   |\n",
       "| Prediction_data.RData       | out                  | --                   | in                   | --                   |\n",
       "| Fitted_models.RData         | --                   | out                  | in                   | --                   |\n",
       "| Weights.RData               | --                   | out                  | in                   | --                   |\n",
       "| Predicted_sapflux.RData     | --                   | --                   | out                  | in                   |\n",
       "| Predicted_water_usage.RData | --                   | --                   | --                   | out                  |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "script_order = dict(zip(data_file_flow.keys(), range(len(data_file_flow.keys()))))\n",
    "\n",
    "# add the name to the objects\n",
    "data_file_flow = {\n",
    "    script_order[k]:{**v, 'name':k}\n",
    "    for k,v in data_file_flow.items()\n",
    "}\n",
    "\n",
    "\n",
    "data_files = reduce(\n",
    "    lambda Y,X:Y if (X in Y) else [*Y,X],\n",
    "    [\n",
    "        f\n",
    "        for S,P in data_file_flow.items() # patterns\n",
    "        for D,F in P.items()\n",
    "        for f in F\n",
    "        if D in ['in','out']\n",
    "        \n",
    "    ],\n",
    "    []\n",
    ")\n",
    "display(Markdown(tabulate(\n",
    "    [\n",
    "        [F.split('/')[-1]]+[\n",
    "            'in' if F in P['in'] else 'out' if F in P['out'] else '--' \n",
    "            for S,P in data_file_flow.items()\n",
    "        ] \n",
    "        for F in data_files\n",
    "    ],\n",
    "    headers=['data-file / script'] + [I['name'] for I in data_file_flow.values()],\n",
    "    tablefmt='github'\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Meta_data.csv',\n",
       " 'Data/Sapflux_Tilia_train.csv',\n",
       " 'Data/Weather_Tilia_train.csv',\n",
       " 'Data/Weather_Tilia_pred.csv',\n",
       " 'Modelling_data.RData',\n",
       " 'Prediction_data.RData',\n",
       " 'Fitted_models.RData',\n",
       " 'Weights.RData',\n",
       " 'Predicted_sapflux.RData',\n",
       " 'Predicted_water_usage.RData']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import R libraries\n",
    "\n",
    "Importing libraries can be done with\n",
    "\n",
    "    Rscript -e 'install.packages(\"drat\", repos=\"https://cloud.r-project.org\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rscript (R) version 4.2.2 (2022-10-31)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(subprocess.run(['Rscript','--version', ], capture_output=True).stdout.decode('UTF-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['Rscript', '--version'], returncode=0, stdout=b'Rscript (R) version 4.2.2 (2022-10-31)\\n', stderr=b'')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['Rscript','--version', ], capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lubridate', 'stringr', 'zoo', 'mgcv']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([L for V in data_file_flow.values() for L in V['libs']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: nlme\n",
      "This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_script_result = subprocess.run(['Rscript','-e', \"library(mgcv)\"], capture_output=True)\n",
    "print(run_script_result.stderr.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "def install_R_package(pkg:str|list):\n",
    "    \"\"\"\n",
    "    Checks and if neccesary installs an R package\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pkg : str|list\n",
    "        name(s) of the package(s)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(pkg, str):\n",
    "        pkg = [pkg]\n",
    "\n",
    "    for pkg_i in pkg:\n",
    "        run_script_result = subprocess.run(['Rscript','-e', f\"library({pkg_i})\"], capture_output=True)\n",
    "        if run_script_result.returncode != 0:\n",
    "            print(f\"Installing {pkg_i}\")\n",
    "            run_script_result = subprocess.run(['Rscript','-e', f\"install.packages({pkg_i}, repos='https://cloud.r-project.org')\"], capture_output=True)\n",
    "        else:\n",
    "            print(f\"Library {pkg_i} already installed\")\n",
    "            \n",
    "        print(run_script_result.stderr.decode('UTF-8'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library lubridate already installed\n",
      "\n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "\n",
      "Library stringr already installed\n",
      "\n",
      "Library zoo already installed\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Library mgcv already installed\n",
      "Loading required package: nlme\n",
      "This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install_R_package(list(set([L for V in data_file_flow.values() for L in V['libs']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checksum calculation\n",
    "\n",
    "Each script has it's own set of input files and should be run to\n",
    "update it's output when either it's inputs have changed or it's \n",
    "expected output does not exist.\n",
    "\n",
    "We can check for filechanges using a hashing algorithm, for \n",
    "instance MD5 or SHA-256. These are available either in Python\n",
    "or from the commandline.\n",
    "\n",
    "Lets look at the commandline version of MD5, on linux this is\n",
    "`md5sum`, with the input file for the preparation stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   \"Data/Meta_data.csv\",\n",
      "   \"Data/Sapflux_Tilia_train.csv\",\n",
      "   \"Data/Weather_Tilia_train.csv\",\n",
      "   \"Data/Weather_Tilia_pred.csv\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data_file_flow[list(data_file_flow.keys())[0]]['in'], indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "md5sum will output hashes to stdout, which `subprocess.run` captures for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   \"Data/Meta_data.csv\",\n",
      "   \"Data/Sapflux_Tilia_train.csv\",\n",
      "   \"Data/Weather_Tilia_train.csv\",\n",
      "   \"Data/Weather_Tilia_pred.csv\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "flow_object_index = 0\n",
    "input_files = data_file_flow[flow_object_index]['in']\n",
    "\n",
    "print(json.dumps(input_files, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4bed61a77505bfd52032591d5c3a6050 *Data/Meta_data.csv\n",
      "6d705d98caa6618a4a990c3742c16564 *Data/Sapflux_Tilia_train.csv\n",
      "1232592f9488ce4fbb4ae11ba5be0349 *Data/Weather_Tilia_train.csv\n",
      "366dac1bf64003d1d08fca6121c036bd *Data/Weather_Tilia_pred.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "md5_encode_result = subprocess.run(\n",
    "    ['md5sum','-b']+\n",
    "    input_files, \n",
    "    cwd=save_dir,\n",
    "    capture_output=True)\n",
    "print(md5_encode_result.stdout.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to check the files we run it with the `-c` option and a file with the previously calculated checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = data_file_flow[flow_object_index]['name']\n",
    "\n",
    "checksum_file = get_save_path(f\"input-checksum-{script_name.split('.')[0]}\")\n",
    "with open(checksum_file, 'wt') as cf:\n",
    "    cf.write(md5_encode_result.stdout.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Meta_data.csv: OK\n",
      "Data/Sapflux_Tilia_train.csv: OK\n",
      "Data/Weather_Tilia_train.csv: OK\n",
      "Data/Weather_Tilia_pred.csv: OK\n",
      "\n",
      "Run returned code 0\n"
     ]
    }
   ],
   "source": [
    "md5_check_result = subprocess.run(\n",
    "    ['md5sum', '-c', checksum_file], \n",
    "    cwd=save_dir,\n",
    "    capture_output=True)\n",
    "print(md5_check_result.stdout.decode('UTF-8'))\n",
    "print(f\"Run returned code {md5_check_result.returncode}\")\n",
    "if md5_check_result.returncode:\n",
    "    print(md5_check_result.stderr.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had there been a change to a file it would have looked like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Meta_data.csv: OK\n",
      "Data/Sapflux_Tilia_train.csv: FAILED\n",
      "Data/Weather_Tilia_train.csv: OK\n",
      "Data/Weather_Tilia_pred.csv: OK\n",
      "\n",
      "Run returned code 1\n"
     ]
    }
   ],
   "source": [
    "md5_check_result = subprocess.run(\n",
    "    ['md5sum', '-c', checksum_file+'-modified'], \n",
    "    cwd=save_dir,\n",
    "    capture_output=True)\n",
    "print(md5_check_result.stdout.decode('UTF-8'))\n",
    "print(f\"Run returned code {md5_check_result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really need specifics, only the return code will\n",
    "do for our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking files\n",
    "\n",
    "\n",
    "#### Generating names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "def calc_hash_from_flowobject(flow_object:dict)->str:\n",
    "    return hashlib.md5(repr(flow_object).encode('UTF-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'da4b2413f6a22c19a8a7823e6564e746'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_hash_from_flowobject(data_file_flow[flow_object_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def check_script_inputs(flow_object:dict)->bool:\n",
    "    \"\"\" \n",
    "    Check if the input files for a script are up-to-date, returns True if up-to-date.\n",
    "    \"\"\"\n",
    "\n",
    "    checksum_file = get_save_path(f\"input-checksum-{calc_hash_from_flowobject(flow_object)}\")\n",
    "    md5_check_result = subprocess.run(\n",
    "        ['md5sum', '-c', checksum_file], \n",
    "        cwd=save_dir,\n",
    "        capture_output=True)\n",
    "    \n",
    "    return int(md5_check_result.returncode) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_script_inputs(data_file_flow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs\n",
    "The output is easily checked for existence with `isfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def check_script_output(flow_object:dict)->bool:\n",
    "    \"\"\" \n",
    "    Check if the output files for a script exist, returns True if they all exist.\n",
    "    \"\"\"\n",
    "\n",
    "    return all([\n",
    "        os.path.isfile(get_save_path(F)) \n",
    "        for F in flow_object['out']\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_script_output(data_file_flow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a script\n",
    "\n",
    "We need to run a script when either any of it's inputs have changed or any \n",
    "of it's outputs do not exist. Return True if a follow-up script should be \n",
    "executed, False if nothing changed or executing the script failed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "def run_script(flow_object):\n",
    "    \"\"\" Run a script in R \n",
    "        args:\n",
    "            flow_object: dict of flow object\n",
    "        returns:\n",
    "            bool: False if nothing has changed, or an update failed,\n",
    "                    and True if a follow-up script might need to be run\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if output exists and inputs have not changed and return False if \n",
    "    # output exists and inputs have not changed\n",
    "    if check_script_output(flow_object) and check_script_inputs(flow_object):\n",
    "        return False\n",
    "    \n",
    "    # Run script\n",
    "    run_script_result = subprocess.run(\n",
    "        ['Rscript', '--vanilla', get_asset_path(flow_object['name'])],\n",
    "        cwd=save_dir,\n",
    "        capture_output=True\n",
    "    )\n",
    "    \n",
    "    # check the return code\n",
    "    if run_script_result.returncode:\n",
    "        print(f\"Run returned code {run_script_result.returncode}\")\n",
    "        print('STDOUT------------\\n', run_script_result.stdout.decode('UTF-8'))\n",
    "        print('STDERR------------\\n', run_script_result.stderr.decode('UTF-8'))\n",
    "        return False\n",
    "    \n",
    "    # check the output\n",
    "    if not check_script_output(flow_object):\n",
    "        print(f\"Output not found for {flow_object['name']}\")\n",
    "        return False\n",
    "    \n",
    "    return check_script_output(flow_object)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corebridge.venv",
   "language": "python",
   "name": "corebridge.venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
