{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RScript-Bridge\n",
    "\n",
    "> Bridge between Stactics AICore framework and RScript prediction scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import addroot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json, os\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "from functools import reduce\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "#warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "assets_dir = os.path.join(os.path.abspath(os.getcwd()), 'assets', 'rscript')\n",
    "save_dir = os.path.join(os.path.abspath(os.getcwd()), 'saves', 'rscript')\n",
    "\n",
    "def get_asset_path(script_name): \n",
    "    return os.path.join(assets_dir, script_name)\n",
    "def get_save_path(datafile_name): \n",
    "    return os.path.join(save_dir, datafile_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def display_table(feature_dict):\n",
    "    display(Markdown(tabulate(\n",
    "      [[v for v in row.values()] for row in feature_dict],\n",
    "      headers=[k for k in feature_dict[0].keys()],\n",
    "        tablefmt='github'\n",
    "    )))\n",
    "data_file_flow = {}\n",
    "\n",
    "def display_flow_table(flow_table):\n",
    "    columns = set([C for S in data_file_flow for C in data_file_flow[S]])\n",
    "    print(columns)\n",
    "    display_table(\n",
    "        [\n",
    "            dict(file=fn, **{c:rd.get(c,' ') for c in columns}) \n",
    "            for fn, rd in flow_table.items()\n",
    "        ]    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running R code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts written in R can be run from a Python program using `subprocess` and `Rscript`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Rscript`\n",
    "\n",
    "A script can be run from the commandline with\n",
    "\n",
    "    Rscript ascript.R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `subproces'\n",
    "\n",
    "[Python's `subprocess`module](https://docs.python.org/3.11/library/subprocess.html#) has the tools to execute external programs like `Rscript`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1] \"hello world\"\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subprocess.run(['Rscript',get_asset_path('hello.R')], capture_output=True).stdout.decode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The  scripts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Data_preparation.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringer\n",
    "* zoo\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Data/Meta_data.csv`\n",
    "* `Data/Sapflux_Tilia_train.csv`\n",
    "* `Data/Weather_Tilia_train.csv`\n",
    "* `Data/Weather_Tilia_pred.csv`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Modelling_data.RData`\n",
    "* `Prediction_data.RData`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Data_preparation.R'] = {\n",
    "      \"in\": [\n",
    "         \"Data/Meta_data.csv\",\n",
    "         \"Data/Sapflux_Tilia_train.csv\",\n",
    "         \"Data/Weather_Tilia_train.csv\",\n",
    "         \"Data/Weather_Tilia_pred.csv\"\n",
    "      ],\n",
    "      \"out\": [\n",
    "         \"Modelling_data.RData\",\n",
    "         \"Prediction_data.RData\"\n",
    "      ],\n",
    "    'libs':['lubridate', 'stringr', 'zoo']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Prediction_part1.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringr\n",
    "* mgcv\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Modelling_data.RData`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Fitted_models.RData`\n",
    "* `Weights.RData`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Prediction_part1.R'] = {\n",
    "      \"in\": [\n",
    "         \"Modelling_data.RData\"\n",
    "      ],\n",
    "      \"out\": [\n",
    "         \"Fitted_models.RData\",\n",
    "         \"Weights.RData\"\n",
    "      ],\n",
    "    'libs':['lubridate', 'stringr', 'mgcv']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Prediction_part2.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringr\n",
    "* mgcv\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Fitted_models.RData`\n",
    "* `Weights.RData`\n",
    "* `Modelling_data.RData`\n",
    "* `Prediction_data.RData`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Predicted_sapflux.RData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Prediction_part2.R'] = {\n",
    "    \"in\":[\n",
    "        'Fitted_models.RData',\n",
    "        'Weights.RData',\n",
    "        'Modelling_data.RData',\n",
    "        'Prediction_data.RData'\n",
    "    ],\n",
    "    \"out\":[\n",
    "        'Predicted_sapflux.RData'\n",
    "    ],\n",
    "    'libs':['lubridate', 'stringr', 'mgcv']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Prediction_part3.R`\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "* lubridate\n",
    "* stringr\n",
    "\n",
    "#### Input\n",
    "\n",
    "* `Predicted_sapflux.RData`\n",
    "\n",
    "#### Output\n",
    "\n",
    "* `Predicted_water_usage.RData`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_flow['Prediction_part3.R'] = {\n",
    "    'in':['Predicted_sapflux.RData'],\n",
    "    'out':['Predicted_water_usage.RData'],\n",
    "    'libs':['lubridate', 'stringr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| data-file / script    | Data preparation.R   | Prediction part1.R   | Prediction part2.R   | Prediction part3.R   |\n",
       "|-----------------------|----------------------|----------------------|----------------------|----------------------|\n",
       "| Meta data             | in                   | --                   | --                   | --                   |\n",
       "| Sapflux Tilia train   | in                   | --                   | --                   | --                   |\n",
       "| Weather Tilia train   | in                   | --                   | --                   | --                   |\n",
       "| Weather Tilia pred    | in                   | --                   | --                   | --                   |\n",
       "| Modelling data        | out                  | in                   | in                   | --                   |\n",
       "| Prediction data       | out                  | --                   | in                   | --                   |\n",
       "| Fitted models         | --                   | out                  | in                   | --                   |\n",
       "| Weights               | --                   | out                  | in                   | --                   |\n",
       "| Predicted sapflux     | --                   | --                   | out                  | in                   |\n",
       "| Predicted water usage | --                   | --                   | --                   | out                  |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(json.dumps(data_file_flow, indent=3))\n",
    "#| hide\n",
    "script_order = dict(zip(data_file_flow.keys(), range(len(data_file_flow.keys()))))\n",
    "\n",
    "data_files = reduce(\n",
    "    lambda Y,X:Y if (X in Y) else [*Y,X],\n",
    "    [\n",
    "        f\n",
    "        for S,P in data_file_flow.items() # patterns\n",
    "        for D,F in P.items()\n",
    "        for f in F\n",
    "        if D in ['in','out']\n",
    "        \n",
    "    ],\n",
    "    []\n",
    ")\n",
    "display(Markdown(tabulate(\n",
    "    [\n",
    "        [F.split('.')[0].replace('_',' ').split('/')[-1]]+[\n",
    "            'in' if F in P['in'] else 'out' if F in P['out'] else '--' \n",
    "            for S,P in data_file_flow.items()\n",
    "        ] \n",
    "        for F in data_files\n",
    "    ],\n",
    "    headers=['data-file / script'] + [\n",
    "            C.replace('_',' ') for C in data_file_flow.keys()\n",
    "        ],\n",
    "    tablefmt='github'\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Meta_data.csv',\n",
       " 'Data/Sapflux_Tilia_train.csv',\n",
       " 'Data/Weather_Tilia_train.csv',\n",
       " 'Data/Weather_Tilia_pred.csv',\n",
       " 'Modelling_data.RData',\n",
       " 'Prediction_data.RData',\n",
       " 'Fitted_models.RData',\n",
       " 'Weights.RData',\n",
       " 'Predicted_sapflux.RData',\n",
       " 'Predicted_water_usage.RData']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import R libraries\n",
    "\n",
    "Importing libraries can be done with\n",
    "\n",
    "    Rscript -e 'install.packages(\"drat\", repos=\"https://cloud.r-project.org\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rscript (R) version 4.2.2 (2022-10-31)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(subprocess.run(['Rscript','--version', ], capture_output=True).stdout.decode('UTF-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['Rscript', '--version'], returncode=0, stdout=b'Rscript (R) version 4.2.2 (2022-10-31)\\n', stderr=b'')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['Rscript','--version', ], capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stringr', 'mgcv', 'zoo', 'lubridate']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([L for V in data_file_flow.values() for L in V['libs']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_script_result = subprocess.run(['Rscript','-e', \"install.packages('mgcv', repos='https://cloud.r-project.org')\"], capture_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/fenke/R/x86_64-suse-linux-gnu-library/4.2’\n",
      "(as ‘lib’ is unspecified)\n",
      "trying URL 'https://cloud.r-project.org/src/contrib/mgcv_1.9-1.tar.gz'\n",
      "Content type 'application/x-gzip' length 1083217 bytes (1.0 MB)\n",
      "==================================================\n",
      "downloaded 1.0 MB\n",
      "\n",
      "* installing *source* package ‘mgcv’ ...\n",
      "** package ‘mgcv’ successfully unpacked and MD5 sums checked\n",
      "** using staged installation\n",
      "** libs\n",
      "discrete.c: In function ‘CXWyd’:\n",
      "discrete.c:700:62: warning: unused variable ‘nrs’ [-Wunused-variable]\n",
      "   int n,*k,*ks,*m,*p,*ts,*dt,*qc,*nthreads,*cs,*rs,nx,nt,ncs,nrs,*ar_stop,*ar_row,*cy;\n",
      "                                                              ^~~\n",
      "discrete.c:700:49: warning: unused variable ‘rs’ [-Wunused-variable]\n",
      "   int n,*k,*ks,*m,*p,*ts,*dt,*qc,*nthreads,*cs,*rs,nx,nt,ncs,nrs,*ar_stop,*ar_row,*cy;\n",
      "                                                 ^~\n",
      "discrete.c:700:35: warning: unused variable ‘nthreads’ [-Wunused-variable]\n",
      "   int n,*k,*ks,*m,*p,*ts,*dt,*qc,*nthreads,*cs,*rs,nx,nt,ncs,nrs,*ar_stop,*ar_row,*cy;\n",
      "                                   ^~~~~~~~\n",
      "installing to /home/fenke/R/x86_64-suse-linux-gnu-library/4.2/00LOCK-mgcv/00new/mgcv/libs\n",
      "** R\n",
      "** data\n",
      "** inst\n",
      "** byte-compile and prepare package for lazy loading\n",
      "** help\n",
      "*** installing help indices\n",
      "** building package indices\n",
      "** testing if installed package can be loaded from temporary location\n",
      "** checking absolute paths in shared objects and dynamic libraries\n",
      "** testing if installed package can be loaded from final location\n",
      "** testing if installed package keeps a record of temporary installation path\n",
      "* DONE (mgcv)\n",
      "\n",
      "The downloaded source packages are in\n",
      "\t‘/tmp/RtmpUL3OW6/downloaded_packages’\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_script_result.stderr.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checksum\n",
    "\n",
    "Each script has it's own set of input files and should be run to\n",
    "update it's output when either it's inputs have changed or it's \n",
    "expected output does not exist.\n",
    "\n",
    "We can check for filechanges using a hashing algorithm, for \n",
    "instance MD5 or SHA-256. These are available either in Python\n",
    "or from the commandline.\n",
    "\n",
    "Lets look at the commandline version of MD5, on linux this is\n",
    "`md5sum`, with the input file for the preparation stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   \"Data/Meta_data.csv\",\n",
      "   \"Data/Sapflux_Tilia_train.csv\",\n",
      "   \"Data/Weather_Tilia_train.csv\",\n",
      "   \"Data/Weather_Tilia_pred.csv\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data_file_flow[list(data_file_flow.keys())[0]]['in'], indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "md5sum will output hashes to stdout, which `subprocess.run` captures for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Data_preparation'],\n",
       " ['Data/Meta_data.csv',\n",
       "  'Data/Sapflux_Tilia_train.csv',\n",
       "  'Data/Weather_Tilia_train.csv',\n",
       "  'Data/Weather_Tilia_pred.csv'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_name = list(data_file_flow.keys())[0]\n",
    "input_files = data_file_flow[script_name]['in']\n",
    "\n",
    "script_name.split('.')[0:-1], input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4bed61a77505bfd52032591d5c3a6050 *Data/Meta_data.csv\n",
      "6d705d98caa6618a4a990c3742c16564 *Data/Sapflux_Tilia_train.csv\n",
      "1232592f9488ce4fbb4ae11ba5be0349 *Data/Weather_Tilia_train.csv\n",
      "366dac1bf64003d1d08fca6121c036bd *Data/Weather_Tilia_pred.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "md5_encode_result = subprocess.run(\n",
    "    ['md5sum','-b']+\n",
    "    input_files, \n",
    "    cwd=save_dir,\n",
    "    capture_output=True)\n",
    "print(md5_encode_result.stdout.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to check the files we run it with the `-c` option and a file with the previously calculated checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksum_file = os.path.join(save_dir, f\"input-checksum-{script_name.split('.')[0]}\")\n",
    "with open(checksum_file, 'wt') as cf:\n",
    "    cf.write(md5_encode_result.stdout.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Meta_data.csv: OK\n",
      "Data/Sapflux_Tilia_train.csv: OK\n",
      "Data/Weather_Tilia_train.csv: OK\n",
      "Data/Weather_Tilia_pred.csv: OK\n",
      "\n",
      "Run returned code 0\n"
     ]
    }
   ],
   "source": [
    "md5_check_result = subprocess.run(\n",
    "    ['md5sum', '-c', checksum_file], \n",
    "    cwd=save_dir,\n",
    "    capture_output=True)\n",
    "print(md5_check_result.stdout.decode('UTF-8'))\n",
    "print(f\"Run returned code {md5_check_result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had there been a change to a file it would have looked like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run returned code 1\n"
     ]
    }
   ],
   "source": [
    "md5_check_result = subprocess.run(\n",
    "    ['md5sum', '-c', checksum_file+'-modified'], \n",
    "    cwd=save_dir,\n",
    "    capture_output=True)\n",
    "print(md5_check_result.stdout.decode('UTF-8'))\n",
    "print(f\"Run returned code {md5_check_result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really need specifics, only the return code will\n",
    "do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a script\n",
    "\n",
    "For each of the scripts we run the follwing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction_part1.R\n"
     ]
    }
   ],
   "source": [
    "script_name = list(data_file_flow.keys())[1]\n",
    "print(script_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = data_file_flow[script_name]['in']\n",
    "checksum_file = os.path.join(save_dir, f\"input-checksum-{script_name.split('.')[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "md5sum: /home/fenke/repos/corebridge/nbs/saves/rscript/input-checksum-Prediction_part1: No such file or directory\n",
      "\n",
      "Run returned code 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "md5_check_result = subprocess.run(\n",
    "    ['md5sum', '-c', checksum_file], \n",
    "    cwd=save_dir,\n",
    "    capture_output=True)\n",
    "\n",
    "print(md5_check_result.stdout.decode('UTF-8'))\n",
    "print(md5_check_result.stderr.decode('UTF-8'))\n",
    "\n",
    "print(f\"Run returned code {md5_check_result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run returned code 1\n",
      "STDOUT------------\n",
      " \n",
      "STDERR------------\n",
      " \n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "Loading required package: nlme\n",
      "This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n",
      "Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection\n",
      "Calls: load -> readChar\n",
      "In addition: Warning message:\n",
      "In readChar(con, 5L, useBytes = TRUE) :\n",
      "  cannot open compressed file 'Modelling_data.RData', probable reason 'No such file or directory'\n",
      "Execution halted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if md5_check_result.returncode:\n",
    "    run_script_result = subprocess.run(\n",
    "        ['Rscript', '--vanilla', get_asset_path(script_name)],\n",
    "        cwd=save_dir,\n",
    "        capture_output=True\n",
    "    )\n",
    "    print(f\"Run returned code {run_script_result.returncode}\")\n",
    "    print('STDOUT------------\\n', run_script_result.stdout.decode('UTF-8'))\n",
    "    print('STDERR------------\\n', run_script_result.stderr.decode('UTF-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libname = 'mgcv'\n",
    "test = subprocess.run(\n",
    "    ['Rscript', '-e', f\"library({libname})\"],capture_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: nlme\n",
      "This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test.stderr.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corebridge.venv",
   "language": "python",
   "name": "corebridge.venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
