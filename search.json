[
  {
    "objectID": "aicorebridge.html",
    "href": "aicorebridge.html",
    "title": "AICore-Bridge",
    "section": "",
    "text": "import json\nimport os\n\nfrom corebridge.timeseriesdataframe import test_data_dict_3_samples",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#support-functions",
    "href": "aicorebridge.html#support-functions",
    "title": "AICore-Bridge",
    "section": "Support functions",
    "text": "Support functions\n\nPop NaN values\n\n\n\npop_nan_values\n\ndef pop_nan_values(\n    data\n):\n\nRecursively pop keys with nan values from dict or lists with  dicts. Use just before handing data to AICore for further processing since it explodes when encountering NaN values.\nArgs: data (Union[list, dict]): The data to be processed.\nReturns: Union[list, dict]: The processed data with keys with nan values removed.\n\ntest_data_with_nan = test_data_dict_3_samples.copy() + [\n   {\n      \"time\":\"2023-05-04T11:44:53.000Z\",\n      \"value\":np.nan\n   }\n\n]\nprint(json.dumps(test_data_with_nan, indent=3))\n\n[\n   {\n      \"time\": \"2023-05-04T10:04:49.000Z\",\n      \"value\": 16.72\n   },\n   {\n      \"time\": \"2023-05-04T10:24:51.000Z\",\n      \"value\": 16.65\n   },\n   {\n      \"time\": \"2023-05-04T10:44:53.000Z\",\n      \"value\": 16.55\n   },\n   {\n      \"time\": \"2023-05-04T11:44:53.000Z\",\n      \"value\": NaN\n   }\n]\n\n\n\nprint(json.dumps(pop_nan_values(test_data_with_nan), indent=3))\n\n[\n   {\n      \"time\": \"2023-05-04T10:04:49.000Z\",\n      \"value\": 16.72\n   },\n   {\n      \"time\": \"2023-05-04T10:24:51.000Z\",\n      \"value\": 16.65\n   },\n   {\n      \"time\": \"2023-05-04T10:44:53.000Z\",\n      \"value\": 16.55\n   },\n   {\n      \"time\": \"2023-05-04T11:44:53.000Z\"\n   }\n]\n\n\n\n\nBuild historic args\n\n\n\nbuild_historic_args\n\ndef build_historic_args(\n    data:DataFrame, # The input time-series DataFrame.\n    history:dict | list, # Historic data definition, each item in the list is a dictionary with \na startDate key to set the start of a section of historic data in the \nresult and a column-value pair for each of the columns.\n)-&gt;dict: # Historic data in dictionary format where keys are column names and \nvalues are the historic values as numpy array.\n\nCreate a timeseries DataFrame from historic data defined in history.\n\ntest_data=set_time_index_zone(timeseries_dataframe_from_datadict(\n   [\n      {\n         \"time\":\"2023-05-04T10:04:49\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51\",\n         \"value\":16.65\n      }\n   ], ['datetimeMeasure', 'time'], 'records'), 'UTC').sort_index()\n\n\ntest_data\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\nhistory_arg = [\n                dict(justANumber=1.0),\n                dict(startDate=\"2023-05-04T10:25:00+00:00\", justANumber=2.0)\n            ]\nbuild_historic_args(test_data,history_arg)\n\n\n\n\n\n\n\n\njustANumber\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n1.0\n\n\n2023-05-04 10:24:51+00:00\n1.0\n\n\n2023-05-04 10:44:53+00:00\n2.0\n\n\n\n\n\n\n\n\nassert len(test_data) == len(build_historic_args(test_data,history_arg)['justANumber']), \"build_historic_args failed to build historic data\"",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#class-aicoremodulebase",
    "href": "aicorebridge.html#class-aicoremodulebase",
    "title": "AICore-Bridge",
    "section": "Class AICoreModuleBase",
    "text": "Class AICoreModuleBase\nIn the third iteration of the AICore module the initializer signature changes from\n    def __init__(\n        self, \n        save_dir:str, # path where the module can keep files \n        assets_dir:str, # path to support files (scripts, metadata, etc)\n        *args, **kwargs\n    ):\nto the almost identical signature\n\n    def __init__(\n        self, \n        files_dir, \n        save_dir\n    ):\nNote how the order of the folder arguments is reversed. We can adapt by\n\ntreating original assets_dir as save_dir and vice versa OR\nrewrite the method to match the new signature and change the signatures of the derived classes in each module\n\n\n\nAICoreModuleBase\n\ndef AICoreModuleBase(\n    files_dir, save_dir, kwargs:VAR_KEYWORD\n):\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nExported source\nclass AICoreModuleBase:\n\n    def __init__(\n        self, \n        files_dir, \n        save_dir,\n        **kwargs\n    ):\n        \n        self.init_time = datetime.datetime.now(datetime.UTC)\n        self.aicorebridge_version = __version__\n\n        self.init_args = []\n        self.init_kwargs = dict(\n            files_dir=files_dir,\n            save_dir=save_dir,\n            **kwargs\n        )\n\n\n        syslog.info(f\"Init {self.__class__.__name__}, version {self.aicorebridge_version}, files directory {files_dir}, save dir {save_dir} on {platform.node()}\")\n\n\n\nsave_dir = os.path.join(os.getcwd(), 'cache')\nfiles_dir = os.path.join(os.getcwd(), 'cache')\ntest_module = AICoreModuleBase(files_dir, save_dir)\n\nassert test_module.init_kwargs['save_dir'] == save_dir, f\"init_kwargs['save_dir'] should be {save_dir}\"\nassert test_module.init_kwargs['files_dir'] == files_dir, f\"init_kwargs['files_dir'] should be {files_dir}\"\n\n2026-01-29T14:38:35+0100 INFO   8596    __main__    2001759155.py   __init__    22  Init AICoreModuleBase, version 0.6.6, files directory c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache, save dir c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache on werkdoos\n\n\n\ntest_module.__dict__\n\n{'init_time': datetime.datetime(2026, 1, 29, 13, 38, 35, 902376, tzinfo=datetime.timezone.utc),\n 'aicorebridge_version': '0.6.6',\n 'init_args': [],\n 'init_kwargs': {'files_dir': 'c:\\\\Users\\\\fenke\\\\repos\\\\corebridge\\\\nbs\\\\cache',\n  'save_dir': 'c:\\\\Users\\\\fenke\\\\repos\\\\corebridge\\\\nbs\\\\cache'}}",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#class-aicoremodule",
    "href": "aicorebridge.html#class-aicoremodule",
    "title": "AICore-Bridge",
    "section": "Class AICoreModule",
    "text": "Class AICoreModule\n\n\nAICoreModule\n\ndef AICoreModule(\n    processor:Callable, # data processing function\n    files_dir:str, # path where the module can keep files\n    save_dir:str, kwargs:VAR_KEYWORD\n):\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nExported source\nclass AICoreModule(AICoreModuleBase):\n    def __init__(self, \n        processor:typing.Callable, # data processing function\n        files_dir:str,              # path where the module can keep files \n        save_dir:str,\n        **kwargs\n    ):\n    \n        super().__init__(files_dir, save_dir, **kwargs)\n        self._init_processor(processor)\n\n\n\n\n\nAICoreModule.call_processor\n\ndef call_processor(\n    calldata, callargs:VAR_KEYWORD\n):\n\n\n\nExported source\n# TODO: Refactor into Processor classes to handle different funtion types\n\n@patch\ndef _init_processor(\n        self:AICoreModule, \n        processor:typing.Callable):\n    \"\"\"Initializes processor related variables on self\"\"\"\n    \n    self.processor = processor\n    self.processor_signature = inspect.signature(self.processor)\n    self.processor_params = dict(self.processor_signature.parameters)\n    self.return_param = self.processor_params.pop('return', None)\n    \n    self.data_param, *self.call_params = list(self.processor_params.keys())\n\n    if not (\n        self.processor_params[self.data_param].annotation == pd.DataFrame\n        or self.processor_params[self.data_param].annotation == np.ndarray\n\n    ):\n\n        self.data_param = None\n        self.call_params = list(self.processor_params.keys())\n\n\n\n\nExported source\n# can be overloaded\n@patch\ndef call_processor(self:AICoreModule, calldata, **callargs):\n    if self.data_param:\n        return self.processor(calldata, **callargs)\n    else:\n        return self.processor(**callargs)\n\n\n\n\ncall\nThe new entry point from AICore with the following signature\ndef call(self, data, files)\nThis method, originally called by earlier versions of AICore, is responsible for processing the data and parameters request recieved by AICore. Infer takes a data parameter which contains the contents of the data key in the request body. Additionally an optional list of files that were send with the request - these are currently ignored - and finally the contents of the kwargs key in the request body.\n\n\n\nAICoreModule.call\n\ndef call(\n    data:dict, _:VAR_POSITIONAL, __:VAR_KEYWORD\n):\n\nInfer the data using the processor function.\n\n\nExported source\n@patch\ndef call(self:AICoreModule, data:dict, *_, **__):\n    \"\"\"Infer the data using the processor function.\"\"\"\n\n    payload_data = data\n\n    msg=[\n        f\"Startup time: {self.init_time.isoformat()}, node {platform.node()}\",\n        f\"Call time: {datetime.datetime.now(datetime.UTC).isoformat()}\",\n        f\"Python version: {sys.version}\",\n        f\"Corebridge version: {self.aicorebridge_version}\",\n        f\"CPU times: {', '.join([f'{k}: {v}' for k, v in psutil.cpu_times_percent()._asdict().items() ])}\",\n        f\"Memory: {', '.join([f'{k}: {v}' for k, v in psutil.virtual_memory()._asdict().items() ])}\",\n\n    ]\n\n    try:\n        t00 = time.perf_counter_ns()\n\n        kwargs = payload_data.get('kwargs', {})\n        data = payload_data.get('data', {})\n\n        msg+=[\n            f\"{self.processor.__name__}({self.processor_signature})\",  \n            f\"Data: {type(data)} length: {len(data)}\",    \n            f\"kwargs {list(kwargs.keys())}\",  \n            #f\"init_args: {self.init_args}, init_kwargs: {self.init_kwargs}\",\n        ]\n\n        # Pickup params, pop those that are not intended for the processor\n        lastSeen = kwargs.pop('lastSeen', False)\n        recordformat = kwargs.pop('format', \"records\").lower()\n        timezone = kwargs.get('timezone', 'UTC')\n        nested = kwargs.pop('nested', False)\n        msg.append(f\"lastSeen: {lastSeen}, timezone: {timezone}, recordformat: {recordformat}, nested: {nested}\")\n\n        samplerPeriod = kwargs.pop('samplerPeriod', self.init_kwargs.get('samplerPeriod','h'))\n        samplerMethod = kwargs.pop('samplerMethod', self.init_kwargs.get('samplerMethod',None))\n        reversed = kwargs.pop('reversed', False)\n\n        calldata = self.get_call_data(\n            data, \n            recordformat=recordformat,\n            timezone=timezone,\n            nested=nested,)\n        \n        history = build_historic_args(calldata, kwargs.pop('history', {}))\n        callargs = self.get_callargs(kwargs, history)\n\n        # for arg, val in callargs.items():\n        #     msg.append(f\"{arg}: {val}\")\n        \n        t02 = time.perf_counter_ns()\n        calculated_result = self.call_processor(\n            calldata, \n            **callargs\n        )\n        t03 = time.perf_counter_ns()\n        msg.append(f\"Processing time: {(t03-t02)/1e6:.1f} ms\")\n        msg.append(f\"Preparation time: {(t02-t00)/1e6:.1f} ms\")\n\n        if isinstance(calculated_result, dict):\n            msg.append(f\"return-data ictionary keys: {calculated_result.keys()}\")\n            return {\n                'msg':msg,\n                'data': [calculated_result]\n            }\n        elif isinstance(calculated_result, list):\n            msg.append(f\"return-data list length: {len(calculated_result)}\")\n            return {\n                'msg':msg,\n                'data': calculated_result\n            }\n\n        try:\n            result = timeseries_dataframe(\n                calculated_result, \n                timezone=timezone)\n            \n            msg.append(f\"result shape: {result.shape}\")\n\n            if samplerMethod:\n                msg.append(f\"Sampler: {samplerMethod}, period: {samplerPeriod}\")\n                result = timeseries_dataframe_resample(result, samplerPeriod, samplerMethod)\n\n            msg.append(f\"return-data shape: {result.shape}\")\n\n            if reversed:\n                result = result[::-1]\n\n            return {\n                'msg':msg,\n                'data': pop_nan_values( timeseries_dataframe_to_datadict(\n                    result if not lastSeen else result[-1:],\n                    recordformat=recordformat,\n                    timezone=timezone))\n            }\n        \n        # tries dataframe return\n        except Exception as err:\n            msg.append(f\"No timeseries data, error={err}\")\n        \n        df = pd.DataFrame(calculated_result)\n        df\n        df.columns = [f\"value_{str(c)}\" if isinstance(c, int) else str(c) for c in list(df.columns)]\n        df.reset_index().to_dict(orient='records')\n        return {\n            'msg':msg,\n            'data': pop_nan_values( df.reset_index().to_dict(orient='records') )\n        }\n\n    \n    # function try-catch\n    except Exception as err:\n        msg.append(''.join(traceback.format_exception(None, err, err.__traceback__)))\n        return {\n            'msg': msg,\n            'data': []\n        }\n\n\n\n\nget_callargs\n\n\nExported source\n# Specialized types for initializing annotated parameters\n# Add types by adding a tuple with the type name and a builder function\nannotated_arg_builders = {\n    str(B[0]):B[1] for B in [\n        (np.ndarray, lambda X: np.array(X, dtype=X.dtype))\n    ]\n}\n\n\n\nannotated_arg_builders\n\n{\"&lt;class 'numpy.ndarray'&gt;\": &lt;function __main__.&lt;lambda&gt;(X)&gt;}\n\n\n\n\n\nAICoreModule.init_annotated_param\n\ndef init_annotated_param(\n    param_name, value\n):\n\nInitialize argument for the processor call\nparam_name: name of the parameter to be initialized value: value of the parameter read from infer data to be used for initialization\n\n\nExported source\n@patch\ndef init_annotated_param(self:AICoreModule, param_name, value):\n    \"\"\"\n    Initialize argument for the processor call\n    \n    param_name: name of the parameter to be initialized\n    value: value of the parameter read from infer data to be used for initialization\n    \n    \"\"\"\n\n    annotation = self.processor_signature.parameters[param_name].annotation\n    #print(f\"param_name: {param_name}, value: {value}, annotation: {annotation}\")\n\n    # try to convert value to one of the types in the builders of annotated_arg_builders\n    for T in typing.get_args(annotation):\n        try:\n            builder = annotated_arg_builders.get(str(T), lambda X:T(X))\n            return builder(value)\n        \n        except TypeError:\n            continue\n\n    try:\n        return annotation(value)\n    \n    except TypeError as err:\n        syslog.exception(f\"Exception {str(err)} in fallback conversion to {annotation} of {type(value)}\")\n\n\n\n\n\nAICoreModule.get_callargs\n\ndef get_callargs(\n    kwargs, history\n):\n\nGet arguments for the processor call\n\n\nExported source\n@patch\ndef get_callargs(self:AICoreModule, kwargs, history):\n    \"Get arguments for the processor call\"\n\n    # Remove null / None values\n    kwargs = {k:v for k,v in kwargs.items() if v is not None}\n    \n    call_args = {\n        K:self.init_annotated_param(\n            K,\n            history.get(\n                K,\n                kwargs.get(\n                    K,\n                    self.init_kwargs.get(\n                        K, \n                        history.get(\n                            snake_case_to_camel_case(K),\n                            kwargs.get(\n                                snake_case_to_camel_case(K),\n                                self.init_kwargs.get(\n                                    snake_case_to_camel_case(K), \n                                    self.processor_signature.parameters[K].default\n                                )\n                            )\n                        )\n                    )\n                )\n            )\n        )\n        for K in self.call_params\n    }\n\n    return call_args\n\n\n\ndef processor_function(data:pd.DataFrame, just_a_number:float|np.ndarray):\n    return just_a_number * data\n\ntest_module = AICoreModule(processor_function, os.path.join(os.getcwd(), 'cache'), os.path.join(os.getcwd(), 'cache'))\nassert 'just_a_number' in test_module.get_callargs(\n    {\n        'justANumber': 2\n    },\n    {}\n   \n), \"get_callargs failed to translate camel-case processor argument to snake-case kwargs argument\"\n\n2026-01-29T14:38:35+0100 INFO   8596    __main__    2001759155.py   __init__    22  Init AICoreModule, version 0.6.6, files directory c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache, save dir c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache on werkdoos\n\n\n\n\nget_call_data\n\n\n\nAICoreModule.get_call_data\n\ndef get_call_data(\n    data:dict | list, recordformat:str='records', timezone:str='UTC', nested:bool=False\n):\n\nConvert data to the processor signature\n\n\nExported source\n@patch\ndef get_call_data(\n        self:AICoreModule, \n        data:dict|list, \n        recordformat='records', \n        timezone='UTC',\n        nested=False):\n    \n    \"Convert data to the processor signature\"\n    \n    if not self.data_param:\n        return None\n    \n    #print(f\"recordformat: {recordformat}, timezone: {timezone}, nested: {nested}\" )\n\n    df = set_time_index_zone(timeseries_dataframe_from_datadict(\n        data, ['datetimeMeasure', 'time'], recordformat=recordformat, nested=nested), timezone)\n\n    df.sort_index(inplace=True)\n\n    if self.processor_params[self.data_param].annotation == pd.DataFrame:\n        return df\n    elif len(df.columns) &gt; 1:\n        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)\n        return df.to_records(index=True)\n    else:\n        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)\n        return df.reset_index().to_numpy()\n\n\n\ntest_data\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(test_data)\n\n[{'time': '2023-05-04T10:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55}]\n\n\n\ncalldata = test_module.get_call_data(timeseries_dataframe_to_datadict(test_data))\ncalldata\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\nhistory = build_historic_args(calldata,history_arg)\nhistory\n\n\n\n\n\n\n\n\njustANumber\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n2.0\n\n\n2023-05-04 10:24:51+00:00\n2.0\n\n\n2023-05-04 10:44:53+00:00\n2.0\n\n\n\n\n\n\n\n\ncalldata\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\nprint(test_module.get_callargs(calldata, history))\n\n{'just_a_number': array([2., 2., 2.])}\n\n\n\nnp.array(history['justANumber'])\n\narray([2., 2., 2.])\n\n\n\nhistory\n\n\n\n\n\n\n\n\njustANumber\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n2.0\n\n\n2023-05-04 10:24:51+00:00\n2.0\n\n\n2023-05-04 10:44:53+00:00\n2.0\n\n\n\n\n\n\n\n\ntest_module.init_annotated_param(\n    'just_a_number',\n    12.34\n)\n\n12.34\n\n\n\ntest_module.processor_signature.parameters['just_a_number'].annotation\n\nfloat | numpy.ndarray\n\n\n\nnp.array(history['justANumber'])\n\narray([2., 2., 2.])\n\n\n\nannotated_arg_builders[str(np.ndarray)](history['justANumber'])\n\narray([2., 2., 2.])\n\n\n\nassert True, 'stop'",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#dynamic-module-class",
    "href": "aicorebridge.html#dynamic-module-class",
    "title": "AICore-Bridge",
    "section": "Dynamic Module Class",
    "text": "Dynamic Module Class\nUntil now every time Univia changed their AICore framework, we had to modify the AICoreModule class for the module. By letting a class factory handle the class creation - class, not object creation - we can avoid ging through evey module and changing it, however little work this appears to be.\n\n\ncreate_basic_module_class\n\ndef create_basic_module_class(\n    processing_function, class_name:str='Module'\n):",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#tests",
    "href": "aicorebridge.html#tests",
    "title": "AICore-Bridge",
    "section": "Tests",
    "text": "Tests\n\nimport os, pandas as pd, numpy as np\n\n\ndef test_function(data:pd.DataFrame, anumber:float|np.ndarray=0):\n    return data * anumber\n\n\ndef test_simple_function(anumber:float, another:float):\n    return [another * anumber]\n\n\nModule = create_basic_module_class(test_function)\n# class TestAICoreModule(AICoreModule):\n#     def __init__(self, files_dir, save_dir):\n#         super().__init__(test_function, files_dir, save_dir)\n\n2026-01-29T14:38:36+0100 INFO   8596    __main__    3690511148.py   create_basic_module_class   4   create_basic_module_class(test_function, Module)\n\n\n\nSimpleAICoreModule = create_basic_module_class(test_simple_function, \"SimpleAICoreModule\")\n\n# class SimpleAICoreModule(AICoreModule):\n#     def __init__(self, files_dir, save_dir):\n#         super().__init__(test_simple_function, files_dir, save_dir)\n\n2026-01-29T14:38:36+0100 INFO   8596    __main__    3690511148.py   create_basic_module_class   4   create_basic_module_class(test_simple_function, SimpleAICoreModule)\n\n\n\nsave_dir = os.path.join(os.getcwd(), 'cache')\nfiles_dir = os.path.join(os.getcwd(), 'cache')\n\ntest_module = Module(files_dir, save_dir)\n\nassert test_module.init_kwargs['save_dir'] == save_dir, f\"init_kwargs['save_dir'] should be {save_dir}\"\nassert test_module.init_kwargs['files_dir'] == files_dir, f\"init_kwargs['files_dir'] should be {files_dir}\"\n\n2026-01-29T14:38:36+0100 INFO   8596    __main__    2001759155.py   __init__    22  Init Module, version 0.6.6, files directory c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache, save dir c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache on werkdoos\n\n\n\ntest_data = [\n    dict(datetimeMeasure='2020-04-01T00:01:11.123Z', value=1.1),\n    dict(datetimeMeasure='2020-04-02T00:20:00Z', value=2.3),\n]\nresult = test_module.call(dict(data=test_data, kwargs=dict(timezone='Europe/Amsterdam', anumber=2)))\n\nprint(\"Test Data\\n\", json.dumps(test_data, indent=2))\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2, cls=NumpyEncoder))\n\nTest Data\n [\n  {\n    \"datetimeMeasure\": \"2020-04-01T00:01:11.123Z\",\n    \"value\": 1.1\n  },\n  {\n    \"datetimeMeasure\": \"2020-04-02T00:20:00Z\",\n    \"value\": 2.3\n  }\n]\nResult Message\n [\n  \"Startup time: 2026-01-29T13:38:36.210166+00:00, node werkdoos\",\n  \"Call time: 2026-01-29T13:38:36.225219+00:00\",\n  \"Python version: 3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\",\n  \"Corebridge version: 0.6.6\",\n  \"CPU times: user: 6.0, system: 3.5, idle: 90.0, interrupt: 0.3, dpc: 0.2\",\n  \"Memory: total: 68425105408, available: 54549725184, percent: 20.3, used: 13875380224, free: 54549725184\",\n  \"test_function((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 2\",\n  \"kwargs ['timezone', 'anumber']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.2 ms\",\n  \"Preparation time: 110.8 ms\",\n  \"result shape: (2, 1)\",\n  \"return-data shape: (2, 1)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2020-04-01T02:01:11.123+02:00\",\n    \"value\": 2.2\n  },\n  {\n    \"time\": \"2020-04-02T02:20:00.000+02:00\",\n    \"value\": 4.6\n  }\n]\n\n\n\ntest_module.processor_signature.parameters['data'].annotation\n\npandas.core.frame.DataFrame\n\n\n\nannotation = test_module.processor_signature.parameters['anumber'].annotation\nprint(typing.get_args(annotation))\n\n(&lt;class 'float'&gt;, &lt;class 'numpy.ndarray'&gt;)\n\n\n\nfor T in typing.get_args(annotation):\n    print(T(0))\n\n0.0\n[]\n\n\n\nSimple module\n\nsimple_module = SimpleAICoreModule(files_dir,save_dir)\n\nassert simple_module.init_kwargs['save_dir'] == save_dir\n\n2026-01-29T14:38:36+0100 INFO   8596    __main__    2001759155.py   __init__    22  Init SimpleAICoreModule, version 0.6.6, files directory c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache, save dir c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache on werkdoos\n\n\n\nnot simple_module.data_param\n\nTrue\n\n\n\nsimple_module.call_params\n\n['anumber', 'another']\n\n\n\nresult = simple_module.call(dict(data=[], kwargs=dict(timezone='Europe/Amsterdam', anumber=2, another=11))) #dict(data=[], kwargs=dict(timezone='Europe/Amsterdam', anumber=2, another=11)\n\n\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2))\n\nResult Message\n [\n  \"Startup time: 2026-01-29T13:38:36.402453+00:00, node werkdoos\",\n  \"Call time: 2026-01-29T13:38:36.435320+00:00\",\n  \"Python version: 3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\",\n  \"Corebridge version: 0.6.6\",\n  \"CPU times: user: 18.4, system: 10.1, idle: 70.3, interrupt: 0.6, dpc: 0.6\",\n  \"Memory: total: 68425105408, available: 54538469376, percent: 20.3, used: 13886636032, free: 54538469376\",\n  \"test_simple_function((anumber: float, another: float))\",\n  \"Data: &lt;class 'list'&gt; length: 0\",\n  \"kwargs ['timezone', 'anumber', 'another']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.0 ms\",\n  \"Preparation time: 0.1 ms\",\n  \"return-data list length: 1\"\n]\nResult Data\n [\n  22.0\n]\n\n\n\n\nTests with library module\n\nfrom corebridge.aicorebridge import AICoreModule, create_basic_module_class\n\n2026-01-29T13:48:09+0000 INFO   2393    corebridge.aicorebridge core.py init_console_logging    53  Installed &lt;StreamHandler (INFO)&gt; for corebridge.aicorebridge\n2026-01-29T13:48:09+0000 INFO   2393    corebridge.aicorebridge aicorebridge.py &lt;module&gt;    35  Loading corebridge.aicorebridge 0.6.6 from /home/runner/work/corebridge/corebridge/corebridge/aicorebridge.py\n\n\n\nTestAICoreModule = create_basic_module_class(test_function, \"CreateTestAICoreModule\")\n# class TestAICoreModule(AICoreModule):\n#     def __init__(self, files_dir, save_dir):\n#         super().__init__(test_function, files_dir, save_dir)\n        \ntest_module = TestAICoreModule(files_dir, save_dir)\n\nassert test_module.init_kwargs['save_dir'] == save_dir\nassert test_module.init_kwargs['files_dir'] == files_dir\n\n2026-01-29T14:38:36+0100 INFO   8596    corebridge.aicorebridge aicorebridge.py create_basic_module_class   421 create_basic_module_class(test_function, CreateTestAICoreModule)\n2026-01-29T14:38:36+0100 INFO   8596    corebridge.aicorebridge aicorebridge.py __init__    135 Init CreateTestAICoreModule, version 0.6.6, files directory c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache, save dir c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache on werkdoos\n\n\n\ntest_data = [\n    dict(datetimeMeasure='2020-04-01T00:01:11.123Z', value=1.1),\n    dict(datetimeMeasure='2020-04-02T00:20:00Z', value=2.3),\n]\nresult = test_module.call(dict(data=test_data, kwargs=dict(timezone='Europe/Amsterdam', anumber=2)))\n\nprint(\"Test Data\\n\", json.dumps(test_data, indent=2))\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2, cls=NumpyEncoder))\n\nTest Data\n [\n  {\n    \"datetimeMeasure\": \"2020-04-01T00:01:11.123Z\",\n    \"value\": 1.1\n  },\n  {\n    \"datetimeMeasure\": \"2020-04-02T00:20:00Z\",\n    \"value\": 2.3\n  }\n]\nResult Message\n [\n  \"Startup time: 2026-01-29T13:38:36.467584+00:00, node werkdoos\",\n  \"Call time: 2026-01-29T13:38:36.478068+00:00\",\n  \"Corebridge version: 0.6.6\",\n  \"CPU times: user: 10.9, system: 9.4, idle: 35.9, interrupt: 1.6, dpc: 0.0\",\n  \"Memory: total: 68425105408, available: 54537240576, percent: 20.3, used: 13887864832, free: 54537240576\",\n  \"test_function((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 2\",\n  \"kwargs ['timezone', 'anumber']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.1 ms\",\n  \"Preparation time: 1.7 ms\",\n  \"result shape: (2, 1)\",\n  \"return-data shape: (2, 1)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2020-04-01T02:01:11.123+02:00\",\n    \"value\": 2.2\n  },\n  {\n    \"time\": \"2020-04-02T02:20:00.000+02:00\",\n    \"value\": 4.6\n  }\n]\n\n\n\nprint(\"Test Data\\n\", json.dumps(test_data, indent=2))\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2, cls=NumpyEncoder))\n\nTest Data\n [\n  {\n    \"datetimeMeasure\": \"2020-04-01T00:01:11.123Z\",\n    \"value\": 1.1\n  },\n  {\n    \"datetimeMeasure\": \"2020-04-02T00:20:00Z\",\n    \"value\": 2.3\n  }\n]\nResult Message\n [\n  \"Startup time: 2026-01-29T13:38:36.467584+00:00, node werkdoos\",\n  \"Call time: 2026-01-29T13:38:36.478068+00:00\",\n  \"Corebridge version: 0.6.6\",\n  \"CPU times: user: 10.9, system: 9.4, idle: 35.9, interrupt: 1.6, dpc: 0.0\",\n  \"Memory: total: 68425105408, available: 54537240576, percent: 20.3, used: 13887864832, free: 54537240576\",\n  \"test_function((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 2\",\n  \"kwargs ['timezone', 'anumber']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.1 ms\",\n  \"Preparation time: 1.7 ms\",\n  \"result shape: (2, 1)\",\n  \"return-data shape: (2, 1)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2020-04-01T02:01:11.123+02:00\",\n    \"value\": 2.2\n  },\n  {\n    \"time\": \"2020-04-02T02:20:00.000+02:00\",\n    \"value\": 4.6\n  }\n]",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#various-experiments",
    "href": "aicorebridge.html#various-experiments",
    "title": "AICore-Bridge",
    "section": "Various experiments",
    "text": "Various experiments\n\nimport json\n\n\ntest_nested_data = json.loads(\"\"\"\n[\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:46:33.313Z\",\n        \"datetimeSource\": \"2025-07-21T09:46:33.313Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:46:33.691Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b4613d2ab820ec21e42a912a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": 0,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": 0,\n                        \"location\": {\n                            \"latitude\": 51.556896,\n                            \"longitude\": 5.865362\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1319,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:36:33.332Z\",\n        \"datetimeSource\": \"2025-07-21T09:36:33.332Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:36:33.697Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d0174603d2a9e20bf21dc2a802a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -104,\n                \"snr\": 5,\n                \"spreadingFactor\": 11,\n                \"frequency\": 867.3,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -104,\n                        \"snr\": 5,\n                        \"location\": {\n                            \"latitude\": 51.5569,\n                            \"longitude\": 5.865385\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1318,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:26:33.350Z\",\n        \"datetimeSource\": \"2025-07-21T09:26:33.350Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:26:33.705Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b45e3d2aa120ad21d42a5d2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -105,\n                \"snr\": 9,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.5,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -105,\n                        \"snr\": 9,\n                        \"location\": {\n                            \"latitude\": 51.556892,\n                            \"longitude\": 5.865356\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1317,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:16:33.368Z\",\n        \"datetimeSource\": \"2025-07-21T09:16:33.368Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:16:33.734Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01745d3d2ac320a621d12a5b2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -109,\n                \"snr\": 2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 866.6,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -109,\n                        \"snr\": 2,\n                        \"location\": {\n                            \"latitude\": 51.556892,\n                            \"longitude\": 5.865359\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1316,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:06:33.386Z\",\n        \"datetimeSource\": \"2025-07-21T09:06:33.386Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:06:33.748Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01345c3d2aa920b821d02a612a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": -2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.5,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": -2,\n                        \"location\": {\n                            \"latitude\": 51.556858,\n                            \"longitude\": 5.865352\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1315,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:56:33.405Z\",\n        \"datetimeSource\": \"2025-07-21T08:56:33.405Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:56:33.754Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01f45a3d2aa020c821d22a7d2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -115,\n                \"snr\": -6.25,\n                \"spreadingFactor\": 11,\n                \"frequency\": 866.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF010323\",\n                        \"rssi\": -115,\n                        \"snr\": -6.25,\n                        \"location\": {\n                            \"latitude\": 51.516491,\n                            \"longitude\": 5.884403\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1314,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:46:33.423Z\",\n        \"datetimeSource\": \"2025-07-21T08:46:33.423Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:46:33.778Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b4593d2ab920d121cf2a922a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": 8,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.5,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": 8,\n                        \"location\": {\n                            \"latitude\": 51.556862,\n                            \"longitude\": 5.865373\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1313,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:36:33.441Z\",\n        \"datetimeSource\": \"2025-07-21T08:36:33.441Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:36:33.821Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d0174583d2ac020e221cb2ada2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": 2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 866.4,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": 2,\n                        \"location\": {\n                            \"latitude\": 51.55687,\n                            \"longitude\": 5.86535\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1312,\n                \"counterDown\": 26,\n                \"errorRate\": 6\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:26:33.460Z\",\n        \"datetimeSource\": \"2025-07-21T08:26:33.460Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:26:33.810Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b4563d2aa220db21c72aba2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -103,\n                \"snr\": -2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -103,\n                        \"snr\": -2,\n                        \"location\": {\n                            \"latitude\": 51.556854,\n                            \"longitude\": 5.865371\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1311,\n                \"counterDown\": 26,\n                \"errorRate\": 6\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:16:33.560Z\",\n        \"datetimeSource\": \"2025-07-21T08:16:33.560Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:16:33.962Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d0174553d2ac220d821c52ad92a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -104,\n                \"snr\": -7,\n                \"spreadingFactor\": 11,\n                \"frequency\": 865.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -104,\n                        \"snr\": -7,\n                        \"location\": {\n                            \"latitude\": 51.556866,\n                            \"longitude\": 5.865384\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1310,\n                \"counterDown\": 26,\n                \"errorRate\": 6\n            }\n        }\n    }\n]\n\n\n  \"\"\")\n\n\nimport pandas as pd\nfrom corebridge.timeseriesdataframe import timeseries_dataframe_from_datadict\n\n\ndf_normalized = pd.json_normalize(\n    test_nested_data, \n    sep='.',\n    #record_prefix='metadata.'\n)\n\n\ndf_normalized.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10 entries, 0 to 9\nData columns (total 15 columns):\n #   Column                               Non-Null Count  Dtype  \n---  ------                               --------------  -----  \n 0   deviceId                             10 non-null     object \n 1   datetimeMeasure                      10 non-null     object \n 2   datetimeSource                       10 non-null     object \n 3   datetimeAcquisition                  10 non-null     object \n 4   connector                            10 non-null     object \n 5   value                                10 non-null     object \n 6   metadata.connection.rssi             10 non-null     int64  \n 7   metadata.connection.snr              10 non-null     float64\n 8   metadata.connection.spreadingFactor  10 non-null     int64  \n 9   metadata.connection.frequency        10 non-null     float64\n 10  metadata.connection.gateways         10 non-null     object \n 11  metadata.frame.port                  10 non-null     int64  \n 12  metadata.frame.counterUp             10 non-null     int64  \n 13  metadata.frame.counterDown           10 non-null     int64  \n 14  metadata.frame.errorRate             10 non-null     int64  \ndtypes: float64(2), int64(6), object(7)\nmemory usage: 1.3+ KB\n\n\n\ndfn = timeseries_dataframe_from_datadict(test_nested_data, ['datetimeMeasure', 'time'], recordformat='records', nested=True).dropna()\ndfn.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 10 entries, 2025-07-21 09:46:33.313000+00:00 to 2025-07-21 08:16:33.560000+00:00\nData columns (total 14 columns):\n #   Column                               Non-Null Count  Dtype  \n---  ------                               --------------  -----  \n 0   deviceId                             10 non-null     object \n 1   datetimeSource                       10 non-null     object \n 2   datetimeAcquisition                  10 non-null     object \n 3   connector                            10 non-null     object \n 4   value                                10 non-null     object \n 5   metadata.connection.rssi             10 non-null     int64  \n 6   metadata.connection.snr              10 non-null     float64\n 7   metadata.connection.spreadingFactor  10 non-null     int64  \n 8   metadata.connection.frequency        10 non-null     float64\n 9   metadata.connection.gateways         10 non-null     object \n 10  metadata.frame.port                  10 non-null     int64  \n 11  metadata.frame.counterUp             10 non-null     int64  \n 12  metadata.frame.counterDown           10 non-null     int64  \n 13  metadata.frame.errorRate             10 non-null     int64  \ndtypes: float64(2), int64(6), object(6)\nmemory usage: 1.2+ KB\n\n\n\ndfn\n\n\n\n\n\n\n\n\ndeviceId\ndatetimeSource\ndatetimeAcquisition\nconnector\nvalue\nmetadata.connection.rssi\nmetadata.connection.snr\nmetadata.connection.spreadingFactor\nmetadata.connection.frequency\nmetadata.connection.gateways\nmetadata.frame.port\nmetadata.frame.counterUp\nmetadata.frame.counterDown\nmetadata.frame.errorRate\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025-07-21 09:46:33.313000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:46:33.313Z\n2025-07-21T09:46:33.691Z\nlora.kpn\n0d01b4613d2ab820ec21e42a912a\n-106\n0.00\n11\n868.1\n[{'id': 'FF01055A', 'rssi': -106, 'snr': 0, 'l...\n2\n1319\n26\n4\n\n\n2025-07-21 09:36:33.332000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:36:33.332Z\n2025-07-21T09:36:33.697Z\nlora.kpn\n0d0174603d2a9e20bf21dc2a802a\n-104\n5.00\n11\n867.3\n[{'id': 'FF01055A', 'rssi': -104, 'snr': 5, 'l...\n2\n1318\n26\n4\n\n\n2025-07-21 09:26:33.350000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:26:33.350Z\n2025-07-21T09:26:33.705Z\nlora.kpn\n0d01b45e3d2aa120ad21d42a5d2a\n-105\n9.00\n11\n868.5\n[{'id': 'FF01055A', 'rssi': -105, 'snr': 9, 'l...\n2\n1317\n26\n4\n\n\n2025-07-21 09:16:33.368000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:16:33.368Z\n2025-07-21T09:16:33.734Z\nlora.kpn\n0d01745d3d2ac320a621d12a5b2a\n-109\n2.00\n11\n866.6\n[{'id': 'FF01055A', 'rssi': -109, 'snr': 2, 'l...\n2\n1316\n26\n4\n\n\n2025-07-21 09:06:33.386000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:06:33.386Z\n2025-07-21T09:06:33.748Z\nlora.kpn\n0d01345c3d2aa920b821d02a612a\n-106\n-2.00\n11\n868.5\n[{'id': 'FF01055A', 'rssi': -106, 'snr': -2, '...\n2\n1315\n26\n4\n\n\n2025-07-21 08:56:33.405000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:56:33.405Z\n2025-07-21T08:56:33.754Z\nlora.kpn\n0d01f45a3d2aa020c821d22a7d2a\n-115\n-6.25\n11\n866.1\n[{'id': 'FF010323', 'rssi': -115, 'snr': -6.25...\n2\n1314\n26\n4\n\n\n2025-07-21 08:46:33.423000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:46:33.423Z\n2025-07-21T08:46:33.778Z\nlora.kpn\n0d01b4593d2ab920d121cf2a922a\n-106\n8.00\n11\n868.5\n[{'id': 'FF01055A', 'rssi': -106, 'snr': 8, 'l...\n2\n1313\n26\n4\n\n\n2025-07-21 08:36:33.441000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:36:33.441Z\n2025-07-21T08:36:33.821Z\nlora.kpn\n0d0174583d2ac020e221cb2ada2a\n-106\n2.00\n11\n866.4\n[{'id': 'FF01055A', 'rssi': -106, 'snr': 2, 'l...\n2\n1312\n26\n6\n\n\n2025-07-21 08:26:33.460000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:26:33.460Z\n2025-07-21T08:26:33.810Z\nlora.kpn\n0d01b4563d2aa220db21c72aba2a\n-103\n-2.00\n11\n868.1\n[{'id': 'FF01055A', 'rssi': -103, 'snr': -2, '...\n2\n1311\n26\n6\n\n\n2025-07-21 08:16:33.560000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:16:33.560Z\n2025-07-21T08:16:33.962Z\nlora.kpn\n0d0174553d2ac220d821c52ad92a\n-104\n-7.00\n11\n865.1\n[{'id': 'FF01055A', 'rssi': -104, 'snr': -7, '...\n2\n1310\n26\n6\n\n\n\n\n\n\n\n\ndfm = timeseries_dataframe_from_datadict(test_nested_data, ['datetimeMeasure', 'time'], recordformat='records', nested=False).dropna()\ndfm.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 10 entries, 2025-07-21 09:46:33.313000+00:00 to 2025-07-21 08:16:33.560000+00:00\nData columns (total 6 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   deviceId             10 non-null     object\n 1   datetimeSource       10 non-null     object\n 2   datetimeAcquisition  10 non-null     object\n 3   connector            10 non-null     object\n 4   value                10 non-null     object\n 5   metadata             10 non-null     object\ndtypes: object(6)\nmemory usage: 560.0+ bytes\n\n\n\ndef test_nested_data_processing(data:pd.DataFrame, anumber:float|np.ndarray=0):\n    print (f\"Processing {len(data)} rows of data\")\n    print(data.columns)\n    return data\n\n\nclass TestNestedAICoreModule(AICoreModule):\n    def __init__(self, files_dir, save_dir):\n        super().__init__(test_nested_data_processing, files_dir, save_dir)\n\ntest_nested_module = TestNestedAICoreModule(os.path.join(os.getcwd(), 'cache'),os.path.join(os.getcwd(), 'cache'))\n\n2026-01-29T14:38:36+0100 INFO   8596    corebridge.aicorebridge aicorebridge.py __init__    135 Init TestNestedAICoreModule, version 0.6.6, files directory c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache, save dir c:\\Users\\fenke\\repos\\corebridge\\nbs\\cache on werkdoos\n\n\n\ntest_result = test_nested_module.call(dict(\n    data=test_nested_data,\n    kwargs=dict(\n        timezone='UTC',\n        recordformat='records',\n        nested=True\n    )\n))\n\nProcessing 10 rows of data\nIndex(['deviceId', 'datetimeSource', 'datetimeAcquisition', 'connector',\n       'value', 'metadata.connection.rssi', 'metadata.connection.snr',\n       'metadata.connection.spreadingFactor', 'metadata.connection.frequency',\n       'metadata.connection.gateways', 'metadata.frame.port',\n       'metadata.frame.counterUp', 'metadata.frame.counterDown',\n       'metadata.frame.errorRate'],\n      dtype='object')\n\n\n\nprint(\"Result Message\\n\", json.dumps(test_result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(test_result['data'], indent=2, cls=NumpyEncoder))\n\nResult Message\n [\n  \"Startup time: 2026-01-29T13:38:36.605275+00:00, node werkdoos\",\n  \"Call time: 2026-01-29T13:38:36.616701+00:00\",\n  \"Corebridge version: 0.6.6\",\n  \"CPU times: user: 21.3, system: 7.4, idle: 71.3, interrupt: 0.0, dpc: 0.0\",\n  \"Memory: total: 68425105408, available: 54528323584, percent: 20.3, used: 13896781824, free: 54528323584\",\n  \"test_nested_data_processing((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 10\",\n  \"kwargs ['timezone', 'recordformat', 'nested']\",\n  \"lastSeen: False, timezone: UTC, recordformat: records, nested: True\",\n  \"Processing time: 0.4 ms\",\n  \"Preparation time: 3.5 ms\",\n  \"result shape: (10, 14)\",\n  \"return-data shape: (10, 14)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2025-07-21T08:16:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:16:33.560Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:16:33.962Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d0174553d2ac220d821c52ad92a\",\n    \"metadata.connection.rssi\": -104,\n    \"metadata.connection.snr\": -7.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 865.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -104,\n        \"snr\": -7,\n        \"location\": {\n          \"latitude\": 51.556866,\n          \"longitude\": 5.865384\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1310,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 6\n  },\n  {\n    \"time\": \"2025-07-21T08:26:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:26:33.460Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:26:33.810Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b4563d2aa220db21c72aba2a\",\n    \"metadata.connection.rssi\": -103,\n    \"metadata.connection.snr\": -2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -103,\n        \"snr\": -2,\n        \"location\": {\n          \"latitude\": 51.556854,\n          \"longitude\": 5.865371\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1311,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 6\n  },\n  {\n    \"time\": \"2025-07-21T08:36:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:36:33.441Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:36:33.821Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d0174583d2ac020e221cb2ada2a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": 2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 866.4,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": 2,\n        \"location\": {\n          \"latitude\": 51.55687,\n          \"longitude\": 5.86535\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1312,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 6\n  },\n  {\n    \"time\": \"2025-07-21T08:46:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:46:33.423Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:46:33.778Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b4593d2ab920d121cf2a922a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": 8.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.5,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": 8,\n        \"location\": {\n          \"latitude\": 51.556862,\n          \"longitude\": 5.865373\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1313,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T08:56:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:56:33.405Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:56:33.754Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01f45a3d2aa020c821d22a7d2a\",\n    \"metadata.connection.rssi\": -115,\n    \"metadata.connection.snr\": -6.25,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 866.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF010323\",\n        \"rssi\": -115,\n        \"snr\": -6.25,\n        \"location\": {\n          \"latitude\": 51.516491,\n          \"longitude\": 5.884403\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1314,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:06:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:06:33.386Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:06:33.748Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01345c3d2aa920b821d02a612a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": -2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.5,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": -2,\n        \"location\": {\n          \"latitude\": 51.556858,\n          \"longitude\": 5.865352\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1315,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:16:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:16:33.368Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:16:33.734Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01745d3d2ac320a621d12a5b2a\",\n    \"metadata.connection.rssi\": -109,\n    \"metadata.connection.snr\": 2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 866.6,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -109,\n        \"snr\": 2,\n        \"location\": {\n          \"latitude\": 51.556892,\n          \"longitude\": 5.865359\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1316,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:26:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:26:33.350Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:26:33.705Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b45e3d2aa120ad21d42a5d2a\",\n    \"metadata.connection.rssi\": -105,\n    \"metadata.connection.snr\": 9.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.5,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -105,\n        \"snr\": 9,\n        \"location\": {\n          \"latitude\": 51.556892,\n          \"longitude\": 5.865356\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1317,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:36:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:36:33.332Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:36:33.697Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d0174603d2a9e20bf21dc2a802a\",\n    \"metadata.connection.rssi\": -104,\n    \"metadata.connection.snr\": 5.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 867.3,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -104,\n        \"snr\": 5,\n        \"location\": {\n          \"latitude\": 51.5569,\n          \"longitude\": 5.865385\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1318,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:46:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:46:33.313Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:46:33.691Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b4613d2ab820ec21e42a912a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": 0.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": 0,\n        \"location\": {\n          \"latitude\": 51.556896,\n          \"longitude\": 5.865362\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1319,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  }\n]\n\n\n\nprint(test_result['msg'][-1])\n\nreturn-data shape: (10, 14)",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#references",
    "href": "aicorebridge.html#references",
    "title": "AICore-Bridge",
    "section": "References",
    "text": "References",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "timeseriesdataframe.html",
    "href": "timeseriesdataframe.html",
    "title": "Timeseries datarames",
    "section": "",
    "text": "Timeseries data is a cornerstone of our data manipulation and most processing is on them\n\n\nProcessing may depend on proper timezone awareness, this utility to set the timezone on a datetime index\n\n\n\n\n\ndef set_time_index_zone(\n    df:DataFrame, # Dataframe to set or convert the timeindex on\n    timezone, # Timezone to set\n):\n\nSets the time zone of the index of a pandas DataFrame.\nArgs: df (pd.DataFrame): The DataFrame whose index time zone is to be set. timezone (str): The desired time zone.\nReturns: pd.DataFrame: The modified DataFrame with its index time zone set to the specified time zone.\nRaises: None\nExamples: &gt;&gt;&gt; df = pd.DataFrame({A: [1, 2, 3]}, index=pd.DatetimeIndex([2022-01-01, 2022-01-02, 2022-01-03])) &gt;&gt;&gt; set_time_index_zone(df, Europe/Berlin) A 2022-01-01 1 2022-01-02 2 2022-01-03 3 DatetimeIndex: 3 entries, 2022-01-01 01:00:00+01:00 to 2022-01-03 01:00:00+01:00\n\n\n\ndf = pd.DataFrame({'A': [1, 2, 3]}, index=pd.DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03']))\nset_time_index_zone(df, 'Europe/Berlin')\ndf.index\n\nDatetimeIndex(['2022-01-01 01:00:00+01:00', '2022-01-02 01:00:00+01:00',\n               '2022-01-03 01:00:00+01:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='time', freq=None)\n\n\n\n\n\n\nConverts Pandas dataframes and series, Numpy arrays and recarrays or a dictionary of individual timeseries into a Pandas dataframe with one datetime index. With all arrays dataframes and series it is assumed that the first column contains the timestamps.\n\n\n\n\n\ndef timeseries_dataframe(\n    data:Union, timezone:str='UTC', columnnames:NoneType=None\n):\n\nConvert various tabular data formats to timeseries DataFrame\nArgs: data (Union[pd.DataFrame, pd.Series, dict, np.ndarray, np.recarray]): The input data to be converted. timezone (str, optional): The timezone to set for the index of the DataFrame. Defaults to UTC. columnnames (Optional[List[str]]): The column names to use for the DataFrame. Defaults to None.\nReturns: pd.DataFrame: The converted timeseries DataFrame with the index set to the specified timezone.\n\n\n\n\n\n\n\n\ndef timeseries_dataframe_from_datadict(\n    data:dict, timecolumns:NoneType=None, recordformat:str='records', nested:bool=False\n):\n\nConverts a data dict into a pandas DataFrame based on the specified record format.  Parameters: - data: A dictionary containing the data to convert. - timecolumns: A list of column names to be treated as time columns. - recordformat: A string specifying the format of the data records (records, table, split, index, tight). Returns: - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n\n\nExported source\ndef timeseries_dataframe_from_datadict(\n        data:dict, \n        timecolumns=None,\n        recordformat='records',\n        nested=False\n):\n        \n    \"\"\"\n    Converts a data dict into a pandas DataFrame based on the specified record format. \n    Parameters:\n        - data: A dictionary containing the data to convert.\n        - timecolumns: A list of column names to be treated as time columns.\n        - recordformat: A string specifying the format of the data records ('records', 'table', 'split', 'index', 'tight').\n    Returns:\n        - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n    \"\"\"\n\n    orient = recordformat.lower()\n    assert orient in ['records', 'table', 'split', 'index', 'tight']\n    assert timecolumns, 'No time columns specified'\n\n    #print(f\"Converting {'nested' if nested else 'flat'} data dict to DataFrame with orient={orient} and timecolumns={timecolumns}\")\n    \n    if orient == 'records':\n        if nested:\n            # data is a nested structure, we need to normalize it\n            df = pd.json_normalize(data, sep='.', errors='ignore')  # type: ignore\n\n        else:\n            # data is a structured ndarray, sequence of tuples or dicts, or DataFrame\n            df = pd.DataFrame.from_records(data, coerce_float=True)  # type: ignore\n            \n        time_columns_in_df = [C for C in df.columns if C in timecolumns]\n        if not  time_columns_in_df:\n            time_column = df.columns[0]\n        else:\n            time_column = time_columns_in_df[0]\n\n    elif orient == 'table':\n        # data is in pandas table format\n        time_column = data['schema']['primaryKey'][0]\n        df = pd.DataFrame.from_dict(data['data'], coerce_float=True).set_index(data['schema']['primaryKey'])\n        df.index.name = 'time'\n    else:\n        # data  is formatted according to 'orient' parameter (pandas)\n        df = pd.DataFrame.from_dict(data, orient=orient, coerce_float=True) # type: ignore\n        time_column = df.index.name\n\n\n    df.columns = list(df.columns)\n    df[time_column] = pd.to_datetime(df[time_column],utc=True,format='ISO8601')\n    df.set_index(time_column, inplace=True)\n    df.index = pd.DatetimeIndex(df.index).round('ms')\n    \n    df.index.name = 'time'\n\n    return df\n\n\n\ndf = timeseries_dataframe_from_datadict(test_data_dict_3_samples, timecolumns=['time'])\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 10:04:49+00:00', '2023-05-04 10:24:51+00:00',\n               '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = set_time_index_zone( \n    timeseries_dataframe_from_datadict(\n        test_data_dict_3_samples, \n        timecolumns=['time']\n    ), \n    timezone='Europe/Amsterdam'\n)\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 12:04:49+02:00\n16.72\n\n\n2023-05-04 12:24:51+02:00\n16.65\n\n\n2023-05-04 12:44:53+02:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 12:04:49+02:00', '2023-05-04 12:24:51+02:00',\n               '2023-05-04 12:44:53+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', name='time', freq=None)\n\n\n\n\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=3, freq='s').tz_convert('Europe/Amsterdam')\nrng\n\nDatetimeIndex(['2018-04-10 09:01:01.123000+02:00',\n               '2018-04-10 09:01:02.123000+02:00',\n               '2018-04-10 09:01:03.123000+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', freq='s')\n\n\n\nrng.strftime(\"%FT%R:%S%z\")\n\nIndex(['2018-04-10T09:01:01+0200', '2018-04-10T09:01:02+0200',\n       '2018-04-10T09:01:03+0200'],\n      dtype='object')\n\n\n\npd.DatetimeIndex(rng.strftime(\"%FT%R:%S%z\")).round('ms')\n\nDatetimeIndex(['2018-04-10 09:01:01+02:00', '2018-04-10 09:01:02+02:00',\n               '2018-04-10 09:01:03+02:00'],\n              dtype='datetime64[ns, UTC+02:00]', freq=None)\n\n\n\nrng.tz_convert('UTC').strftime(\"%FT%R:%SZ\")\n\nIndex(['2018-04-10T07:01:01Z', '2018-04-10T07:01:02Z', '2018-04-10T07:01:03Z'], dtype='object')\n\n\n\n# .map(lambda x: x.isoformat())\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=30000, freq='s').tz_convert('Europe/Amsterdam')\n\n\n\n\nft = rng.strftime(\"%FT%R:%S%z\")\n\n340 ms  18.3 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n\n\n\nft = rng.map(lambda x: x.isoformat(timespec='milliseconds'))\n\n136 ms  9.46 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n\n\n\n\n\n\ndef timeseries_dataframe_to_datadict(\n    data:Union, recordformat:str='records', timezone:str='UTC'\n):\n\nConvert a timeseries DataFrame or Series into a dictionary representation.\nArgs: data (Union[pd.DataFrame, pd.Series, dict]): The input data to be converted. It can be a pandas DataFrame, Series, or a dictionary. recordformat (str, optional): The format of the output records. Defaults to records. timezone (str, optional): The timezone to use for the DataFrame index. Defaults to UTC.\nReturns: Union[dict, list]: The converted dictionary representation of the input data, a dictionary or a list of dictionaries depending on the recordformat parameter.\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe(df, timezone='UTC').index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records')\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records', timezone='Europe/Berlin')\n\n[{'time': '2023-05-04T11:04:49.050+02:00', 'value': 16.72},\n {'time': '2023-05-04T12:24:51.010+02:00', 'value': 16.65},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': 16.55},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': nan}]\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='tight')\n\n{'index': ['2023-05-04T09:04:49Z',\n  '2023-05-04T10:24:51Z',\n  '2023-05-04T10:44:53Z',\n  '2023-05-04T10:44:53Z'],\n 'columns': ['value'],\n 'data': [[16.72], [16.65], [16.55], [nan]],\n 'index_names': ['time'],\n 'column_names': [None]}\n\n\n\ntest_data = timeseries_dataframe_to_datadict(df, recordformat='records')\n\n\ntest_data\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\n\n\n\n\ndef timeseries_dataframe_resample(\n    df:DataFrame, period:str, method:str\n):\n\nResamples a time-series DataFrame on the specified period and method.\nParameters: df (pd.DataFrame): The input time-series DataFrame. period (str): The resampling period. method (str): The resampling method. Can be a string of multiple methods separated by ;. method_args (dict, optional): Additional arguments for the resampling method.\nReturns: pd.DataFrame: The resampled DataFrame.\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.000Z\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.000Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T11:04:49.000Z\",\n         \"value\":16.47\n      },\n      {\n         \"time\":\"2023-05-04T11:24:51.000Z\",\n         \"value\":16.44\n      },\n      {\n         \"time\":\"2023-05-04T11:44:53.000Z\",\n         \"value\":16.38\n      },\n   ], timecolumns=['time'])\n\n\ntimeseries_dataframe_resample(df, \"80min\", 'mean;count')\n\n\n\n\n\n\n\n\nvalue\nvalue_mean\nvalue_count\n\n\ntime\n\n\n\n\n\n\n\n2023-05-04 09:20:00+00:00\nNaN\n16.685\n2.0\n\n\n2023-05-04 10:04:49+00:00\n16.72\nNaN\nNaN\n\n\n2023-05-04 10:24:51+00:00\n16.65\nNaN\nNaN\n\n\n2023-05-04 10:40:00+00:00\nNaN\n16.460\n4.0\n\n\n2023-05-04 10:44:53+00:00\n16.55\nNaN\nNaN\n\n\n2023-05-04 11:04:49+00:00\n16.47\nNaN\nNaN\n\n\n2023-05-04 11:24:51+00:00\n16.44\nNaN\nNaN\n\n\n2023-05-04 11:44:53+00:00\n16.38\nNaN\nNaN",
    "crumbs": [
      "Timeseries datarames"
    ]
  },
  {
    "objectID": "timeseriesdataframe.html#timeseries-dataframes",
    "href": "timeseriesdataframe.html#timeseries-dataframes",
    "title": "Timeseries datarames",
    "section": "",
    "text": "Timeseries data is a cornerstone of our data manipulation and most processing is on them\n\n\nProcessing may depend on proper timezone awareness, this utility to set the timezone on a datetime index\n\n\n\n\n\ndef set_time_index_zone(\n    df:DataFrame, # Dataframe to set or convert the timeindex on\n    timezone, # Timezone to set\n):\n\nSets the time zone of the index of a pandas DataFrame.\nArgs: df (pd.DataFrame): The DataFrame whose index time zone is to be set. timezone (str): The desired time zone.\nReturns: pd.DataFrame: The modified DataFrame with its index time zone set to the specified time zone.\nRaises: None\nExamples: &gt;&gt;&gt; df = pd.DataFrame({A: [1, 2, 3]}, index=pd.DatetimeIndex([2022-01-01, 2022-01-02, 2022-01-03])) &gt;&gt;&gt; set_time_index_zone(df, Europe/Berlin) A 2022-01-01 1 2022-01-02 2 2022-01-03 3 DatetimeIndex: 3 entries, 2022-01-01 01:00:00+01:00 to 2022-01-03 01:00:00+01:00\n\n\n\ndf = pd.DataFrame({'A': [1, 2, 3]}, index=pd.DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03']))\nset_time_index_zone(df, 'Europe/Berlin')\ndf.index\n\nDatetimeIndex(['2022-01-01 01:00:00+01:00', '2022-01-02 01:00:00+01:00',\n               '2022-01-03 01:00:00+01:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='time', freq=None)\n\n\n\n\n\n\nConverts Pandas dataframes and series, Numpy arrays and recarrays or a dictionary of individual timeseries into a Pandas dataframe with one datetime index. With all arrays dataframes and series it is assumed that the first column contains the timestamps.\n\n\n\n\n\ndef timeseries_dataframe(\n    data:Union, timezone:str='UTC', columnnames:NoneType=None\n):\n\nConvert various tabular data formats to timeseries DataFrame\nArgs: data (Union[pd.DataFrame, pd.Series, dict, np.ndarray, np.recarray]): The input data to be converted. timezone (str, optional): The timezone to set for the index of the DataFrame. Defaults to UTC. columnnames (Optional[List[str]]): The column names to use for the DataFrame. Defaults to None.\nReturns: pd.DataFrame: The converted timeseries DataFrame with the index set to the specified timezone.\n\n\n\n\n\n\n\n\ndef timeseries_dataframe_from_datadict(\n    data:dict, timecolumns:NoneType=None, recordformat:str='records', nested:bool=False\n):\n\nConverts a data dict into a pandas DataFrame based on the specified record format.  Parameters: - data: A dictionary containing the data to convert. - timecolumns: A list of column names to be treated as time columns. - recordformat: A string specifying the format of the data records (records, table, split, index, tight). Returns: - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n\n\nExported source\ndef timeseries_dataframe_from_datadict(\n        data:dict, \n        timecolumns=None,\n        recordformat='records',\n        nested=False\n):\n        \n    \"\"\"\n    Converts a data dict into a pandas DataFrame based on the specified record format. \n    Parameters:\n        - data: A dictionary containing the data to convert.\n        - timecolumns: A list of column names to be treated as time columns.\n        - recordformat: A string specifying the format of the data records ('records', 'table', 'split', 'index', 'tight').\n    Returns:\n        - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n    \"\"\"\n\n    orient = recordformat.lower()\n    assert orient in ['records', 'table', 'split', 'index', 'tight']\n    assert timecolumns, 'No time columns specified'\n\n    #print(f\"Converting {'nested' if nested else 'flat'} data dict to DataFrame with orient={orient} and timecolumns={timecolumns}\")\n    \n    if orient == 'records':\n        if nested:\n            # data is a nested structure, we need to normalize it\n            df = pd.json_normalize(data, sep='.', errors='ignore')  # type: ignore\n\n        else:\n            # data is a structured ndarray, sequence of tuples or dicts, or DataFrame\n            df = pd.DataFrame.from_records(data, coerce_float=True)  # type: ignore\n            \n        time_columns_in_df = [C for C in df.columns if C in timecolumns]\n        if not  time_columns_in_df:\n            time_column = df.columns[0]\n        else:\n            time_column = time_columns_in_df[0]\n\n    elif orient == 'table':\n        # data is in pandas table format\n        time_column = data['schema']['primaryKey'][0]\n        df = pd.DataFrame.from_dict(data['data'], coerce_float=True).set_index(data['schema']['primaryKey'])\n        df.index.name = 'time'\n    else:\n        # data  is formatted according to 'orient' parameter (pandas)\n        df = pd.DataFrame.from_dict(data, orient=orient, coerce_float=True) # type: ignore\n        time_column = df.index.name\n\n\n    df.columns = list(df.columns)\n    df[time_column] = pd.to_datetime(df[time_column],utc=True,format='ISO8601')\n    df.set_index(time_column, inplace=True)\n    df.index = pd.DatetimeIndex(df.index).round('ms')\n    \n    df.index.name = 'time'\n\n    return df\n\n\n\ndf = timeseries_dataframe_from_datadict(test_data_dict_3_samples, timecolumns=['time'])\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 10:04:49+00:00', '2023-05-04 10:24:51+00:00',\n               '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = set_time_index_zone( \n    timeseries_dataframe_from_datadict(\n        test_data_dict_3_samples, \n        timecolumns=['time']\n    ), \n    timezone='Europe/Amsterdam'\n)\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 12:04:49+02:00\n16.72\n\n\n2023-05-04 12:24:51+02:00\n16.65\n\n\n2023-05-04 12:44:53+02:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 12:04:49+02:00', '2023-05-04 12:24:51+02:00',\n               '2023-05-04 12:44:53+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', name='time', freq=None)\n\n\n\n\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=3, freq='s').tz_convert('Europe/Amsterdam')\nrng\n\nDatetimeIndex(['2018-04-10 09:01:01.123000+02:00',\n               '2018-04-10 09:01:02.123000+02:00',\n               '2018-04-10 09:01:03.123000+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', freq='s')\n\n\n\nrng.strftime(\"%FT%R:%S%z\")\n\nIndex(['2018-04-10T09:01:01+0200', '2018-04-10T09:01:02+0200',\n       '2018-04-10T09:01:03+0200'],\n      dtype='object')\n\n\n\npd.DatetimeIndex(rng.strftime(\"%FT%R:%S%z\")).round('ms')\n\nDatetimeIndex(['2018-04-10 09:01:01+02:00', '2018-04-10 09:01:02+02:00',\n               '2018-04-10 09:01:03+02:00'],\n              dtype='datetime64[ns, UTC+02:00]', freq=None)\n\n\n\nrng.tz_convert('UTC').strftime(\"%FT%R:%SZ\")\n\nIndex(['2018-04-10T07:01:01Z', '2018-04-10T07:01:02Z', '2018-04-10T07:01:03Z'], dtype='object')\n\n\n\n# .map(lambda x: x.isoformat())\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=30000, freq='s').tz_convert('Europe/Amsterdam')\n\n\n\n\nft = rng.strftime(\"%FT%R:%S%z\")\n\n340 ms  18.3 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n\n\n\nft = rng.map(lambda x: x.isoformat(timespec='milliseconds'))\n\n136 ms  9.46 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n\n\n\n\n\n\ndef timeseries_dataframe_to_datadict(\n    data:Union, recordformat:str='records', timezone:str='UTC'\n):\n\nConvert a timeseries DataFrame or Series into a dictionary representation.\nArgs: data (Union[pd.DataFrame, pd.Series, dict]): The input data to be converted. It can be a pandas DataFrame, Series, or a dictionary. recordformat (str, optional): The format of the output records. Defaults to records. timezone (str, optional): The timezone to use for the DataFrame index. Defaults to UTC.\nReturns: Union[dict, list]: The converted dictionary representation of the input data, a dictionary or a list of dictionaries depending on the recordformat parameter.\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe(df, timezone='UTC').index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records')\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records', timezone='Europe/Berlin')\n\n[{'time': '2023-05-04T11:04:49.050+02:00', 'value': 16.72},\n {'time': '2023-05-04T12:24:51.010+02:00', 'value': 16.65},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': 16.55},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': nan}]\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='tight')\n\n{'index': ['2023-05-04T09:04:49Z',\n  '2023-05-04T10:24:51Z',\n  '2023-05-04T10:44:53Z',\n  '2023-05-04T10:44:53Z'],\n 'columns': ['value'],\n 'data': [[16.72], [16.65], [16.55], [nan]],\n 'index_names': ['time'],\n 'column_names': [None]}\n\n\n\ntest_data = timeseries_dataframe_to_datadict(df, recordformat='records')\n\n\ntest_data\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\n\n\n\n\ndef timeseries_dataframe_resample(\n    df:DataFrame, period:str, method:str\n):\n\nResamples a time-series DataFrame on the specified period and method.\nParameters: df (pd.DataFrame): The input time-series DataFrame. period (str): The resampling period. method (str): The resampling method. Can be a string of multiple methods separated by ;. method_args (dict, optional): Additional arguments for the resampling method.\nReturns: pd.DataFrame: The resampled DataFrame.\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.000Z\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.000Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T11:04:49.000Z\",\n         \"value\":16.47\n      },\n      {\n         \"time\":\"2023-05-04T11:24:51.000Z\",\n         \"value\":16.44\n      },\n      {\n         \"time\":\"2023-05-04T11:44:53.000Z\",\n         \"value\":16.38\n      },\n   ], timecolumns=['time'])\n\n\ntimeseries_dataframe_resample(df, \"80min\", 'mean;count')\n\n\n\n\n\n\n\n\nvalue\nvalue_mean\nvalue_count\n\n\ntime\n\n\n\n\n\n\n\n2023-05-04 09:20:00+00:00\nNaN\n16.685\n2.0\n\n\n2023-05-04 10:04:49+00:00\n16.72\nNaN\nNaN\n\n\n2023-05-04 10:24:51+00:00\n16.65\nNaN\nNaN\n\n\n2023-05-04 10:40:00+00:00\nNaN\n16.460\n4.0\n\n\n2023-05-04 10:44:53+00:00\n16.55\nNaN\nNaN\n\n\n2023-05-04 11:04:49+00:00\n16.47\nNaN\nNaN\n\n\n2023-05-04 11:24:51+00:00\n16.44\nNaN\nNaN\n\n\n2023-05-04 11:44:53+00:00\n16.38\nNaN\nNaN",
    "crumbs": [
      "Timeseries datarames"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "corebridge",
    "section": "",
    "text": "This package provides functions and classes to run wodan style processing functions in the Stactics AICore environment.",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "corebridge",
    "section": "Installation",
    "text": "Installation\nUse\npip install corebridge\nto install corebrdige.",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "corebridge",
    "section": "How to use",
    "text": "How to use\n\nIntroduction\nWodan is a proprietary backend service that applies high performance, custom analytical processing to timeseries data in the Whysor data and dashboarding environment.\nEach wodan module defines one function that operates as the entry point. The parameter annotations in this function definition are used to format data and retrieve parameters from the originating call to the wodan api. This function is called with data retrieved according to a specification and with additional parameters as annotated.\nA simple function might look like:\nimport numpy as np\n\ndef multiply(data:np.ndarray, multiplier:float=1.0):\n    return data * multiplier\n    \nWodan binds this function to a service endpoint and takes care of fetching data and parameters and converting the result for the caller.\n\n\nAICore modules\nFor AICore users define a class, always named Module with a constructor __init__ and a method infer.\nThis package defines a baseclass to quickly construct a Module class that is able to use a wodan processor function inside the AICore system:\nimport numpy as np\nimport corebridge\n\ndef multiply(data:np.ndarray, multiplier:float=1.0):\n    return data * multiplier\n\nclass Module(corebridge.aicorebridge.AICoreModule):\n    def __init__(self, save_dir, assets_dir, *args, **kwargs):\n        super().__init__(multiply, save_dir, assets_dir, *args, **kwargs)\n    \nThats it. Well, you can add parameters to __init__ that can be used as hyperparameters in the web-interface and you could override infer for the same reason. The baseclass takes care of converting call parameters and data to the function specification and, calls the function and converts the result for the caller, similar to the original Wodan service.\nYou dont have to use AICoreModule baseclas but can create your own class and use functionality within CoreBridge to convert call parameters and data to fit your needs. AICoreModule was developed to make the deployment of existing Wodan modules within AICore easier. It also helps developing functions independently of AICore while being able to deploy these functions as modules within AICore.",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#development",
    "href": "index.html#development",
    "title": "corebridge",
    "section": "Development",
    "text": "Development\n\nNBDev\nThis library is developed with NBDev - a literate programming toolkit that supports developing code using jupyter notebooks and mix code with documentation.\nLiterate programming is a methodology - introduced in 1984 by Donald Knuth - that combines a programming language with a documentation language. In this approach, a program is explained in a human language (such as English) alongside code snippets. The literate source file is then processed by a preprocessor to produce both source code and formatted documentation.\nThis paradigm enhances program robustness, portability, and maintainability, making it a valuable tool in scientific computing and data science1\n\n\nQuarto\nDocumentation is prepared from the notebook with Quarto. Quarto too combines code with documentation but it does not extract source code into modules like nbdev.\n\n\nInstallation\n\nQuarto\nQuarto uses Pandoc and, for pdf format, LaTeX. These must be available on your system.\nInstall Quarto as you see fit, there is a VSCode extension which handles this.\n\n\nNBDev\nNBDev is available as PyPi package and is installed with\npip install nbdev\nor if you are using conda\nconda install -c fastai -y nbdev\nIf so desired you can let NBDev install Quarto with\nnbdev_install_quarto\nBut this ask for the system admin password.\n\n\n\nLocal editing & testing\nSetup a virtual environment, activate it and install the development package and dependencies with, on linux\n    pip install -e .[dev]\n\nor on Windows\n    pip install -e .[dev]\n\n\nJupyter\nThe above pip install should also install jupyter but to use it the kernel needs to be installed with:\n    python -m ipykernel install --user --name=corebridge.venv\n\n\n\nnbdev cycle\n\nedit\nnbdev_prepare\n\nThe latter performs - nbdev_export - nbdev_test - nbdev_clean - nbdev_readme\nBefore committing changes to git run - nbdev_clean\nThen commit to git and for a new pip release upload to Pypi with nbdev_pypi",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "corebridge",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWikipedia on Literate Programming",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core functionality",
    "section": "",
    "text": "def init_console_logging(\n    name:str='__main__', level:int=20, timestamp:bool=True\n):\n\nSetup none-blocking stream handler for sending loggin to the console.\n\n\nExported source\ndef init_console_logging(name=__name__, level=logging.INFO, timestamp=True):\n    '''Setup none-blocking stream handler for sending loggin to the console.'''\n\n    logger = logging.getLogger(name)\n    # Only if no handlers defined.\n    if not logger.hasHandlers():\n\n        logger.setLevel(level)\n\n\n        console = logging.StreamHandler()\n        console.setLevel(level)\n\n        # set a format which is simpler for console use\n        if timestamp:\n            formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(funcName)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n        else:\n            formatter = logging.Formatter(\"%(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(funcName)s\\t%(lineno)d\\t%(message)s\")\n            \n        #formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n\n        # tell the handler to use this format\n        console.setFormatter(formatter)\n\n        # add the handler to the root logger\n        logger.addHandler(console)\n\n        logger.info(f\"Installed {console} for {name}\")\n    else:\n        logger.info(f'There already is a logger installed for {name}.')\n\n    logger.propagate = False\n    return logger\n\n\n\nsyslog = init_console_logging(__name__)\n\n2025-11-05T15:51:40+0100 INFO   5868    __main__    2225119750.py   30  Installed &lt;StreamHandler stderr (INFO)&gt; for __main__\n\n\n\nsyslog.info('Test')\n\n2025-11-05T15:51:40+0100 INFO   5868    __main__    130201418.py    1   Test\n\n\n\nsyslog.info('Test 2')\n\n2025-11-05T15:51:40+0100 INFO   5868    __main__    1107363523.py   1   Test 2",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#logging",
    "href": "core.html#logging",
    "title": "Core functionality",
    "section": "",
    "text": "def init_console_logging(\n    name:str='__main__', level:int=20, timestamp:bool=True\n):\n\nSetup none-blocking stream handler for sending loggin to the console.\n\n\nExported source\ndef init_console_logging(name=__name__, level=logging.INFO, timestamp=True):\n    '''Setup none-blocking stream handler for sending loggin to the console.'''\n\n    logger = logging.getLogger(name)\n    # Only if no handlers defined.\n    if not logger.hasHandlers():\n\n        logger.setLevel(level)\n\n\n        console = logging.StreamHandler()\n        console.setLevel(level)\n\n        # set a format which is simpler for console use\n        if timestamp:\n            formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(funcName)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n        else:\n            formatter = logging.Formatter(\"%(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(funcName)s\\t%(lineno)d\\t%(message)s\")\n            \n        #formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n\n        # tell the handler to use this format\n        console.setFormatter(formatter)\n\n        # add the handler to the root logger\n        logger.addHandler(console)\n\n        logger.info(f\"Installed {console} for {name}\")\n    else:\n        logger.info(f'There already is a logger installed for {name}.')\n\n    logger.propagate = False\n    return logger\n\n\n\nsyslog = init_console_logging(__name__)\n\n2025-11-05T15:51:40+0100 INFO   5868    __main__    2225119750.py   30  Installed &lt;StreamHandler stderr (INFO)&gt; for __main__\n\n\n\nsyslog.info('Test')\n\n2025-11-05T15:51:40+0100 INFO   5868    __main__    130201418.py    1   Test\n\n\n\nsyslog.info('Test 2')\n\n2025-11-05T15:51:40+0100 INFO   5868    __main__    1107363523.py   1   Test 2",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#machine-information",
    "href": "core.html#machine-information",
    "title": "Core functionality",
    "section": "Machine information",
    "text": "Machine information\n\nget_machine_info()\n\n{'OS Name': 'nt',\n 'System Name': 'Windows',\n 'Release': '11',\n 'Version': '10.0.26100',\n 'Architecture': ('64bit', 'WindowsPE'),\n 'Machine': 'AMD64',\n 'Processor': 'Intel64 Family 6 Model 85 Stepping 4, GenuineIntel',\n 'Node Name': 'werkdoos'}",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#strings",
    "href": "core.html#strings",
    "title": "Core functionality",
    "section": "Strings",
    "text": "Strings\n\n\nsnake_case_to_camel_case\n\ndef snake_case_to_camel_case(\n    snake_case:str\n)-&gt;str:\n\n\n\nExported source\n@lru_cache(128)\ndef snake_case_to_camel_case(snake_case:str) -&gt; str:\n    splittext = snake_case.split('_')\n    return ''.join([x.capitalize() if n &gt; 0 else x for x,n in zip(splittext, range(len(splittext)))])",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#numpy-data-in-json",
    "href": "core.html#numpy-data-in-json",
    "title": "Core functionality",
    "section": "Numpy data in JSON",
    "text": "Numpy data in JSON\n\n\nNumpyEncoder\n\ndef NumpyEncoder(\n    skipkeys:bool=False, ensure_ascii:bool=True, check_circular:bool=True, allow_nan:bool=True, sort_keys:bool=False,\n    indent:NoneType=None, separators:NoneType=None, default:NoneType=None\n):\n\nCustom encoder for numpy data types",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#timeseries-dataframes",
    "href": "core.html#timeseries-dataframes",
    "title": "Core functionality",
    "section": "Timeseries dataframes",
    "text": "Timeseries dataframes\nTimeseries data is a cornerstone of our data manipulation and most processing is on them\n\nset_time_index_zone\nProcessing may depend on proper timezone awareness, this utility to set the timezone on a datetime index\n\n\n\nset_time_index_zone\n\ndef set_time_index_zone(\n    df:DataFrame, # Dataframe to set or convert the timeindex on\n    timezone, # Timezone to set\n):\n\nSets the time zone of the index of a pandas DataFrame.\nArgs: df (pd.DataFrame): The DataFrame whose index time zone is to be set. timezone (str): The desired time zone.\nReturns: pd.DataFrame: The modified DataFrame with its index time zone set to the specified time zone.\nRaises: None\nExamples: &gt;&gt;&gt; df = pd.DataFrame({A: [1, 2, 3]}, index=pd.DatetimeIndex([2022-01-01, 2022-01-02, 2022-01-03])) &gt;&gt;&gt; set_time_index_zone(df, Europe/Berlin) A 2022-01-01 1 2022-01-02 2 2022-01-03 3 DatetimeIndex: 3 entries, 2022-01-01 01:00:00+01:00 to 2022-01-03 01:00:00+01:00\n\nExample\n\ndf = pd.DataFrame({'A': [1, 2, 3]}, index=pd.DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03']))\nset_time_index_zone(df, 'Europe/Berlin')\ndf.index\n\nDatetimeIndex(['2022-01-01 01:00:00+01:00', '2022-01-02 01:00:00+01:00',\n               '2022-01-03 01:00:00+01:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='time', freq=None)\n\n\n\n\n\ntimeseries_dataframe\nConverts Pandas dataframes and series, Numpy arrays and recarrays or a dictionary of individual timeseries into a Pandas dataframe with one datetime index. With all arrays dataframes and series it is assumed that the first column contains the timestamps.\n\n\n\ntimeseries_dataframe\n\ndef timeseries_dataframe(\n    data:Union, timezone:str='UTC', columnnames:NoneType=None\n):\n\nConvert various tabular data formats to timeseries DataFrame\nArgs: data (Union[pd.DataFrame, pd.Series, dict, np.ndarray, np.recarray]): The input data to be converted. timezone (str, optional): The timezone to set for the index of the DataFrame. Defaults to UTC. columnnames (Optional[List[str]]): The column names to use for the DataFrame. Defaults to None.\nReturns: pd.DataFrame: The converted timeseries DataFrame with the index set to the specified timezone.\n\n\ntimeseries_dataframe_from_datadict\n\n\n\ntimeseries_dataframe_from_datadict\n\ndef timeseries_dataframe_from_datadict(\n    data:dict, timecolumns:NoneType=None, recordformat:str='records'\n):\n\nConverts a data dict into a pandas DataFrame based on the specified record format.  Parameters: - data: A dictionary containing the data to convert. - timecolumns: A list of column names to be treated as time columns. - recordformat: A string specifying the format of the data records (records, table, split, index, tight). Returns: - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n\n\nExported source\ndef timeseries_dataframe_from_datadict(\n        data:dict, \n        timecolumns=None,\n        recordformat='records'):\n        \n    \"\"\"\n    Converts a data dict into a pandas DataFrame based on the specified record format. \n    Parameters:\n        - data: A dictionary containing the data to convert.\n        - timecolumns: A list of column names to be treated as time columns.\n        - recordformat: A string specifying the format of the data records ('records', 'table', 'split', 'index', 'tight').\n    Returns:\n        - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n    \"\"\"\n\n    orient = recordformat.lower()\n    assert orient in ['records', 'table', 'split', 'index', 'tight']\n    assert timecolumns, 'No time columns specified'\n\n    if orient == 'records':\n        # data is a structured ndarray, sequence of tuples or dicts, or DataFrame\n        df = pd.DataFrame.from_records(data)\n        time_columns_in_df = [C for C in df.columns if C in timecolumns]\n        if not  time_columns_in_df:\n            #syslog.error(f\"No  column in records {df.columns} matches specification in time columns {timecolumns}, assuming first column is time\")\n            time_column = df.columns[0]\n        else:\n            time_column = time_columns_in_df[0]\n\n    elif orient == 'table':\n        # data is in pandas table format\n        time_column = data['schema']['primaryKey'][0]\n        df = pd.DataFrame.from_dict(data['data']).set_index(data['schema']['primaryKey'])\n        df.index.name = 'time'\n    else:\n        # data  is formatted according to 'orient' parameter (pandas)\n        df = pd.DataFrame.from_dict(data, orient=orient) # type: ignore\n        time_column = df.index.name\n\n\n    df.columns = list(df.columns)\n    df[time_column] = pd.to_datetime(df[time_column],utc=True,format='ISO8601')\n    df.set_index(time_column, inplace=True)\n    df.index = pd.DatetimeIndex(df.index).round('ms')\n    \n    df.index.name = 'time'\n\n    return df\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.000Z\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.000Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      }\n   ], timecolumns=['time'])\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 10:04:49+00:00', '2023-05-04 10:24:51+00:00',\n               '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = set_time_index_zone( timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53\",\n         \"value\":16.55\n      }\n   ], timecolumns=['time']), timezone='Europe/Amsterdam')\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 12:04:49+02:00\n16.72\n\n\n2023-05-04 12:24:51+02:00\n16.65\n\n\n2023-05-04 12:44:53+02:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 12:04:49+02:00', '2023-05-04 12:24:51+02:00',\n               '2023-05-04 12:44:53+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', name='time', freq=None)",
    "crumbs": [
      "Core functionality"
    ]
  }
]