[
  {
    "objectID": "aicorebridge.html",
    "href": "aicorebridge.html",
    "title": "AICore-Bridge",
    "section": "",
    "text": "import json\nimport os\n\nfrom corebridge.timeseriesdataframe import test_data_dict_3_samples\nfrom corebridge.core import init_console_logging\nsyslog = init_console_logging(__name__, logging.DEBUG, timestamp=False)",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#support-functions",
    "href": "aicorebridge.html#support-functions",
    "title": "AICore-Bridge",
    "section": "Support functions",
    "text": "Support functions\n\nPop NaN values\n\nsource\n\n\npop_nan_values\n\n pop_nan_values (data)\n\n*Recursively pop keys with nan values from dict or lists with dicts. Use just before handing data to AICore for further processing since it explodes when encountering NaN values.\nArgs: data (Union[list, dict]): The data to be processed.\nReturns: Union[list, dict]: The processed data with keys with nan values removed.*\n\ntest_data_with_nan = test_data_dict_3_samples.copy() + [\n   {\n      \"time\":\"2023-05-04T11:44:53.000Z\",\n      \"value\":np.nan\n   }\n\n]\nprint(json.dumps(test_data_with_nan, indent=3))\n\n[\n   {\n      \"time\": \"2023-05-04T10:04:49.000Z\",\n      \"value\": 16.72\n   },\n   {\n      \"time\": \"2023-05-04T10:24:51.000Z\",\n      \"value\": 16.65\n   },\n   {\n      \"time\": \"2023-05-04T10:44:53.000Z\",\n      \"value\": 16.55\n   },\n   {\n      \"time\": \"2023-05-04T11:44:53.000Z\",\n      \"value\": NaN\n   }\n]\n\n\n\nprint(json.dumps(pop_nan_values(test_data_with_nan), indent=3))\n\n[\n   {\n      \"time\": \"2023-05-04T10:04:49.000Z\",\n      \"value\": 16.72\n   },\n   {\n      \"time\": \"2023-05-04T10:24:51.000Z\",\n      \"value\": 16.65\n   },\n   {\n      \"time\": \"2023-05-04T10:44:53.000Z\",\n      \"value\": 16.55\n   },\n   {\n      \"time\": \"2023-05-04T11:44:53.000Z\"\n   }\n]\n\n\n\n\nBuild historic args\n\nsource\n\n\nbuild_historic_args\n\n build_historic_args (data:pandas.core.frame.DataFrame, history:dict|list)\n\nCreate a timeseries DataFrame from historic data defined in history.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nDataFrame\nThe input time-series DataFrame.\n\n\nhistory\ndict | list\nHistoric data definition, each item in the list is a dictionary with a startDate key to set the start of a section of historic data in the result and a column-value pair for each of the columns.\n\n\nReturns\ndict\nHistoric data in dictionary format where keys are column names and values are the historic values as numpy array.\n\n\n\n\ntest_data=set_time_index_zone(timeseries_dataframe_from_datadict(\n   [\n      {\n         \"time\":\"2023-05-04T10:04:49\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51\",\n         \"value\":16.65\n      }\n   ], ['datetimeMeasure', 'time'], 'records'), 'UTC').sort_index()\n\nConverting flat data dict to DataFrame with orient=records and timecolumns=['datetimeMeasure', 'time']\n\n\n\ntest_data\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\nhistory_arg = [\n                dict(justANumber=1.0),\n                dict(startDate=\"2023-05-04T10:25:00+00:00\", justANumber=2.0)\n            ]\nbuild_historic_args(test_data,history_arg)\n\n\n\n\n\n\n\n\njustANumber\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n1.0\n\n\n2023-05-04 10:24:51+00:00\n1.0\n\n\n2023-05-04 10:44:53+00:00\n2.0\n\n\n\n\n\n\n\n\nassert len(test_data) == len(build_historic_args(test_data,history_arg)['justANumber']), \"build_historic_args failed to build historic data\"",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#class-aicoremodulebase",
    "href": "aicorebridge.html#class-aicoremodulebase",
    "title": "AICore-Bridge",
    "section": "Class AICoreModuleBase",
    "text": "Class AICoreModuleBase\nIn the third iteration of the AICore module the initializer signature changes from\n    def __init__(\n        self, \n        save_dir:str, # path where the module can keep files \n        assets_dir:str, # path to support files (scripts, metadata, etc)\n        *args, **kwargs\n    ):\nto the almost identical signature\n\n    def __init__(\n        self, \n        files_dir, \n        save_dir\n    ):\nNote how the order of the folder arguments is reversed. We can adapt by\n\ntreating original assets_dir as save_dir and vice versa OR\nrewrite the method to match the new signature and change the signatures of the derived classes in each module\n\n\nsource\n\nAICoreModuleBase\n\n AICoreModuleBase (files_dir, save_dir, **kwargs)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nExported source\nclass AICoreModuleBase:\n\n    def __init__(\n        self, \n        files_dir, \n        save_dir,\n        **kwargs\n    ):\n        \n        self.init_time = datetime.datetime.now(datetime.UTC)\n        self.aicorebridge_version = __version__\n\n        self.init_args = []\n        self.init_kwargs = dict(\n            files_dir=files_dir,\n            save_dir=save_dir,\n            **kwargs\n        )\n\n\n        syslog.info(f\"Init {self.__class__.__name__}, version {self.aicorebridge_version}, files directory {files_dir}, save dir {save_dir} on {platform.node()}\")\n\n\n\nsave_dir = os.path.join(os.getcwd(), 'cache')\nfiles_dir = os.path.join(os.getcwd(), 'cache')\ntest_module = AICoreModuleBase(files_dir, save_dir)\n\nassert test_module.init_kwargs['save_dir'] == save_dir, f\"init_kwargs['save_dir'] should be {save_dir}\"\nassert test_module.init_kwargs['files_dir'] == files_dir, f\"init_kwargs['files_dir'] should be {files_dir}\"\n\nINFO    9588    root    2001759155.py   22  Init AICoreModuleBase, version 0.6.1, files directory /home/fenke/repos/corebridge/nbs/cache, save dir /home/fenke/repos/corebridge/nbs/cache on bouwdoosje\n\n\n\ntest_module.__dict__\n\n{'init_time': datetime.datetime(2025, 10, 13, 13, 55, 9, 301785, tzinfo=datetime.timezone.utc),\n 'aicorebridge_version': '0.6.1',\n 'init_args': [],\n 'init_kwargs': {'files_dir': '/home/fenke/repos/corebridge/nbs/cache',\n  'save_dir': '/home/fenke/repos/corebridge/nbs/cache'}}",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#class-aicoremodule",
    "href": "aicorebridge.html#class-aicoremodule",
    "title": "AICore-Bridge",
    "section": "Class AICoreModule",
    "text": "Class AICoreModule\n\nsource\n\nAICoreModule\n\n AICoreModule (processor:Callable, files_dir:str, save_dir:str, **kwargs)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nType\nDetails\n\n\n\n\nprocessor\nCallable\ndata processing function\n\n\nfiles_dir\nstr\npath where the module can keep files\n\n\nsave_dir\nstr\n\n\n\nkwargs\nVAR_KEYWORD\n\n\n\n\n\n\nExported source\nclass AICoreModule(AICoreModuleBase):\n    def __init__(self, \n        processor:typing.Callable, # data processing function\n        files_dir:str,              # path where the module can keep files \n        save_dir:str,\n        **kwargs\n    ):\n    \n        super().__init__(files_dir, save_dir, **kwargs)\n        self._init_processor(processor)\n\n\n\nsource\n\n\nAICoreModule.call_processor\n\n AICoreModule.call_processor (calldata, **callargs)\n\n\n\nExported source\n# TODO: Refactor into Processor classes to handle different funtion types\n\n@patch\ndef _init_processor(\n        self:AICoreModule, \n        processor:typing.Callable):\n    \"\"\"Initializes processor related variables on self\"\"\"\n    \n    self.processor = processor\n    self.processor_signature = inspect.signature(self.processor)\n    self.processor_params = dict(self.processor_signature.parameters)\n    self.return_param = self.processor_params.pop('return', None)\n    \n    self.data_param, *self.call_params = list(self.processor_params.keys())\n\n    if not (\n        self.processor_params[self.data_param].annotation == pd.DataFrame\n        or self.processor_params[self.data_param].annotation == np.ndarray\n\n    ):\n\n        self.data_param = None\n        self.call_params = list(self.processor_params.keys())\n\n\n\n\nExported source\n# can be overloaded\n@patch\ndef call_processor(self:AICoreModule, calldata, **callargs):\n    if self.data_param:\n        return self.processor(calldata, **callargs)\n    else:\n        return self.processor(**callargs)\n\n\n\n\ncall\nThe new entry point from AICore with the following signature\ndef call(self, data, files)\nThis method, originally called by earlier versions of AICore, is responsible for processing the data and parameters request recieved by AICore. Infer takes a data parameter which contains the contents of the data key in the request body. Additionally an optional list of files that were send with the request - these are currently ignored - and finally the contents of the kwargs key in the request body.\n\nsource\n\n\nAICoreModule.call\n\n AICoreModule.call (data:dict, *_, **__)\n\nInfer the data using the processor function.\n\n\nExported source\n@patch\ndef call(self:AICoreModule, data:dict, *_, **__):\n    \"\"\"Infer the data using the processor function.\"\"\"\n\n    payload_data = data\n\n    msg=[\n        f\"Startup: time {self.init_time.isoformat()}, node {platform.node()}\",\n        f\"Corebridge version: {self.aicorebridge_version}\",\n    ]\n\n    try:\n        t00 = time.perf_counter_ns()\n\n        kwargs = payload_data.get('kwargs', {})\n        data = payload_data.get('data', {})\n\n        msg+=[\n            f\"{self.processor.__name__}({self.processor_signature})\",  \n            f\"Data: {type(data)} length: {len(data)}\",    \n            f\"kwargs {list(kwargs.keys())}\",       \n            #f\"init_args: {self.init_args}, init_kwargs: {self.init_kwargs}\",\n        ]\n\n        # Pickup params, pop those that are not intended for the processor\n        lastSeen = kwargs.pop('lastSeen', False)\n        recordformat = kwargs.pop('format', \"records\").lower()\n        timezone = kwargs.get('timezone', 'UTC')\n        nested = kwargs.pop('nested', False)\n        msg.append(f\"lastSeen: {lastSeen}, timezone: {timezone}, recordformat: {recordformat}, nested: {nested}\")\n\n        samplerPeriod = kwargs.pop('samplerPeriod', self.init_kwargs.get('samplerPeriod','h'))\n        samplerMethod = kwargs.pop('samplerMethod', self.init_kwargs.get('samplerMethod',None))\n        reversed = kwargs.pop('reversed', False)\n\n        calldata = self.get_call_data(\n            data, \n            recordformat=recordformat,\n            timezone=timezone,\n            nested=nested,)\n        \n        history = build_historic_args(calldata, kwargs.pop('history', {}))\n        callargs = self.get_callargs(kwargs, history)\n\n        # for arg, val in callargs.items():\n        #     msg.append(f\"{arg}: {val}\")\n        \n        t02 = time.perf_counter_ns()\n        calculated_result = self.call_processor(\n            calldata, \n            **callargs\n        )\n        t03 = time.perf_counter_ns()\n        msg.append(f\"Processing time: {(t03-t02)/1e6:.1f} ms\")\n        msg.append(f\"Preparation time: {(t02-t00)/1e6:.1f} ms\")\n\n        if isinstance(calculated_result, dict):\n            msg.append(f\"return-data ictionary keys: {calculated_result.keys()}\")\n            return {\n                'msg':msg,\n                'data': [calculated_result]\n            }\n        elif isinstance(calculated_result, list):\n            msg.append(f\"return-data list length: {len(calculated_result)}\")\n            return {\n                'msg':msg,\n                'data': calculated_result\n            }\n\n        try:\n            result = timeseries_dataframe(\n                calculated_result, \n                timezone=timezone)\n            \n            msg.append(f\"result shape: {result.shape}\")\n\n            if samplerMethod:\n                msg.append(f\"Sampler: {samplerMethod}, period: {samplerPeriod}\")\n                result = timeseries_dataframe_resample(result, samplerPeriod, samplerMethod)\n\n            msg.append(f\"return-data shape: {result.shape}\")\n\n            if reversed:\n                result = result[::-1]\n\n            return {\n                'msg':msg,\n                'data': pop_nan_values( timeseries_dataframe_to_datadict(\n                    result if not lastSeen else result[-1:],\n                    recordformat=recordformat,\n                    timezone=timezone))\n            }\n        \n        # tries dataframe return\n        except Exception as err:\n            msg.append(f\"No timeseries data, error={err}\")\n        \n        df = pd.DataFrame(calculated_result)\n        df\n        df.columns = [f\"value_{str(c)}\" if isinstance(c, int) else str(c) for c in list(df.columns)]\n        df.reset_index().to_dict(orient='records')\n        return {\n            'msg':msg,\n            'data': pop_nan_values( df.reset_index().to_dict(orient='records') )\n        }\n\n    \n    # function try-catch\n    except Exception as err:\n        msg.append(''.join(traceback.format_exception(None, err, err.__traceback__)))\n        return {\n            'msg': msg,\n            'data': []\n        }\n\n\n\n\nget_callargs\n\n\nExported source\n# Specialized types for initializing annotated parameters\n# Add types by adding a tuple with the type name and a builder function\nannotated_arg_builders = {\n    str(B[0]):B[1] for B in [\n        (np.ndarray, lambda X: np.array(X, dtype=X.dtype))\n    ]\n}\n\n\n\nannotated_arg_builders\n\n{\"&lt;class 'numpy.ndarray'&gt;\": &lt;function __main__.&lt;lambda&gt;(X)&gt;}\n\n\n\nsource\n\n\nAICoreModule.init_annotated_param\n\n AICoreModule.init_annotated_param (param_name, value)\n\n*Initialize argument for the processor call\nparam_name: name of the parameter to be initialized value: value of the parameter read from infer data to be used for initialization*\n\n\nExported source\n@patch\ndef init_annotated_param(self:AICoreModule, param_name, value):\n    \"\"\"\n    Initialize argument for the processor call\n    \n    param_name: name of the parameter to be initialized\n    value: value of the parameter read from infer data to be used for initialization\n    \n    \"\"\"\n\n    annotation = self.processor_signature.parameters[param_name].annotation\n    #print(f\"param_name: {param_name}, value: {value}, annotation: {annotation}\")\n\n    # try to convert value to one of the types in the builders of annotated_arg_builders\n    for T in typing.get_args(annotation):\n        try:\n            builder = annotated_arg_builders.get(str(T), lambda X:T(X))\n            return builder(value)\n        \n        except TypeError as err:\n            continue\n\n    try:\n        return annotation(value)\n    \n    except TypeError as err:\n        syslog.exception(f\"Exception {str(err)} in fallback conversion to {annotation} of {type(value)}\")\n\n\n\nsource\n\n\nAICoreModule.get_callargs\n\n AICoreModule.get_callargs (kwargs, history)\n\nGet arguments for the processor call\n\n\nExported source\n@patch\ndef get_callargs(self:AICoreModule, kwargs, history):\n    \"Get arguments for the processor call\"\n\n    # Remove null / None values\n    kwargs = {k:v for k,v in kwargs.items() if v is not None}\n    \n    call_args = {\n        K:self.init_annotated_param(\n            K,\n            history.get(\n                K,\n                kwargs.get(\n                    K,\n                    self.init_kwargs.get(\n                        K, \n                        history.get(\n                            snake_case_to_camel_case(K),\n                            kwargs.get(\n                                snake_case_to_camel_case(K),\n                                self.init_kwargs.get(\n                                    snake_case_to_camel_case(K), \n                                    self.processor_signature.parameters[K].default\n                                )\n                            )\n                        )\n                    )\n                )\n            )\n        )\n        for K in self.call_params\n    }\n\n    return call_args\n\n\n\ndef processor_function(data:pd.DataFrame, just_a_number:float|np.ndarray):\n    return just_a_number * data\n\ntest_module = AICoreModule(processor_function, os.path.join(os.getcwd(), 'cache'), os.path.join(os.getcwd(), 'cache'))\nassert 'just_a_number' in test_module.get_callargs(\n    {\n        'justANumber': 2\n    },\n    {}\n   \n), \"get_callargs failed to translate camel-case processor argument to snake-case kwargs argument\"\n\nINFO    9588    root    2001759155.py   22  Init AICoreModule, version 0.6.1, files directory /home/fenke/repos/corebridge/nbs/cache, save dir /home/fenke/repos/corebridge/nbs/cache on bouwdoosje\n\n\n\n\nget_call_data\n\nsource\n\n\nAICoreModule.get_call_data\n\n AICoreModule.get_call_data (data:dict|list, recordformat='records',\n                             timezone='UTC', nested=False)\n\nConvert data to the processor signature\n\n\nExported source\n@patch\ndef get_call_data(\n        self:AICoreModule, \n        data:dict|list, \n        recordformat='records', \n        timezone='UTC',\n        nested=False):\n    \n    \"Convert data to the processor signature\"\n    \n    if not self.data_param:\n        return None\n    \n    #print(f\"recordformat: {recordformat}, timezone: {timezone}, nested: {nested}\" )\n\n    df = set_time_index_zone(timeseries_dataframe_from_datadict(\n        data, ['datetimeMeasure', 'time'], recordformat=recordformat, nested=nested), timezone)\n\n    df.sort_index(inplace=True)\n\n    if self.processor_params[self.data_param].annotation == pd.DataFrame:\n        return df\n    elif len(df.columns) &gt; 1:\n        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)\n        return df.to_records(index=True)\n    else:\n        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)\n        return df.reset_index().to_numpy()\n\n\n\ntest_data\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(test_data)\n\n[{'time': '2023-05-04T10:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55}]\n\n\n\ncalldata = test_module.get_call_data(timeseries_dataframe_to_datadict(test_data))\ncalldata\n\nrecordformat: records, timezone: UTC, nested: False\nConverting flat data dict to DataFrame with orient=records and timecolumns=['datetimeMeasure', 'time']\n\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\nhistory = build_historic_args(calldata,history_arg)\nhistory\n\n\n\n\n\n\n\n\njustANumber\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n2.0\n\n\n2023-05-04 10:24:51+00:00\n2.0\n\n\n2023-05-04 10:44:53+00:00\n2.0\n\n\n\n\n\n\n\n\ncalldata\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\nprint(test_module.get_callargs(calldata, history))\n\n{'just_a_number': array([2., 2., 2.])}\n\n\n\nnp.array(history['justANumber'])\n\narray([2., 2., 2.])\n\n\n\nhistory\n\n\n\n\n\n\n\n\njustANumber\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n2.0\n\n\n2023-05-04 10:24:51+00:00\n2.0\n\n\n2023-05-04 10:44:53+00:00\n2.0\n\n\n\n\n\n\n\n\ntest_module.init_annotated_param(\n    'just_a_number',\n    12.34\n)\n\n12.34\n\n\n\ntest_module.processor_signature.parameters['just_a_number'].annotation\n\nfloat | numpy.ndarray\n\n\n\nnp.array(history['justANumber'])\n\narray([2., 2., 2.])\n\n\n\nannotated_arg_builders[str(np.ndarray)](history['justANumber'])\n\narray([2., 2., 2.])\n\n\n\nassert True, 'stop'\n\n\n\nTests\n\nimport os, pandas as pd, numpy as np\n\n\ndef test_function(data:pd.DataFrame, anumber:float|np.ndarray=0):\n    return data * anumber\n\n\ndef test_simple_function(anumber:float, another:float):\n    return [another * anumber]\n\n\nclass TestAICoreModule(AICoreModule):\n    def __init__(self, files_dir, save_dir):\n        super().__init__(test_function, files_dir, save_dir)\n\n\nclass SimpleAICoreModule(AICoreModule):\n    def __init__(self, files_dir, save_dir):\n        super().__init__(test_simple_function, files_dir, save_dir)\n\n\nsave_dir = os.path.join(os.getcwd(), 'cache')\nfiles_dir = os.path.join(os.getcwd(), 'cache')\n\ntest_module = TestAICoreModule(files_dir, save_dir)\n\nassert test_module.init_kwargs['save_dir'] == save_dir, f\"init_kwargs['save_dir'] should be {save_dir}\"\nassert test_module.init_kwargs['files_dir'] == files_dir, f\"init_kwargs['files_dir'] should be {files_dir}\"\n\nINFO    9588    root    2001759155.py   22  Init TestAICoreModule, version 0.6.1, files directory /home/fenke/repos/corebridge/nbs/cache, save dir /home/fenke/repos/corebridge/nbs/cache on bouwdoosje\n\n\n\ntest_data = [\n    dict(datetimeMeasure='2020-04-01T00:01:11.123Z', value=1.1),\n    dict(datetimeMeasure='2020-04-02T00:20:00Z', value=2.3),\n]\nresult = test_module.call(dict(data=test_data, kwargs=dict(timezone='Europe/Amsterdam', anumber=2)))\n\nprint(\"Test Data\\n\", json.dumps(test_data, indent=2))\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2, cls=NumpyEncoder))\n\nrecordformat: records, timezone: Europe/Amsterdam, nested: False\nConverting flat data dict to DataFrame with orient=records and timecolumns=['datetimeMeasure', 'time']\nTest Data\n [\n  {\n    \"datetimeMeasure\": \"2020-04-01T00:01:11.123Z\",\n    \"value\": 1.1\n  },\n  {\n    \"datetimeMeasure\": \"2020-04-02T00:20:00Z\",\n    \"value\": 2.3\n  }\n]\nResult Message\n [\n  \"Startup: time 2025-10-13T13:55:09.561683+00:00, node bouwdoosje\",\n  \"Corebridge version: 0.6.1\",\n  \"test_function((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 2\",\n  \"kwargs ['timezone', 'anumber']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.2 ms\",\n  \"Preparation time: 19.4 ms\",\n  \"result shape: (2, 1)\",\n  \"return-data shape: (2, 1)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2020-04-01T02:01:11.123+02:00\",\n    \"value\": 2.2\n  },\n  {\n    \"time\": \"2020-04-02T02:20:00.000+02:00\",\n    \"value\": 4.6\n  }\n]\n\n\n\ntest_module.processor_signature.parameters['data'].annotation\n\npandas.core.frame.DataFrame\n\n\n\nannotation = test_module.processor_signature.parameters['anumber'].annotation\nprint(typing.get_args(annotation))\n\n(&lt;class 'float'&gt;, &lt;class 'numpy.ndarray'&gt;)\n\n\n\nfor T in typing.get_args(annotation):\n    print(T(0))\n\n0.0\n[]\n\n\n\nSimple module\n\nsimple_module = SimpleAICoreModule(files_dir,save_dir)\n\nassert simple_module.init_kwargs['save_dir'] == save_dir\n\nINFO    9588    root    2001759155.py   22  Init SimpleAICoreModule, version 0.6.1, files directory /home/fenke/repos/corebridge/nbs/cache, save dir /home/fenke/repos/corebridge/nbs/cache on bouwdoosje\n\n\n\nnot simple_module.data_param\n\nTrue\n\n\n\nsimple_module.call_params\n\n['anumber', 'another']\n\n\n\nresult = simple_module.call(dict(data=[], kwargs=dict(timezone='Europe/Amsterdam', anumber=2, another=11))) #dict(data=[], kwargs=dict(timezone='Europe/Amsterdam', anumber=2, another=11)\n\n\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2))\n\nResult Message\n [\n  \"Startup: time 2025-10-13T13:55:09.638778+00:00, node bouwdoosje\",\n  \"Corebridge version: 0.6.1\",\n  \"test_simple_function((anumber: float, another: float))\",\n  \"Data: &lt;class 'list'&gt; length: 0\",\n  \"kwargs ['timezone', 'anumber', 'another']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.0 ms\",\n  \"Preparation time: 0.1 ms\",\n  \"return-data list length: 1\"\n]\nResult Data\n [\n  22.0\n]\n\n\n\n\n\nTests with library module\n\nimport corebridge.core\n\n\nfrom corebridge.aicorebridge import AICoreModule\n\nDEBUG   9588    corebridge.aicorebridge aicorebridge.py 35  Loading corebridge.aicorebridge 0.6.1 from /home/fenke/repos/corebridge/corebridge/aicorebridge.py\n\n\n\nclass TestAICoreModule(AICoreModule):\n    def __init__(self, files_dir, save_dir):\n        super().__init__(test_function, files_dir, save_dir)\n        \ntest_module = TestAICoreModule(files_dir, save_dir)\n\nassert test_module.init_kwargs['save_dir'] == save_dir\nassert test_module.init_kwargs['files_dir'] == files_dir\n\nINFO    9588    corebridge.aicorebridge aicorebridge.py 134 Init TestAICoreModule, version 0.6.1, files directory /home/fenke/repos/corebridge/nbs/cache, save dir /home/fenke/repos/corebridge/nbs/cache on bouwdoosje\n\n\n\ntest_data = [\n    dict(datetimeMeasure='2020-04-01T00:01:11.123Z', value=1.1),\n    dict(datetimeMeasure='2020-04-02T00:20:00Z', value=2.3),\n]\nresult = test_module.call(dict(data=test_data, kwargs=dict(timezone='Europe/Amsterdam', anumber=2)))\n\nprint(\"Test Data\\n\", json.dumps(test_data, indent=2))\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2, cls=NumpyEncoder))\n\nrecordformat: records, timezone: Europe/Amsterdam, nested: False\nConverting flat data dict to DataFrame with orient=records and timecolumns=['datetimeMeasure', 'time']\nTest Data\n [\n  {\n    \"datetimeMeasure\": \"2020-04-01T00:01:11.123Z\",\n    \"value\": 1.1\n  },\n  {\n    \"datetimeMeasure\": \"2020-04-02T00:20:00Z\",\n    \"value\": 2.3\n  }\n]\nResult Message\n [\n  \"Startup: time 2025-10-13T13:55:09.715945+00:00, node bouwdoosje\",\n  \"Corebridge version: 0.6.1\",\n  \"test_function((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 2\",\n  \"kwargs ['timezone', 'anumber']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.1 ms\",\n  \"Preparation time: 2.2 ms\",\n  \"result shape: (2, 1)\",\n  \"return-data shape: (2, 1)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2020-04-01T02:01:11.123+02:00\",\n    \"value\": 2.2\n  },\n  {\n    \"time\": \"2020-04-02T02:20:00.000+02:00\",\n    \"value\": 4.6\n  }\n]\n\n\n\nprint(\"Test Data\\n\", json.dumps(test_data, indent=2))\nprint(\"Result Message\\n\", json.dumps(result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(result['data'], indent=2, cls=NumpyEncoder))\n\nTest Data\n [\n  {\n    \"datetimeMeasure\": \"2020-04-01T00:01:11.123Z\",\n    \"value\": 1.1\n  },\n  {\n    \"datetimeMeasure\": \"2020-04-02T00:20:00Z\",\n    \"value\": 2.3\n  }\n]\nResult Message\n [\n  \"Startup: time 2025-10-13T13:55:09.715945+00:00, node bouwdoosje\",\n  \"Corebridge version: 0.6.1\",\n  \"test_function((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 2\",\n  \"kwargs ['timezone', 'anumber']\",\n  \"lastSeen: False, timezone: Europe/Amsterdam, recordformat: records, nested: False\",\n  \"Processing time: 0.1 ms\",\n  \"Preparation time: 2.2 ms\",\n  \"result shape: (2, 1)\",\n  \"return-data shape: (2, 1)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2020-04-01T02:01:11.123+02:00\",\n    \"value\": 2.2\n  },\n  {\n    \"time\": \"2020-04-02T02:20:00.000+02:00\",\n    \"value\": 4.6\n  }\n]",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#various-experiments",
    "href": "aicorebridge.html#various-experiments",
    "title": "AICore-Bridge",
    "section": "Various experiments",
    "text": "Various experiments\n\nimport json\n\n\ntest_nested_data = json.loads(\"\"\"\n[\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:46:33.313Z\",\n        \"datetimeSource\": \"2025-07-21T09:46:33.313Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:46:33.691Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b4613d2ab820ec21e42a912a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": 0,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": 0,\n                        \"location\": {\n                            \"latitude\": 51.556896,\n                            \"longitude\": 5.865362\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1319,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:36:33.332Z\",\n        \"datetimeSource\": \"2025-07-21T09:36:33.332Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:36:33.697Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d0174603d2a9e20bf21dc2a802a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -104,\n                \"snr\": 5,\n                \"spreadingFactor\": 11,\n                \"frequency\": 867.3,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -104,\n                        \"snr\": 5,\n                        \"location\": {\n                            \"latitude\": 51.5569,\n                            \"longitude\": 5.865385\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1318,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:26:33.350Z\",\n        \"datetimeSource\": \"2025-07-21T09:26:33.350Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:26:33.705Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b45e3d2aa120ad21d42a5d2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -105,\n                \"snr\": 9,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.5,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -105,\n                        \"snr\": 9,\n                        \"location\": {\n                            \"latitude\": 51.556892,\n                            \"longitude\": 5.865356\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1317,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:16:33.368Z\",\n        \"datetimeSource\": \"2025-07-21T09:16:33.368Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:16:33.734Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01745d3d2ac320a621d12a5b2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -109,\n                \"snr\": 2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 866.6,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -109,\n                        \"snr\": 2,\n                        \"location\": {\n                            \"latitude\": 51.556892,\n                            \"longitude\": 5.865359\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1316,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T09:06:33.386Z\",\n        \"datetimeSource\": \"2025-07-21T09:06:33.386Z\",\n        \"datetimeAcquisition\": \"2025-07-21T09:06:33.748Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01345c3d2aa920b821d02a612a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": -2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.5,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": -2,\n                        \"location\": {\n                            \"latitude\": 51.556858,\n                            \"longitude\": 5.865352\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1315,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:56:33.405Z\",\n        \"datetimeSource\": \"2025-07-21T08:56:33.405Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:56:33.754Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01f45a3d2aa020c821d22a7d2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -115,\n                \"snr\": -6.25,\n                \"spreadingFactor\": 11,\n                \"frequency\": 866.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF010323\",\n                        \"rssi\": -115,\n                        \"snr\": -6.25,\n                        \"location\": {\n                            \"latitude\": 51.516491,\n                            \"longitude\": 5.884403\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1314,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:46:33.423Z\",\n        \"datetimeSource\": \"2025-07-21T08:46:33.423Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:46:33.778Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b4593d2ab920d121cf2a922a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": 8,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.5,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": 8,\n                        \"location\": {\n                            \"latitude\": 51.556862,\n                            \"longitude\": 5.865373\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1313,\n                \"counterDown\": 26,\n                \"errorRate\": 4\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:36:33.441Z\",\n        \"datetimeSource\": \"2025-07-21T08:36:33.441Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:36:33.821Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d0174583d2ac020e221cb2ada2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -106,\n                \"snr\": 2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 866.4,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -106,\n                        \"snr\": 2,\n                        \"location\": {\n                            \"latitude\": 51.55687,\n                            \"longitude\": 5.86535\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1312,\n                \"counterDown\": 26,\n                \"errorRate\": 6\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:26:33.460Z\",\n        \"datetimeSource\": \"2025-07-21T08:26:33.460Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:26:33.810Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d01b4563d2aa220db21c72aba2a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -103,\n                \"snr\": -2,\n                \"spreadingFactor\": 11,\n                \"frequency\": 868.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -103,\n                        \"snr\": -2,\n                        \"location\": {\n                            \"latitude\": 51.556854,\n                            \"longitude\": 5.865371\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1311,\n                \"counterDown\": 26,\n                \"errorRate\": 6\n            }\n        }\n    },\n    {\n        \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n        \"datetimeMeasure\": \"2025-07-21T08:16:33.560Z\",\n        \"datetimeSource\": \"2025-07-21T08:16:33.560Z\",\n        \"datetimeAcquisition\": \"2025-07-21T08:16:33.962Z\",\n        \"connector\": \"lora.kpn\",\n        \"value\": \"0d0174553d2ac220d821c52ad92a\",\n        \"metadata\": {\n            \"connection\": {\n                \"rssi\": -104,\n                \"snr\": -7,\n                \"spreadingFactor\": 11,\n                \"frequency\": 865.1,\n                \"gateways\": [\n                    {\n                        \"id\": \"FF01055A\",\n                        \"rssi\": -104,\n                        \"snr\": -7,\n                        \"location\": {\n                            \"latitude\": 51.556866,\n                            \"longitude\": 5.865384\n                        }\n                    }\n                ]\n            },\n            \"frame\": {\n                \"port\": 2,\n                \"counterUp\": 1310,\n                \"counterDown\": 26,\n                \"errorRate\": 6\n            }\n        }\n    }\n]\n\n\n  \"\"\")\n\n\nimport pandas as pd\nfrom corebridge.timeseriesdataframe import timeseries_dataframe_from_datadict\n\n\ndf_normalized = pd.json_normalize(\n    test_nested_data, \n    sep='.',\n    #record_prefix='metadata.'\n)\n\n\ndf_normalized.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10 entries, 0 to 9\nData columns (total 15 columns):\n #   Column                               Non-Null Count  Dtype  \n---  ------                               --------------  -----  \n 0   deviceId                             10 non-null     object \n 1   datetimeMeasure                      10 non-null     object \n 2   datetimeSource                       10 non-null     object \n 3   datetimeAcquisition                  10 non-null     object \n 4   connector                            10 non-null     object \n 5   value                                10 non-null     object \n 6   metadata.connection.rssi             10 non-null     int64  \n 7   metadata.connection.snr              10 non-null     float64\n 8   metadata.connection.spreadingFactor  10 non-null     int64  \n 9   metadata.connection.frequency        10 non-null     float64\n 10  metadata.connection.gateways         10 non-null     object \n 11  metadata.frame.port                  10 non-null     int64  \n 12  metadata.frame.counterUp             10 non-null     int64  \n 13  metadata.frame.counterDown           10 non-null     int64  \n 14  metadata.frame.errorRate             10 non-null     int64  \ndtypes: float64(2), int64(6), object(7)\nmemory usage: 1.3+ KB\n\n\n\ndfn = timeseries_dataframe_from_datadict(test_nested_data, ['datetimeMeasure', 'time'], recordformat='records', nested=True).dropna()\ndfn.info()\n\nConverting nested data dict to DataFrame with orient=records and timecolumns=['datetimeMeasure', 'time']\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 10 entries, 2025-07-21 09:46:33.313000+00:00 to 2025-07-21 08:16:33.560000+00:00\nData columns (total 14 columns):\n #   Column                               Non-Null Count  Dtype  \n---  ------                               --------------  -----  \n 0   deviceId                             10 non-null     object \n 1   datetimeSource                       10 non-null     object \n 2   datetimeAcquisition                  10 non-null     object \n 3   connector                            10 non-null     object \n 4   value                                10 non-null     object \n 5   metadata.connection.rssi             10 non-null     int64  \n 6   metadata.connection.snr              10 non-null     float64\n 7   metadata.connection.spreadingFactor  10 non-null     int64  \n 8   metadata.connection.frequency        10 non-null     float64\n 9   metadata.connection.gateways         10 non-null     object \n 10  metadata.frame.port                  10 non-null     int64  \n 11  metadata.frame.counterUp             10 non-null     int64  \n 12  metadata.frame.counterDown           10 non-null     int64  \n 13  metadata.frame.errorRate             10 non-null     int64  \ndtypes: float64(2), int64(6), object(6)\nmemory usage: 1.2+ KB\n\n\n\ndfn\n\n\n\n\n\n\n\n\ndeviceId\ndatetimeSource\ndatetimeAcquisition\nconnector\nvalue\nmetadata.connection.rssi\nmetadata.connection.snr\nmetadata.connection.spreadingFactor\nmetadata.connection.frequency\nmetadata.connection.gateways\nmetadata.frame.port\nmetadata.frame.counterUp\nmetadata.frame.counterDown\nmetadata.frame.errorRate\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025-07-21 09:46:33.313000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:46:33.313Z\n2025-07-21T09:46:33.691Z\nlora.kpn\n0d01b4613d2ab820ec21e42a912a\n-106\n0.00\n11\n868.1\n[{'id': 'FF01055A', 'rssi': -106, 'snr': 0, 'l...\n2\n1319\n26\n4\n\n\n2025-07-21 09:36:33.332000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:36:33.332Z\n2025-07-21T09:36:33.697Z\nlora.kpn\n0d0174603d2a9e20bf21dc2a802a\n-104\n5.00\n11\n867.3\n[{'id': 'FF01055A', 'rssi': -104, 'snr': 5, 'l...\n2\n1318\n26\n4\n\n\n2025-07-21 09:26:33.350000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:26:33.350Z\n2025-07-21T09:26:33.705Z\nlora.kpn\n0d01b45e3d2aa120ad21d42a5d2a\n-105\n9.00\n11\n868.5\n[{'id': 'FF01055A', 'rssi': -105, 'snr': 9, 'l...\n2\n1317\n26\n4\n\n\n2025-07-21 09:16:33.368000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:16:33.368Z\n2025-07-21T09:16:33.734Z\nlora.kpn\n0d01745d3d2ac320a621d12a5b2a\n-109\n2.00\n11\n866.6\n[{'id': 'FF01055A', 'rssi': -109, 'snr': 2, 'l...\n2\n1316\n26\n4\n\n\n2025-07-21 09:06:33.386000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T09:06:33.386Z\n2025-07-21T09:06:33.748Z\nlora.kpn\n0d01345c3d2aa920b821d02a612a\n-106\n-2.00\n11\n868.5\n[{'id': 'FF01055A', 'rssi': -106, 'snr': -2, '...\n2\n1315\n26\n4\n\n\n2025-07-21 08:56:33.405000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:56:33.405Z\n2025-07-21T08:56:33.754Z\nlora.kpn\n0d01f45a3d2aa020c821d22a7d2a\n-115\n-6.25\n11\n866.1\n[{'id': 'FF010323', 'rssi': -115, 'snr': -6.25...\n2\n1314\n26\n4\n\n\n2025-07-21 08:46:33.423000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:46:33.423Z\n2025-07-21T08:46:33.778Z\nlora.kpn\n0d01b4593d2ab920d121cf2a922a\n-106\n8.00\n11\n868.5\n[{'id': 'FF01055A', 'rssi': -106, 'snr': 8, 'l...\n2\n1313\n26\n4\n\n\n2025-07-21 08:36:33.441000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:36:33.441Z\n2025-07-21T08:36:33.821Z\nlora.kpn\n0d0174583d2ac020e221cb2ada2a\n-106\n2.00\n11\n866.4\n[{'id': 'FF01055A', 'rssi': -106, 'snr': 2, 'l...\n2\n1312\n26\n6\n\n\n2025-07-21 08:26:33.460000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:26:33.460Z\n2025-07-21T08:26:33.810Z\nlora.kpn\n0d01b4563d2aa220db21c72aba2a\n-103\n-2.00\n11\n868.1\n[{'id': 'FF01055A', 'rssi': -103, 'snr': -2, '...\n2\n1311\n26\n6\n\n\n2025-07-21 08:16:33.560000+00:00\n00209835-4443-4fee-ae1f-281082fcfbbc\n2025-07-21T08:16:33.560Z\n2025-07-21T08:16:33.962Z\nlora.kpn\n0d0174553d2ac220d821c52ad92a\n-104\n-7.00\n11\n865.1\n[{'id': 'FF01055A', 'rssi': -104, 'snr': -7, '...\n2\n1310\n26\n6\n\n\n\n\n\n\n\n\ndfm = timeseries_dataframe_from_datadict(test_nested_data, ['datetimeMeasure', 'time'], recordformat='records', nested=False).dropna()\ndfm.info()\n\nConverting flat data dict to DataFrame with orient=records and timecolumns=['datetimeMeasure', 'time']\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 10 entries, 2025-07-21 09:46:33.313000+00:00 to 2025-07-21 08:16:33.560000+00:00\nData columns (total 6 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   deviceId             10 non-null     object\n 1   datetimeSource       10 non-null     object\n 2   datetimeAcquisition  10 non-null     object\n 3   connector            10 non-null     object\n 4   value                10 non-null     object\n 5   metadata             10 non-null     object\ndtypes: object(6)\nmemory usage: 560.0+ bytes\n\n\n\ndef test_nested_data_processing(data:pd.DataFrame, anumber:float|np.ndarray=0):\n    print (f\"Processing {len(data)} rows of data\")\n    print(data.columns)\n    return data\n\n\nclass TestNestedAICoreModule(AICoreModule):\n    def __init__(self, files_dir, save_dir):\n        super().__init__(test_nested_data_processing, files_dir, save_dir)\n\ntest_nested_module = TestNestedAICoreModule(os.path.join(os.getcwd(), 'cache'),os.path.join(os.getcwd(), 'cache'))\n\nINFO    9588    corebridge.aicorebridge aicorebridge.py 134 Init TestNestedAICoreModule, version 0.6.1, files directory /home/fenke/repos/corebridge/nbs/cache, save dir /home/fenke/repos/corebridge/nbs/cache on bouwdoosje\n\n\n\ntest_result = test_nested_module.call(dict(\n    data=test_nested_data,\n    kwargs=dict(\n        timezone='UTC',\n        recordformat='records',\n        nested=True\n    )\n))\n\nrecordformat: records, timezone: UTC, nested: True\nConverting nested data dict to DataFrame with orient=records and timecolumns=['datetimeMeasure', 'time']\nProcessing 10 rows of data\nIndex(['deviceId', 'datetimeSource', 'datetimeAcquisition', 'connector',\n       'value', 'metadata.connection.rssi', 'metadata.connection.snr',\n       'metadata.connection.spreadingFactor', 'metadata.connection.frequency',\n       'metadata.connection.gateways', 'metadata.frame.port',\n       'metadata.frame.counterUp', 'metadata.frame.counterDown',\n       'metadata.frame.errorRate'],\n      dtype='object')\n\n\n\nprint(\"Result Message\\n\", json.dumps(test_result['msg'], indent=2, cls=NumpyEncoder))\nprint(\"Result Data\\n\", json.dumps(test_result['data'], indent=2, cls=NumpyEncoder))\n\nResult Message\n [\n  \"Startup: time 2025-10-13T13:55:09.873476+00:00, node bouwdoosje\",\n  \"Corebridge version: 0.6.1\",\n  \"test_nested_data_processing((data: pandas.core.frame.DataFrame, anumber: float | numpy.ndarray = 0))\",\n  \"Data: &lt;class 'list'&gt; length: 10\",\n  \"kwargs ['timezone', 'recordformat', 'nested']\",\n  \"lastSeen: False, timezone: UTC, recordformat: records, nested: True\",\n  \"Processing time: 0.3 ms\",\n  \"Preparation time: 4.9 ms\",\n  \"result shape: (10, 14)\",\n  \"return-data shape: (10, 14)\"\n]\nResult Data\n [\n  {\n    \"time\": \"2025-07-21T08:16:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:16:33.560Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:16:33.962Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d0174553d2ac220d821c52ad92a\",\n    \"metadata.connection.rssi\": -104,\n    \"metadata.connection.snr\": -7.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 865.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -104,\n        \"snr\": -7,\n        \"location\": {\n          \"latitude\": 51.556866,\n          \"longitude\": 5.865384\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1310,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 6\n  },\n  {\n    \"time\": \"2025-07-21T08:26:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:26:33.460Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:26:33.810Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b4563d2aa220db21c72aba2a\",\n    \"metadata.connection.rssi\": -103,\n    \"metadata.connection.snr\": -2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -103,\n        \"snr\": -2,\n        \"location\": {\n          \"latitude\": 51.556854,\n          \"longitude\": 5.865371\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1311,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 6\n  },\n  {\n    \"time\": \"2025-07-21T08:36:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:36:33.441Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:36:33.821Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d0174583d2ac020e221cb2ada2a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": 2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 866.4,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": 2,\n        \"location\": {\n          \"latitude\": 51.55687,\n          \"longitude\": 5.86535\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1312,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 6\n  },\n  {\n    \"time\": \"2025-07-21T08:46:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:46:33.423Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:46:33.778Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b4593d2ab920d121cf2a922a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": 8.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.5,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": 8,\n        \"location\": {\n          \"latitude\": 51.556862,\n          \"longitude\": 5.865373\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1313,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T08:56:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T08:56:33.405Z\",\n    \"datetimeAcquisition\": \"2025-07-21T08:56:33.754Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01f45a3d2aa020c821d22a7d2a\",\n    \"metadata.connection.rssi\": -115,\n    \"metadata.connection.snr\": -6.25,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 866.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF010323\",\n        \"rssi\": -115,\n        \"snr\": -6.25,\n        \"location\": {\n          \"latitude\": 51.516491,\n          \"longitude\": 5.884403\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1314,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:06:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:06:33.386Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:06:33.748Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01345c3d2aa920b821d02a612a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": -2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.5,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": -2,\n        \"location\": {\n          \"latitude\": 51.556858,\n          \"longitude\": 5.865352\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1315,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:16:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:16:33.368Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:16:33.734Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01745d3d2ac320a621d12a5b2a\",\n    \"metadata.connection.rssi\": -109,\n    \"metadata.connection.snr\": 2.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 866.6,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -109,\n        \"snr\": 2,\n        \"location\": {\n          \"latitude\": 51.556892,\n          \"longitude\": 5.865359\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1316,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:26:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:26:33.350Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:26:33.705Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b45e3d2aa120ad21d42a5d2a\",\n    \"metadata.connection.rssi\": -105,\n    \"metadata.connection.snr\": 9.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.5,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -105,\n        \"snr\": 9,\n        \"location\": {\n          \"latitude\": 51.556892,\n          \"longitude\": 5.865356\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1317,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:36:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:36:33.332Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:36:33.697Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d0174603d2a9e20bf21dc2a802a\",\n    \"metadata.connection.rssi\": -104,\n    \"metadata.connection.snr\": 5.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 867.3,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -104,\n        \"snr\": 5,\n        \"location\": {\n          \"latitude\": 51.5569,\n          \"longitude\": 5.865385\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1318,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  },\n  {\n    \"time\": \"2025-07-21T09:46:33Z\",\n    \"deviceId\": \"00209835-4443-4fee-ae1f-281082fcfbbc\",\n    \"datetimeSource\": \"2025-07-21T09:46:33.313Z\",\n    \"datetimeAcquisition\": \"2025-07-21T09:46:33.691Z\",\n    \"connector\": \"lora.kpn\",\n    \"value\": \"0d01b4613d2ab820ec21e42a912a\",\n    \"metadata.connection.rssi\": -106,\n    \"metadata.connection.snr\": 0.0,\n    \"metadata.connection.spreadingFactor\": 11,\n    \"metadata.connection.frequency\": 868.1,\n    \"metadata.connection.gateways\": [\n      {\n        \"id\": \"FF01055A\",\n        \"rssi\": -106,\n        \"snr\": 0,\n        \"location\": {\n          \"latitude\": 51.556896,\n          \"longitude\": 5.865362\n        }\n      }\n    ],\n    \"metadata.frame.port\": 2,\n    \"metadata.frame.counterUp\": 1319,\n    \"metadata.frame.counterDown\": 26,\n    \"metadata.frame.errorRate\": 4\n  }\n]\n\n\n\nprint(test_result['msg'][-1])\n\nreturn-data shape: (10, 14)",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "aicorebridge.html#references",
    "href": "aicorebridge.html#references",
    "title": "AICore-Bridge",
    "section": "References",
    "text": "References",
    "crumbs": [
      "AICore-Bridge"
    ]
  },
  {
    "objectID": "timeseriesdataframe.html",
    "href": "timeseriesdataframe.html",
    "title": "Timeseries datarames",
    "section": "",
    "text": "Timeseries data is a cornerstone of our data manipulation and most processing is on them\n\n\nProcessing may depend on proper timezone awareness, this utility to set the timezone on a datetime index\n\nsource\n\n\n\n\n set_time_index_zone (df:pandas.core.frame.DataFrame, timezone)\n\n*Sets the time zone of the index of a pandas DataFrame.\nArgs: df (pd.DataFrame): The DataFrame whose index time zone is to be set. timezone (str): The desired time zone.\nReturns: pd.DataFrame: The modified DataFrame with its index time zone set to the specified time zone.\nRaises: None\nExamples: &gt;&gt;&gt; df = pd.DataFrame({‘A’: [1, 2, 3]}, index=pd.DatetimeIndex([‘2022-01-01’, ‘2022-01-02’, ‘2022-01-03’])) &gt;&gt;&gt; set_time_index_zone(df, ‘Europe/Berlin’) A 2022-01-01 1 2022-01-02 2 2022-01-03 3 DatetimeIndex: 3 entries, 2022-01-01 01:00:00+01:00 to 2022-01-03 01:00:00+01:00*\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nDataframe to set or convert the timeindex on\n\n\ntimezone\n\nTimezone to set\n\n\n\n\n\n\ndf = pd.DataFrame({'A': [1, 2, 3]}, index=pd.DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03']))\nset_time_index_zone(df, 'Europe/Berlin')\ndf.index\n\nDatetimeIndex(['2022-01-01 01:00:00+01:00', '2022-01-02 01:00:00+01:00',\n               '2022-01-03 01:00:00+01:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='time', freq=None)\n\n\n\n\n\n\nConverts Pandas dataframes and series, Numpy array’s and recarrays or a dictionary of individual timeseries into a Pandas dataframe with one datetime index. With all arrays dataframes and series it is assumed that the first column contains the timestamps.\n\nsource\n\n\n\n\n timeseries_dataframe (data:Union[pandas.core.frame.DataFrame,pandas.core.\n                       series.Series,dict,numpy.ndarray,numpy.rec.recarray\n                       ], timezone='UTC', columnnames=None)\n\n*Convert various tabular data formats to timeseries DataFrame\nArgs: data (Union[pd.DataFrame, pd.Series, dict, np.ndarray, np.recarray]): The input data to be converted. timezone (str, optional): The timezone to set for the index of the DataFrame. Defaults to ‘UTC’. columnnames (Optional[List[str]]): The column names to use for the DataFrame. Defaults to None.\nReturns: pd.DataFrame: The converted timeseries DataFrame with the index set to the specified timezone.*\n\n\n\n\nsource\n\n\n\n\n timeseries_dataframe_from_datadict (data:dict, timecolumns=None,\n                                     recordformat='records', nested=False)\n\nConverts a data dict into a pandas DataFrame based on the specified record format. Parameters: - data: A dictionary containing the data to convert. - timecolumns: A list of column names to be treated as time columns. - recordformat: A string specifying the format of the data records (‘records’, ‘table’, ‘split’, ‘index’, ‘tight’). Returns: - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n\n\nExported source\ndef timeseries_dataframe_from_datadict(\n        data:dict, \n        timecolumns=None,\n        recordformat='records',\n        nested=False\n):\n        \n    \"\"\"\n    Converts a data dict into a pandas DataFrame based on the specified record format. \n    Parameters:\n        - data: A dictionary containing the data to convert.\n        - timecolumns: A list of column names to be treated as time columns.\n        - recordformat: A string specifying the format of the data records ('records', 'table', 'split', 'index', 'tight').\n    Returns:\n        - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n    \"\"\"\n\n    orient = recordformat.lower()\n    assert orient in ['records', 'table', 'split', 'index', 'tight']\n    assert timecolumns, 'No time columns specified'\n\n    #print(f\"Converting {'nested' if nested else 'flat'} data dict to DataFrame with orient={orient} and timecolumns={timecolumns}\")\n    \n    if orient == 'records':\n        if nested:\n            # data is a nested structure, we need to normalize it\n            df = pd.json_normalize(data, sep='.', errors='ignore')  # type: ignore\n\n        else:\n            # data is a structured ndarray, sequence of tuples or dicts, or DataFrame\n            df = pd.DataFrame.from_records(data, coerce_float=True)  # type: ignore\n            \n        time_columns_in_df = [C for C in df.columns if C in timecolumns]\n        if not  time_columns_in_df:\n            time_column = df.columns[0]\n        else:\n            time_column = time_columns_in_df[0]\n\n    elif orient == 'table':\n        # data is in pandas table format\n        time_column = data['schema']['primaryKey'][0]\n        df = pd.DataFrame.from_dict(data['data'], coerce_float=True).set_index(data['schema']['primaryKey'])\n        df.index.name = 'time'\n    else:\n        # data  is formatted according to 'orient' parameter (pandas)\n        df = pd.DataFrame.from_dict(data, orient=orient, coerce_float=True) # type: ignore\n        time_column = df.index.name\n\n\n    df.columns = list(df.columns)\n    df[time_column] = pd.to_datetime(df[time_column],utc=True,format='ISO8601')\n    df.set_index(time_column, inplace=True)\n    df.index = pd.DatetimeIndex(df.index).round('ms')\n    \n    df.index.name = 'time'\n\n    return df\n\n\n\ndf = timeseries_dataframe_from_datadict(test_data_dict_3_samples, timecolumns=['time'])\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 10:04:49+00:00', '2023-05-04 10:24:51+00:00',\n               '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = set_time_index_zone( \n    timeseries_dataframe_from_datadict(\n        test_data_dict_3_samples, \n        timecolumns=['time']\n    ), \n    timezone='Europe/Amsterdam'\n)\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 12:04:49+02:00\n16.72\n\n\n2023-05-04 12:24:51+02:00\n16.65\n\n\n2023-05-04 12:44:53+02:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 12:04:49+02:00', '2023-05-04 12:24:51+02:00',\n               '2023-05-04 12:44:53+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', name='time', freq=None)\n\n\n\n\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=3, freq='s').tz_convert('Europe/Amsterdam')\nrng\n\nDatetimeIndex(['2018-04-10 09:01:01.123000+02:00',\n               '2018-04-10 09:01:02.123000+02:00',\n               '2018-04-10 09:01:03.123000+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', freq='s')\n\n\n\nrng.strftime(\"%FT%R:%S%z\")\n\nIndex(['2018-04-10T09:01:01+0200', '2018-04-10T09:01:02+0200',\n       '2018-04-10T09:01:03+0200'],\n      dtype='object')\n\n\n\npd.DatetimeIndex(rng.strftime(\"%FT%R:%S%z\")).round('ms')\n\nDatetimeIndex(['2018-04-10 09:01:01+02:00', '2018-04-10 09:01:02+02:00',\n               '2018-04-10 09:01:03+02:00'],\n              dtype='datetime64[ns, UTC+02:00]', freq=None)\n\n\n\nrng.tz_convert('UTC').strftime(\"%FT%R:%SZ\")\n\nIndex(['2018-04-10T07:01:01Z', '2018-04-10T07:01:02Z', '2018-04-10T07:01:03Z'], dtype='object')\n\n\n\n# .map(lambda x: x.isoformat())\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=30000, freq='s').tz_convert('Europe/Amsterdam')\n\n\n\n\nft = rng.strftime(\"%FT%R:%S%z\")\n\n340 ms ± 18.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nft = rng.map(lambda x: x.isoformat(timespec='milliseconds'))\n\n136 ms ± 9.46 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n\n\nsource\n\n\n\n\n timeseries_dataframe_to_datadict\n                                   (data:Union[pandas.core.frame.DataFrame\n                                   ,pandas.core.series.Series,dict],\n                                   recordformat:str='records',\n                                   timezone:str='UTC')\n\n*Convert a timeseries DataFrame or Series into a dictionary representation.\nArgs: data (Union[pd.DataFrame, pd.Series, dict]): The input data to be converted. It can be a pandas DataFrame, Series, or a dictionary. recordformat (str, optional): The format of the output records. Defaults to ‘records’. timezone (str, optional): The timezone to use for the DataFrame index. Defaults to ‘UTC’.\nReturns: Union[dict, list]: The converted dictionary representation of the input data, a dictionary or a list of dictionaries depending on the recordformat parameter.*\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe(df, timezone='UTC').index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records')\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records', timezone='Europe/Berlin')\n\n[{'time': '2023-05-04T11:04:49.050+02:00', 'value': 16.72},\n {'time': '2023-05-04T12:24:51.010+02:00', 'value': 16.65},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': 16.55},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': nan}]\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='tight')\n\n{'index': ['2023-05-04T09:04:49Z',\n  '2023-05-04T10:24:51Z',\n  '2023-05-04T10:44:53Z',\n  '2023-05-04T10:44:53Z'],\n 'columns': ['value'],\n 'data': [[16.72], [16.65], [16.55], [nan]],\n 'index_names': ['time'],\n 'column_names': [None]}\n\n\n\ntest_data = timeseries_dataframe_to_datadict(df, recordformat='records')\n\n\ntest_data\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\nsource\n\n\n\n\n timeseries_dataframe_resample (df:pandas.core.frame.DataFrame,\n                                period:str, method:str)\n\n*Resamples a time-series DataFrame on the specified period and method.\nParameters: df (pd.DataFrame): The input time-series DataFrame. period (str): The resampling period. method (str): The resampling method. Can be a string of multiple methods separated by ‘;’. method_args (dict, optional): Additional arguments for the resampling method.\nReturns: pd.DataFrame: The resampled DataFrame.*\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.000Z\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.000Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T11:04:49.000Z\",\n         \"value\":16.47\n      },\n      {\n         \"time\":\"2023-05-04T11:24:51.000Z\",\n         \"value\":16.44\n      },\n      {\n         \"time\":\"2023-05-04T11:44:53.000Z\",\n         \"value\":16.38\n      },\n   ], timecolumns=['time'])\n\n\ntimeseries_dataframe_resample(df, \"80min\", 'mean;count')\n\n\n\n\n\n\n\n\nvalue\nvalue_mean\nvalue_count\n\n\ntime\n\n\n\n\n\n\n\n2023-05-04 09:20:00+00:00\nNaN\n16.685\n2.0\n\n\n2023-05-04 10:04:49+00:00\n16.72\nNaN\nNaN\n\n\n2023-05-04 10:24:51+00:00\n16.65\nNaN\nNaN\n\n\n2023-05-04 10:40:00+00:00\nNaN\n16.460\n4.0\n\n\n2023-05-04 10:44:53+00:00\n16.55\nNaN\nNaN\n\n\n2023-05-04 11:04:49+00:00\n16.47\nNaN\nNaN\n\n\n2023-05-04 11:24:51+00:00\n16.44\nNaN\nNaN\n\n\n2023-05-04 11:44:53+00:00\n16.38\nNaN\nNaN",
    "crumbs": [
      "Timeseries datarames"
    ]
  },
  {
    "objectID": "timeseriesdataframe.html#timeseries-dataframes",
    "href": "timeseriesdataframe.html#timeseries-dataframes",
    "title": "Timeseries datarames",
    "section": "",
    "text": "Timeseries data is a cornerstone of our data manipulation and most processing is on them\n\n\nProcessing may depend on proper timezone awareness, this utility to set the timezone on a datetime index\n\nsource\n\n\n\n\n set_time_index_zone (df:pandas.core.frame.DataFrame, timezone)\n\n*Sets the time zone of the index of a pandas DataFrame.\nArgs: df (pd.DataFrame): The DataFrame whose index time zone is to be set. timezone (str): The desired time zone.\nReturns: pd.DataFrame: The modified DataFrame with its index time zone set to the specified time zone.\nRaises: None\nExamples: &gt;&gt;&gt; df = pd.DataFrame({‘A’: [1, 2, 3]}, index=pd.DatetimeIndex([‘2022-01-01’, ‘2022-01-02’, ‘2022-01-03’])) &gt;&gt;&gt; set_time_index_zone(df, ‘Europe/Berlin’) A 2022-01-01 1 2022-01-02 2 2022-01-03 3 DatetimeIndex: 3 entries, 2022-01-01 01:00:00+01:00 to 2022-01-03 01:00:00+01:00*\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nDataframe to set or convert the timeindex on\n\n\ntimezone\n\nTimezone to set\n\n\n\n\n\n\ndf = pd.DataFrame({'A': [1, 2, 3]}, index=pd.DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03']))\nset_time_index_zone(df, 'Europe/Berlin')\ndf.index\n\nDatetimeIndex(['2022-01-01 01:00:00+01:00', '2022-01-02 01:00:00+01:00',\n               '2022-01-03 01:00:00+01:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='time', freq=None)\n\n\n\n\n\n\nConverts Pandas dataframes and series, Numpy array’s and recarrays or a dictionary of individual timeseries into a Pandas dataframe with one datetime index. With all arrays dataframes and series it is assumed that the first column contains the timestamps.\n\nsource\n\n\n\n\n timeseries_dataframe (data:Union[pandas.core.frame.DataFrame,pandas.core.\n                       series.Series,dict,numpy.ndarray,numpy.rec.recarray\n                       ], timezone='UTC', columnnames=None)\n\n*Convert various tabular data formats to timeseries DataFrame\nArgs: data (Union[pd.DataFrame, pd.Series, dict, np.ndarray, np.recarray]): The input data to be converted. timezone (str, optional): The timezone to set for the index of the DataFrame. Defaults to ‘UTC’. columnnames (Optional[List[str]]): The column names to use for the DataFrame. Defaults to None.\nReturns: pd.DataFrame: The converted timeseries DataFrame with the index set to the specified timezone.*\n\n\n\n\nsource\n\n\n\n\n timeseries_dataframe_from_datadict (data:dict, timecolumns=None,\n                                     recordformat='records', nested=False)\n\nConverts a data dict into a pandas DataFrame based on the specified record format. Parameters: - data: A dictionary containing the data to convert. - timecolumns: A list of column names to be treated as time columns. - recordformat: A string specifying the format of the data records (‘records’, ‘table’, ‘split’, ‘index’, ‘tight’). Returns: - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n\n\nExported source\ndef timeseries_dataframe_from_datadict(\n        data:dict, \n        timecolumns=None,\n        recordformat='records',\n        nested=False\n):\n        \n    \"\"\"\n    Converts a data dict into a pandas DataFrame based on the specified record format. \n    Parameters:\n        - data: A dictionary containing the data to convert.\n        - timecolumns: A list of column names to be treated as time columns.\n        - recordformat: A string specifying the format of the data records ('records', 'table', 'split', 'index', 'tight').\n    Returns:\n        - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n    \"\"\"\n\n    orient = recordformat.lower()\n    assert orient in ['records', 'table', 'split', 'index', 'tight']\n    assert timecolumns, 'No time columns specified'\n\n    #print(f\"Converting {'nested' if nested else 'flat'} data dict to DataFrame with orient={orient} and timecolumns={timecolumns}\")\n    \n    if orient == 'records':\n        if nested:\n            # data is a nested structure, we need to normalize it\n            df = pd.json_normalize(data, sep='.', errors='ignore')  # type: ignore\n\n        else:\n            # data is a structured ndarray, sequence of tuples or dicts, or DataFrame\n            df = pd.DataFrame.from_records(data, coerce_float=True)  # type: ignore\n            \n        time_columns_in_df = [C for C in df.columns if C in timecolumns]\n        if not  time_columns_in_df:\n            time_column = df.columns[0]\n        else:\n            time_column = time_columns_in_df[0]\n\n    elif orient == 'table':\n        # data is in pandas table format\n        time_column = data['schema']['primaryKey'][0]\n        df = pd.DataFrame.from_dict(data['data'], coerce_float=True).set_index(data['schema']['primaryKey'])\n        df.index.name = 'time'\n    else:\n        # data  is formatted according to 'orient' parameter (pandas)\n        df = pd.DataFrame.from_dict(data, orient=orient, coerce_float=True) # type: ignore\n        time_column = df.index.name\n\n\n    df.columns = list(df.columns)\n    df[time_column] = pd.to_datetime(df[time_column],utc=True,format='ISO8601')\n    df.set_index(time_column, inplace=True)\n    df.index = pd.DatetimeIndex(df.index).round('ms')\n    \n    df.index.name = 'time'\n\n    return df\n\n\n\ndf = timeseries_dataframe_from_datadict(test_data_dict_3_samples, timecolumns=['time'])\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 10:04:49+00:00', '2023-05-04 10:24:51+00:00',\n               '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = set_time_index_zone( \n    timeseries_dataframe_from_datadict(\n        test_data_dict_3_samples, \n        timecolumns=['time']\n    ), \n    timezone='Europe/Amsterdam'\n)\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 12:04:49+02:00\n16.72\n\n\n2023-05-04 12:24:51+02:00\n16.65\n\n\n2023-05-04 12:44:53+02:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 12:04:49+02:00', '2023-05-04 12:24:51+02:00',\n               '2023-05-04 12:44:53+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', name='time', freq=None)\n\n\n\n\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=3, freq='s').tz_convert('Europe/Amsterdam')\nrng\n\nDatetimeIndex(['2018-04-10 09:01:01.123000+02:00',\n               '2018-04-10 09:01:02.123000+02:00',\n               '2018-04-10 09:01:03.123000+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', freq='s')\n\n\n\nrng.strftime(\"%FT%R:%S%z\")\n\nIndex(['2018-04-10T09:01:01+0200', '2018-04-10T09:01:02+0200',\n       '2018-04-10T09:01:03+0200'],\n      dtype='object')\n\n\n\npd.DatetimeIndex(rng.strftime(\"%FT%R:%S%z\")).round('ms')\n\nDatetimeIndex(['2018-04-10 09:01:01+02:00', '2018-04-10 09:01:02+02:00',\n               '2018-04-10 09:01:03+02:00'],\n              dtype='datetime64[ns, UTC+02:00]', freq=None)\n\n\n\nrng.tz_convert('UTC').strftime(\"%FT%R:%SZ\")\n\nIndex(['2018-04-10T07:01:01Z', '2018-04-10T07:01:02Z', '2018-04-10T07:01:03Z'], dtype='object')\n\n\n\n# .map(lambda x: x.isoformat())\n\n\nrng = pd.date_range(pd.Timestamp(\"2018-04-10T09:01:01.123+02:00\"), periods=30000, freq='s').tz_convert('Europe/Amsterdam')\n\n\n\n\nft = rng.strftime(\"%FT%R:%S%z\")\n\n340 ms ± 18.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nft = rng.map(lambda x: x.isoformat(timespec='milliseconds'))\n\n136 ms ± 9.46 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n\n\nsource\n\n\n\n\n timeseries_dataframe_to_datadict\n                                   (data:Union[pandas.core.frame.DataFrame\n                                   ,pandas.core.series.Series,dict],\n                                   recordformat:str='records',\n                                   timezone:str='UTC')\n\n*Convert a timeseries DataFrame or Series into a dictionary representation.\nArgs: data (Union[pd.DataFrame, pd.Series, dict]): The input data to be converted. It can be a pandas DataFrame, Series, or a dictionary. recordformat (str, optional): The format of the output records. Defaults to ‘records’. timezone (str, optional): The timezone to use for the DataFrame index. Defaults to ‘UTC’.\nReturns: Union[dict, list]: The converted dictionary representation of the input data, a dictionary or a list of dictionaries depending on the recordformat parameter.*\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe(df, timezone='UTC').index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records')\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='records', timezone='Europe/Berlin')\n\n[{'time': '2023-05-04T11:04:49.050+02:00', 'value': 16.72},\n {'time': '2023-05-04T12:24:51.010+02:00', 'value': 16.65},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': 16.55},\n {'time': '2023-05-04T12:44:53.000+02:00', 'value': nan}]\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 09:04:49.050000+00:00',\n               '2023-05-04 10:24:51.010000+00:00',\n                      '2023-05-04 10:44:53+00:00',\n                      '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.050+01:00\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.010Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":np.nan\n      }\n   ], timecolumns=['time'])\n\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 09:04:49.050000+00:00\n16.72\n\n\n2023-05-04 10:24:51.010000+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n2023-05-04 10:44:53+00:00\nNaN\n\n\n\n\n\n\n\n\ntimeseries_dataframe_to_datadict(df, recordformat='tight')\n\n{'index': ['2023-05-04T09:04:49Z',\n  '2023-05-04T10:24:51Z',\n  '2023-05-04T10:44:53Z',\n  '2023-05-04T10:44:53Z'],\n 'columns': ['value'],\n 'data': [[16.72], [16.65], [16.55], [nan]],\n 'index_names': ['time'],\n 'column_names': [None]}\n\n\n\ntest_data = timeseries_dataframe_to_datadict(df, recordformat='records')\n\n\ntest_data\n\n[{'time': '2023-05-04T09:04:49Z', 'value': 16.72},\n {'time': '2023-05-04T10:24:51Z', 'value': 16.65},\n {'time': '2023-05-04T10:44:53Z', 'value': 16.55},\n {'time': '2023-05-04T10:44:53Z', 'value': nan}]\n\n\n\nsource\n\n\n\n\n timeseries_dataframe_resample (df:pandas.core.frame.DataFrame,\n                                period:str, method:str)\n\n*Resamples a time-series DataFrame on the specified period and method.\nParameters: df (pd.DataFrame): The input time-series DataFrame. period (str): The resampling period. method (str): The resampling method. Can be a string of multiple methods separated by ‘;’. method_args (dict, optional): Additional arguments for the resampling method.\nReturns: pd.DataFrame: The resampled DataFrame.*\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.000Z\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.000Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      },\n      {\n         \"time\":\"2023-05-04T11:04:49.000Z\",\n         \"value\":16.47\n      },\n      {\n         \"time\":\"2023-05-04T11:24:51.000Z\",\n         \"value\":16.44\n      },\n      {\n         \"time\":\"2023-05-04T11:44:53.000Z\",\n         \"value\":16.38\n      },\n   ], timecolumns=['time'])\n\n\ntimeseries_dataframe_resample(df, \"80min\", 'mean;count')\n\n\n\n\n\n\n\n\nvalue\nvalue_mean\nvalue_count\n\n\ntime\n\n\n\n\n\n\n\n2023-05-04 09:20:00+00:00\nNaN\n16.685\n2.0\n\n\n2023-05-04 10:04:49+00:00\n16.72\nNaN\nNaN\n\n\n2023-05-04 10:24:51+00:00\n16.65\nNaN\nNaN\n\n\n2023-05-04 10:40:00+00:00\nNaN\n16.460\n4.0\n\n\n2023-05-04 10:44:53+00:00\n16.55\nNaN\nNaN\n\n\n2023-05-04 11:04:49+00:00\n16.47\nNaN\nNaN\n\n\n2023-05-04 11:24:51+00:00\n16.44\nNaN\nNaN\n\n\n2023-05-04 11:44:53+00:00\n16.38\nNaN\nNaN",
    "crumbs": [
      "Timeseries datarames"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "corebridge",
    "section": "",
    "text": "This package provides functions and classes to run wodan style processing functions in the Stactics AICore environment.",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "corebridge",
    "section": "Installation",
    "text": "Installation\nUse\npip install corebridge\nto install corebrdige.",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "corebridge",
    "section": "How to use",
    "text": "How to use\n\nIntroduction\nWodan is a proprietary backend service that applies high performance, custom analytical processing to timeseries data in the Whysor data and dashboarding environment.\nEach wodan module defines one function that operates as the entry point. The parameter annotations in this function definition are used to format data and retrieve parameters from the originating call to the wodan api. This function is called with data retrieved according to a specification and with additional parameters as annotated.\nA simple function might look like:\nimport numpy as np\n\ndef multiply(data:np.ndarray, multiplier:float=1.0):\n    return data * multiplier\n    \nWodan binds this function to a service endpoint and takes care of fetching data and parameters and converting the result for the caller.\n\n\nAICore modules\nFor AICore users define a class, always named Module with a constructor __init__ and a method infer.\nThis package defines a baseclass to quickly construct a Module class that is able to use a wodan processor function inside the AICore system:\nimport numpy as np\nimport corebridge\n\ndef multiply(data:np.ndarray, multiplier:float=1.0):\n    return data * multiplier\n\nclass Module(corebridge.aicorebridge.AICoreModule):\n    def __init__(self, save_dir, assets_dir, *args, **kwargs):\n        super().__init__(multiply, save_dir, assets_dir, *args, **kwargs)\n    \nThat’s it. Well, you can add parameters to __init__ that can be used as hyperparameters in the web-interface and you could override infer for the same reason. The baseclass takes care of converting call parameters and data to the function specification and, calls the function and converts the result for the caller, similar to the original Wodan service.\nYou don’t have to use AICoreModule baseclas but can create your own class and use functionality within CoreBridge to convert call parameters and data to fit your needs. AICoreModule was developed to make the deployment of existing Wodan modules within AICore easier. It also helps developing functions independently of AICore while being able to deploy these functions as modules within AICore.",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#development",
    "href": "index.html#development",
    "title": "corebridge",
    "section": "Development",
    "text": "Development\n\nNBDev\nThis library is developed with NBDev - a literate programming toolkit that supports developing code using jupyter notebooks and mix code with documentation.\nLiterate programming is a methodology - introduced in 1984 by Donald Knuth - that combines a programming language with a documentation language. In this approach, a program is explained in a human language (such as English) alongside code snippets. The literate source file is then processed by a preprocessor to produce both source code and formatted documentation.\nThis paradigm enhances program robustness, portability, and maintainability, making it a valuable tool in scientific computing and data science1\n\n\nQuarto\nDocumentation is prepared from the notebook with Quarto. Quarto too combines code with documentation but it does not extract source code into modules like nbdev.\n\n\nInstallation\n\nQuarto\nQuarto uses Pandoc and, for pdf format, LaTeX. These must be available on your system.\nInstall Quarto as you see fit, there is a VSCode extension which handles this.\n\n\nNBDev\nNBDev is available as PyPi package and is installed with\npip install nbdev\nor if you are using conda\nconda install -c fastai -y nbdev\nIf so desired you can let NBDev install Quarto with\nnbdev_install_quarto\nBut this ask for the system admin password.\n\n\n\nLocal editing & testing\nSetup a virtual environment, activate it and install the development package and dependencies with, on linux\n    pip install -e ‘.[dev]’\n\nor on Windows\n    pip install -e .[dev]\n\n\nJupyter\nThe above pip install should also install jupyter but to use it the kernel needs to be installed with:\n    python -m ipykernel install --user --name=corebridge.venv\n\n\n\nnbdev cycle\n\nedit\nnbdev_prepare\n\nThe latter performs - nbdev_export - nbdev_test - nbdev_clean - nbdev_readme\nBefore committing changes to git run - nbdev_clean\nThen commit to git and for a new pip release upload to Pypi with nbdev_pypi",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "corebridge",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWikipedia on ‘Literate Programming’↩︎",
    "crumbs": [
      "corebridge"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core functionality",
    "section": "",
    "text": "source\n\n\n\n init_console_logging (name=None, level=20, timestamp=True)\n\nSetup none-blocking stream handler for sending loggin to the console.\n\n\nExported source\ndef init_console_logging(name=None, level=logging.INFO, timestamp=True):\n    '''Setup none-blocking stream handler for sending loggin to the console.'''\n\n    # Only if no handlers defined.\n    if not logging.getLogger(name).handlers:\n\n        logger = logging.getLogger()\n        logger.setLevel(level)\n\n        console = logging.StreamHandler()\n        console.setLevel(level)\n\n        # set a format which is simpler for console use\n        if timestamp:\n            formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n        else:\n            formatter = logging.Formatter(\"%(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\")\n            \n        #formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n\n        # tell the handler to use this format\n        console.setFormatter(formatter)\n\n        # add the handler to the root logger\n        logger.addHandler(console)\n        return logger\n    else:\n        logging.getLogger(name).info(f'There already is a logger installed for {name}.')",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#logging",
    "href": "core.html#logging",
    "title": "Core functionality",
    "section": "",
    "text": "source\n\n\n\n init_console_logging (name=None, level=20, timestamp=True)\n\nSetup none-blocking stream handler for sending loggin to the console.\n\n\nExported source\ndef init_console_logging(name=None, level=logging.INFO, timestamp=True):\n    '''Setup none-blocking stream handler for sending loggin to the console.'''\n\n    # Only if no handlers defined.\n    if not logging.getLogger(name).handlers:\n\n        logger = logging.getLogger()\n        logger.setLevel(level)\n\n        console = logging.StreamHandler()\n        console.setLevel(level)\n\n        # set a format which is simpler for console use\n        if timestamp:\n            formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n        else:\n            formatter = logging.Formatter(\"%(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\")\n            \n        #formatter = logging.Formatter(\"%(asctime)s %(levelname)s\\t%(process)d\\t%(name)s\\t%(filename)s\\t%(lineno)d\\t%(message)s\", datefmt='%Y-%m-%dT%H:%M:%S%z')\n\n        # tell the handler to use this format\n        console.setFormatter(formatter)\n\n        # add the handler to the root logger\n        logger.addHandler(console)\n        return logger\n    else:\n        logging.getLogger(name).info(f'There already is a logger installed for {name}.')",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#machine-information",
    "href": "core.html#machine-information",
    "title": "Core functionality",
    "section": "Machine information",
    "text": "Machine information\n\nget_machine_info()\n\n{'OS Name': 'nt',\n 'System Name': 'Windows',\n 'Release': '11',\n 'Version': '10.0.26100',\n 'Architecture': ('64bit', 'WindowsPE'),\n 'Machine': 'AMD64',\n 'Processor': 'Intel64 Family 6 Model 85 Stepping 4, GenuineIntel',\n 'Node Name': 'werkdoos'}",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#strings",
    "href": "core.html#strings",
    "title": "Core functionality",
    "section": "Strings",
    "text": "Strings\n\nsource\n\nsnake_case_to_camel_case\n\n snake_case_to_camel_case (snake_case:str)\n\n\n\nExported source\n@lru_cache(128)\ndef snake_case_to_camel_case(snake_case:str) -&gt; str:\n    splittext = snake_case.split('_')\n    return ''.join([x.capitalize() if n &gt; 0 else x for x,n in zip(splittext, range(len(splittext)))])",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#numpy-data-in-json",
    "href": "core.html#numpy-data-in-json",
    "title": "Core functionality",
    "section": "Numpy data in JSON",
    "text": "Numpy data in JSON\n\nsource\n\nNumpyEncoder\n\n NumpyEncoder (skipkeys=False, ensure_ascii=True, check_circular=True,\n               allow_nan=True, sort_keys=False, indent=None,\n               separators=None, default=None)\n\nCustom encoder for numpy data types",
    "crumbs": [
      "Core functionality"
    ]
  },
  {
    "objectID": "core.html#timeseries-dataframes",
    "href": "core.html#timeseries-dataframes",
    "title": "Core functionality",
    "section": "Timeseries dataframes",
    "text": "Timeseries dataframes\nTimeseries data is a cornerstone of our data manipulation and most processing is on them\n\nset_time_index_zone\nProcessing may depend on proper timezone awareness, this utility to set the timezone on a datetime index\n\nsource\n\n\nset_time_index_zone\n\n set_time_index_zone (df:pandas.core.frame.DataFrame, timezone)\n\n*Sets the time zone of the index of a pandas DataFrame.\nArgs: df (pd.DataFrame): The DataFrame whose index time zone is to be set. timezone (str): The desired time zone.\nReturns: pd.DataFrame: The modified DataFrame with its index time zone set to the specified time zone.\nRaises: None\nExamples: &gt;&gt;&gt; df = pd.DataFrame({‘A’: [1, 2, 3]}, index=pd.DatetimeIndex([‘2022-01-01’, ‘2022-01-02’, ‘2022-01-03’])) &gt;&gt;&gt; set_time_index_zone(df, ‘Europe/Berlin’) A 2022-01-01 1 2022-01-02 2 2022-01-03 3 DatetimeIndex: 3 entries, 2022-01-01 01:00:00+01:00 to 2022-01-03 01:00:00+01:00*\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nDataframe to set or convert the timeindex on\n\n\ntimezone\n\nTimezone to set\n\n\n\n\nExample\n\ndf = pd.DataFrame({'A': [1, 2, 3]}, index=pd.DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03']))\nset_time_index_zone(df, 'Europe/Berlin')\ndf.index\n\nDatetimeIndex(['2022-01-01 01:00:00+01:00', '2022-01-02 01:00:00+01:00',\n               '2022-01-03 01:00:00+01:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='time', freq=None)\n\n\n\n\n\ntimeseries_dataframe\nConverts Pandas dataframes and series, Numpy array’s and recarrays or a dictionary of individual timeseries into a Pandas dataframe with one datetime index. With all arrays dataframes and series it is assumed that the first column contains the timestamps.\n\nsource\n\n\ntimeseries_dataframe\n\n timeseries_dataframe (data:Union[pandas.core.frame.DataFrame,pandas.core.\n                       series.Series,dict,numpy.ndarray,numpy.rec.recarray\n                       ], timezone='UTC', columnnames=None)\n\n*Convert various tabular data formats to timeseries DataFrame\nArgs: data (Union[pd.DataFrame, pd.Series, dict, np.ndarray, np.recarray]): The input data to be converted. timezone (str, optional): The timezone to set for the index of the DataFrame. Defaults to ‘UTC’. columnnames (Optional[List[str]]): The column names to use for the DataFrame. Defaults to None.\nReturns: pd.DataFrame: The converted timeseries DataFrame with the index set to the specified timezone.*\n\n\ntimeseries_dataframe_from_datadict\n\nsource\n\n\ntimeseries_dataframe_from_datadict\n\n timeseries_dataframe_from_datadict (data:dict, timecolumns=None,\n                                     recordformat='records')\n\nConverts a data dict into a pandas DataFrame based on the specified record format. Parameters: - data: A dictionary containing the data to convert. - timecolumns: A list of column names to be treated as time columns. - recordformat: A string specifying the format of the data records (‘records’, ‘table’, ‘split’, ‘index’, ‘tight’). Returns: - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n\n\nExported source\ndef timeseries_dataframe_from_datadict(\n        data:dict, \n        timecolumns=None,\n        recordformat='records'):\n        \n    \"\"\"\n    Converts a data dict into a pandas DataFrame based on the specified record format. \n    Parameters:\n        - data: A dictionary containing the data to convert.\n        - timecolumns: A list of column names to be treated as time columns.\n        - recordformat: A string specifying the format of the data records ('records', 'table', 'split', 'index', 'tight').\n    Returns:\n        - df: A pandas DataFrame with a DatetimeIndex representing the converted data.\n    \"\"\"\n\n    orient = recordformat.lower()\n    assert orient in ['records', 'table', 'split', 'index', 'tight']\n    assert timecolumns, 'No time columns specified'\n\n    if orient == 'records':\n        # data is a structured ndarray, sequence of tuples or dicts, or DataFrame\n        df = pd.DataFrame.from_records(data)\n        time_columns_in_df = [C for C in df.columns if C in timecolumns]\n        if not  time_columns_in_df:\n            #syslog.error(f\"No  column in records {df.columns} matches specification in time columns {timecolumns}, assuming first column is time\")\n            time_column = df.columns[0]\n        else:\n            time_column = time_columns_in_df[0]\n\n    elif orient == 'table':\n        # data is in pandas table format\n        time_column = data['schema']['primaryKey'][0]\n        df = pd.DataFrame.from_dict(data['data']).set_index(data['schema']['primaryKey'])\n        df.index.name = 'time'\n    else:\n        # data  is formatted according to 'orient' parameter (pandas)\n        df = pd.DataFrame.from_dict(data, orient=orient) # type: ignore\n        time_column = df.index.name\n\n\n    df.columns = list(df.columns)\n    df[time_column] = pd.to_datetime(df[time_column],utc=True,format='ISO8601')\n    df.set_index(time_column, inplace=True)\n    df.index = pd.DatetimeIndex(df.index).round('ms')\n    \n    df.index.name = 'time'\n\n    return df\n\n\n\ndf = timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49.000Z\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51.000Z\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53.000Z\",\n         \"value\":16.55\n      }\n   ], timecolumns=['time'])\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 10:04:49+00:00\n16.72\n\n\n2023-05-04 10:24:51+00:00\n16.65\n\n\n2023-05-04 10:44:53+00:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 10:04:49+00:00', '2023-05-04 10:24:51+00:00',\n               '2023-05-04 10:44:53+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None)\n\n\n\ndf = set_time_index_zone( timeseries_dataframe_from_datadict([\n      {\n         \"time\":\"2023-05-04T10:04:49\",\n         \"value\":16.72\n      },\n      {\n         \"time\":\"2023-05-04T10:24:51\",\n         \"value\":16.65\n      },\n      {\n         \"time\":\"2023-05-04T10:44:53\",\n         \"value\":16.55\n      }\n   ], timecolumns=['time']), timezone='Europe/Amsterdam')\ndf\n\n\n\n\n\n\n\n\nvalue\n\n\ntime\n\n\n\n\n\n2023-05-04 12:04:49+02:00\n16.72\n\n\n2023-05-04 12:24:51+02:00\n16.65\n\n\n2023-05-04 12:44:53+02:00\n16.55\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2023-05-04 12:04:49+02:00', '2023-05-04 12:24:51+02:00',\n               '2023-05-04 12:44:53+02:00'],\n              dtype='datetime64[ns, Europe/Amsterdam]', name='time', freq=None)",
    "crumbs": [
      "Core functionality"
    ]
  }
]